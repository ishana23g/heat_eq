==PROF== Connected to process 28535 (/home/driffyn/Documents/CMDA4634/heat_eq/optimized/cuda_heat_equation)
==PROF== Profiling "heat_kernel_2d_fused" - 0: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 1: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 2: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 3: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 4: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 5: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 6: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 7: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 8: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 9: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 10: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 11: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 12: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 13: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 14: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 15: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 16: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 17: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 18: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 19: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 20: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 21: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 22: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 23: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 24: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 25: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 26: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 27: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 28: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 29: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 30: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 31: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 32: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 33: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 34: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 35: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 36: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 37: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 38: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 39: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 40: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 41: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 42: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 43: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 44: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 45: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 46: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 47: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 48: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 49: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 50: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 51: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 52: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 53: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 54: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 55: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 56: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 57: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 58: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 59: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 60: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 61: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 62: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 63: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 64: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 65: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 66: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 67: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 68: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 69: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 70: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 71: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 72: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 73: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 74: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 75: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 76: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 77: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 78: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 79: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 80: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 81: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 82: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 83: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 84: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 85: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 86: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 87: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 88: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 89: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 90: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 91: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 92: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 93: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 94: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 95: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 96: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 97: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 98: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 99: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 100: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 101: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 102: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 103: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 104: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 105: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 106: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 107: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 108: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 109: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 110: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 111: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 112: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 113: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 114: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 115: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 116: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 117: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 118: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 119: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 120: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 121: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 122: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 123: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 124: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 125: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 126: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 127: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 128: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 129: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 130: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 131: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 132: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 133: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 134: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 135: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 136: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 137: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 138: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 139: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 140: 0%....50%....100% - 8 passes
==PROF== Disconnected from process 28535
[28535] cuda_heat_equation@127.0.0.1
  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.14
    Elapsed Cycles                cycle       81,089
    Memory Throughput                 %        72.97
    DRAM Throughput                   %        41.19
    Duration                         us        99.23
    L1/TEX Cache Throughput           %        74.72
    L2 Cache Throughput               %        28.99
    SM Active Cycles              cycle    78,842.20
    Compute (SM) Throughput           %        82.19
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.71
    Achieved Active Warps Per SM           warp        43.54
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,800
    Total DRAM Elapsed Cycles        cycle    3,565,568
    Average L1 Active Cycles         cycle    78,842.20
    Total L1 Elapsed Cycles          cycle    2,421,770
    Average L2 Active Cycles         cycle    72,914.96
    Total L2 Elapsed Cycles          cycle    1,820,856
    Average SM Active Cycles         cycle    78,842.20
    Total SM Elapsed Cycles          cycle    2,421,770
    Average SMSP Active Cycles       cycle    78,725.68
    Total SMSP Elapsed Cycles        cycle    9,687,080
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.16
    Elapsed Cycles                cycle       80,884
    Memory Throughput                 %        72.77
    DRAM Throughput                   %        41.32
    Duration                         us        98.98
    L1/TEX Cache Throughput           %        74.83
    L2 Cache Throughput               %        29.13
    SM Active Cycles              cycle    78,727.57
    Compute (SM) Throughput           %        81.95
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.63
    Achieved Active Warps Per SM           warp        43.50
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,997.33
    Total DRAM Elapsed Cycles        cycle    3,557,376
    Average L1 Active Cycles         cycle    78,727.57
    Total L1 Elapsed Cycles          cycle    2,428,690
    Average L2 Active Cycles         cycle    72,760.38
    Total L2 Elapsed Cycles          cycle    1,816,344
    Average SM Active Cycles         cycle    78,727.57
    Total SM Elapsed Cycles          cycle    2,428,690
    Average SMSP Active Cycles       cycle    78,724.43
    Total SMSP Elapsed Cycles        cycle    9,714,760
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.36
    Elapsed Cycles                cycle       80,930
    Memory Throughput                 %        72.80
    DRAM Throughput                   %        41.27
    Duration                         us        99.01
    L1/TEX Cache Throughput           %        74.79
    L2 Cache Throughput               %        29.11
    SM Active Cycles              cycle    78,761.57
    Compute (SM) Throughput           %        82.00
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.69
    Achieved Active Warps Per SM           warp        43.53
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,773.33
    Total DRAM Elapsed Cycles        cycle    3,558,400
    Average L1 Active Cycles         cycle    78,761.57
    Total L1 Elapsed Cycles          cycle    2,427,390
    Average L2 Active Cycles         cycle    72,869.58
    Total L2 Elapsed Cycles          cycle    1,817,352
    Average SM Active Cycles         cycle    78,761.57
    Total SM Elapsed Cycles          cycle    2,427,390
    Average SMSP Active Cycles       cycle    78,691.31
    Total SMSP Elapsed Cycles        cycle    9,709,560
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.16
    Elapsed Cycles                cycle       81,068
    Memory Throughput                 %        72.77
    DRAM Throughput                   %        41.34
    Duration                         us        99.20
    L1/TEX Cache Throughput           %        74.80
    L2 Cache Throughput               %        29.06
    SM Active Cycles              cycle    78,753.93
    Compute (SM) Throughput           %        81.95
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.67
    Achieved Active Warps Per SM           warp        43.52
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,677.33
    Total DRAM Elapsed Cycles        cycle    3,565,568
    Average L1 Active Cycles         cycle    78,753.93
    Total L1 Elapsed Cycles          cycle    2,428,660
    Average L2 Active Cycles         cycle    72,831.42
    Total L2 Elapsed Cycles          cycle    1,820,568
    Average SM Active Cycles         cycle    78,753.93
    Total SM Elapsed Cycles          cycle    2,428,660
    Average SMSP Active Cycles       cycle    78,649.94
    Total SMSP Elapsed Cycles        cycle    9,714,640
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.88
    SM Frequency                    Mhz       798.02
    Elapsed Cycles                cycle        3,014
    Memory Throughput                 %         0.90
    DRAM Throughput                   %         0.40
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.90
    SM Active Cycles              cycle       428.93
    Compute (SM) Throughput           %         0.54
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.24
    Achieved Active Warps Per SM           warp         5.39
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.76%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           88
    Total DRAM Elapsed Cycles        cycle      133,120
    Average L1 Active Cycles         cycle       428.93
    Total L1 Elapsed Cycles          cycle       91,470
    Average L2 Active Cycles         cycle       214.50
    Total L2 Elapsed Cycles          cycle       67,704
    Average SM Active Cycles         cycle       428.93
    Total SM Elapsed Cycles          cycle       91,470
    Average SMSP Active Cycles       cycle       305.48
    Total SMSP Elapsed Cycles        cycle      365,880
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.49%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.46% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.841%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.26% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.49%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.46% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.18
    Elapsed Cycles                cycle       80,912
    Memory Throughput                 %        72.85
    DRAM Throughput                   %        41.25
    Duration                         us        99.01
    L1/TEX Cache Throughput           %        74.83
    L2 Cache Throughput               %        29.12
    SM Active Cycles              cycle    78,723.13
    Compute (SM) Throughput           %        82.05
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.69
    Achieved Active Warps Per SM           warp        43.53
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,653.33
    Total DRAM Elapsed Cycles        cycle    3,558,400
    Average L1 Active Cycles         cycle    78,723.13
    Total L1 Elapsed Cycles          cycle    2,425,910
    Average L2 Active Cycles         cycle    72,833.75
    Total L2 Elapsed Cycles          cycle    1,816,944
    Average SM Active Cycles         cycle    78,723.13
    Total SM Elapsed Cycles          cycle    2,425,910
    Average SMSP Active Cycles       cycle    78,713.50
    Total SMSP Elapsed Cycles        cycle    9,703,640
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.09
    Elapsed Cycles                cycle       80,903
    Memory Throughput                 %        72.90
    DRAM Throughput                   %        41.33
    Duration                         us        99.01
    L1/TEX Cache Throughput           %        74.71
    L2 Cache Throughput               %        29.14
    SM Active Cycles              cycle    78,849.43
    Compute (SM) Throughput           %        82.11
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.64
    Achieved Active Warps Per SM           warp        43.51
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,021.33
    Total DRAM Elapsed Cycles        cycle    3,557,376
    Average L1 Active Cycles         cycle    78,849.43
    Total L1 Elapsed Cycles          cycle    2,424,080
    Average L2 Active Cycles         cycle    72,825.54
    Total L2 Elapsed Cycles          cycle    1,816,896
    Average SM Active Cycles         cycle    78,849.43
    Total SM Elapsed Cycles          cycle    2,424,080
    Average SMSP Active Cycles       cycle    78,752.12
    Total SMSP Elapsed Cycles        cycle    9,696,320
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.39
    Elapsed Cycles                cycle       81,088
    Memory Throughput                 %        72.75
    DRAM Throughput                   %        41.21
    Duration                         us        99.20
    L1/TEX Cache Throughput           %        74.68
    L2 Cache Throughput               %        29.10
    SM Active Cycles              cycle    78,878.30
    Compute (SM) Throughput           %        81.93
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.73
    Achieved Active Warps Per SM           warp        43.55
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,917.33
    Total DRAM Elapsed Cycles        cycle    3,565,568
    Average L1 Active Cycles         cycle    78,878.30
    Total L1 Elapsed Cycles          cycle    2,429,340
    Average L2 Active Cycles         cycle    72,997.96
    Total L2 Elapsed Cycles          cycle    1,820,904
    Average SM Active Cycles         cycle    78,878.30
    Total SM Elapsed Cycles          cycle    2,429,340
    Average SMSP Active Cycles       cycle    78,660.20
    Total SMSP Elapsed Cycles        cycle    9,717,360
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.19
    Elapsed Cycles                cycle       80,992
    Memory Throughput                 %        72.81
    DRAM Throughput                   %        41.43
    Duration                         us        99.10
    L1/TEX Cache Throughput           %        74.78
    L2 Cache Throughput               %        29.10
    SM Active Cycles              cycle    78,772.53
    Compute (SM) Throughput           %        82.00
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.64
    Achieved Active Warps Per SM           warp        43.51
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,013.33
    Total DRAM Elapsed Cycles        cycle    3,562,496
    Average L1 Active Cycles         cycle    78,772.53
    Total L1 Elapsed Cycles          cycle    2,427,150
    Average L2 Active Cycles         cycle    72,879.71
    Total L2 Elapsed Cycles          cycle    1,818,888
    Average SM Active Cycles         cycle    78,772.53
    Total SM Elapsed Cycles          cycle    2,427,150
    Average SMSP Active Cycles       cycle    78,741.56
    Total SMSP Elapsed Cycles        cycle    9,708,600
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.91
    SM Frequency                    Mhz       802.69
    Elapsed Cycles                cycle        3,109
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.36
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.85
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       421.40
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.12
    Achieved Active Warps Per SM           warp         5.34
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.88%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        82.67
    Total DRAM Elapsed Cycles        cycle      137,216
    Average L1 Active Cycles         cycle       421.40
    Total L1 Elapsed Cycles          cycle       90,130
    Average L2 Active Cycles         cycle       234.42
    Total L2 Elapsed Cycles          cycle       69,744
    Average SM Active Cycles         cycle       421.40
    Total SM Elapsed Cycles          cycle       90,130
    Average SMSP Active Cycles       cycle       293.98
    Total SMSP Elapsed Cycles        cycle      360,520
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.459%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.43% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.516%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.82% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.459%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.43% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.46
    Elapsed Cycles                cycle       81,071
    Memory Throughput                 %        72.68
    DRAM Throughput                   %        41.40
    Duration                         us        99.17
    L1/TEX Cache Throughput           %        74.74
    L2 Cache Throughput               %        29.06
    SM Active Cycles              cycle    78,821.07
    Compute (SM) Throughput           %        81.85
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.65
    Achieved Active Warps Per SM           warp        43.51
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,978.67
    Total DRAM Elapsed Cycles        cycle    3,564,544
    Average L1 Active Cycles         cycle    78,821.07
    Total L1 Elapsed Cycles          cycle    2,431,710
    Average L2 Active Cycles         cycle    72,853.21
    Total L2 Elapsed Cycles          cycle    1,820,424
    Average SM Active Cycles         cycle    78,821.07
    Total SM Elapsed Cycles          cycle    2,431,710
    Average SMSP Active Cycles       cycle    78,899.76
    Total SMSP Elapsed Cycles        cycle    9,726,840
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.37
    Elapsed Cycles                cycle       80,982
    Memory Throughput                 %        72.88
    DRAM Throughput                   %        41.49
    Duration                         us        99.07
    L1/TEX Cache Throughput           %        74.76
    L2 Cache Throughput               %        29.11
    SM Active Cycles              cycle    78,800.37
    Compute (SM) Throughput           %        82.07
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.68
    Achieved Active Warps Per SM           warp        43.52
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,290.67
    Total DRAM Elapsed Cycles        cycle    3,561,472
    Average L1 Active Cycles         cycle    78,800.37
    Total L1 Elapsed Cycles          cycle    2,425,040
    Average L2 Active Cycles         cycle    72,889.83
    Total L2 Elapsed Cycles          cycle    1,818,672
    Average SM Active Cycles         cycle    78,800.37
    Total SM Elapsed Cycles          cycle    2,425,040
    Average SMSP Active Cycles       cycle    78,741.50
    Total SMSP Elapsed Cycles        cycle    9,700,160
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.22
    Elapsed Cycles                cycle       81,021
    Memory Throughput                 %        72.88
    DRAM Throughput                   %        41.38
    Duration                         us        99.14
    L1/TEX Cache Throughput           %        74.85
    L2 Cache Throughput               %        29.10
    SM Active Cycles              cycle    78,700.83
    Compute (SM) Throughput           %        82.08
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.68
    Achieved Active Warps Per SM           warp        43.52
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,706.67
    Total DRAM Elapsed Cycles        cycle    3,562,496
    Average L1 Active Cycles         cycle    78,700.83
    Total L1 Elapsed Cycles          cycle    2,424,880
    Average L2 Active Cycles         cycle    72,887.42
    Total L2 Elapsed Cycles          cycle    1,819,368
    Average SM Active Cycles         cycle    78,700.83
    Total SM Elapsed Cycles          cycle    2,424,880
    Average SMSP Active Cycles       cycle    78,693.59
    Total SMSP Elapsed Cycles        cycle    9,699,520
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.10
    Elapsed Cycles                cycle       80,985
    Memory Throughput                 %        72.75
    DRAM Throughput                   %        41.23
    Duration                         us        99.10
    L1/TEX Cache Throughput           %        74.82
    L2 Cache Throughput               %        29.09
    SM Active Cycles              cycle    78,730.13
    Compute (SM) Throughput           %        81.93
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.65
    Achieved Active Warps Per SM           warp        43.51
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,757.33
    Total DRAM Elapsed Cycles        cycle    3,561,472
    Average L1 Active Cycles         cycle    78,730.13
    Total L1 Elapsed Cycles          cycle    2,429,320
    Average L2 Active Cycles         cycle    72,949.29
    Total L2 Elapsed Cycles          cycle    1,818,576
    Average SM Active Cycles         cycle    78,730.13
    Total SM Elapsed Cycles          cycle    2,429,320
    Average SMSP Active Cycles       cycle    78,726.44
    Total SMSP Elapsed Cycles        cycle    9,717,280
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.86
    SM Frequency                    Mhz       800.62
    Elapsed Cycles                cycle        3,102
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.33
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       428.40
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.24
    Achieved Active Warps Per SM           warp         5.39
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.76%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        74.67
    Total DRAM Elapsed Cycles        cycle      136,192
    Average L1 Active Cycles         cycle       428.40
    Total L1 Elapsed Cycles          cycle       89,080
    Average L2 Active Cycles         cycle       241.62
    Total L2 Elapsed Cycles          cycle       69,600
    Average SM Active Cycles         cycle       428.40
    Total SM Elapsed Cycles          cycle       89,080
    Average SMSP Active Cycles       cycle       304.38
    Total SMSP Elapsed Cycles        cycle      356,320
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.749%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.57% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.865%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.73% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.749%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.57% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.3%                                                                                            
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 63.61% above the average, while the minimum instance value is 84.69% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.28
    Elapsed Cycles                cycle       80,948
    Memory Throughput                 %        72.88
    DRAM Throughput                   %        41.34
    Duration                         us        99.04
    L1/TEX Cache Throughput           %        74.80
    L2 Cache Throughput               %        29.10
    SM Active Cycles              cycle    78,758.97
    Compute (SM) Throughput           %        82.07
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.68
    Achieved Active Warps Per SM           warp        43.53
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,216
    Total DRAM Elapsed Cycles        cycle    3,559,424
    Average L1 Active Cycles         cycle    78,758.97
    Total L1 Elapsed Cycles          cycle    2,424,940
    Average L2 Active Cycles         cycle    72,844.08
    Total L2 Elapsed Cycles          cycle    1,817,880
    Average SM Active Cycles         cycle    78,758.97
    Total SM Elapsed Cycles          cycle    2,424,940
    Average SMSP Active Cycles       cycle    78,757.18
    Total SMSP Elapsed Cycles        cycle    9,699,760
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.15
    Elapsed Cycles                cycle       80,934
    Memory Throughput                 %        72.87
    DRAM Throughput                   %        41.28
    Duration                         us        99.04
    L1/TEX Cache Throughput           %        74.75
    L2 Cache Throughput               %        29.13
    SM Active Cycles              cycle    78,810.13
    Compute (SM) Throughput           %        82.06
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.64
    Achieved Active Warps Per SM           warp        43.51
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,810.67
    Total DRAM Elapsed Cycles        cycle    3,558,400
    Average L1 Active Cycles         cycle    78,810.13
    Total L1 Elapsed Cycles          cycle    2,425,130
    Average L2 Active Cycles         cycle    72,873.83
    Total L2 Elapsed Cycles          cycle    1,817,472
    Average SM Active Cycles         cycle    78,810.13
    Total SM Elapsed Cycles          cycle    2,425,130
    Average SMSP Active Cycles       cycle    78,619.68
    Total SMSP Elapsed Cycles        cycle    9,700,520
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.87
    SM Frequency                    Mhz       800.07
    Elapsed Cycles                cycle        3,047
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.36
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.86
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       419.53
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.11
    Achieved Active Warps Per SM           warp         5.33
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.89%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      134,144
    Average L1 Active Cycles         cycle       419.53
    Total L1 Elapsed Cycles          cycle       90,430
    Average L2 Active Cycles         cycle       224.46
    Total L2 Elapsed Cycles          cycle       68,376
    Average SM Active Cycles         cycle       419.53
    Total SM Elapsed Cycles          cycle       90,430
    Average SMSP Active Cycles       cycle       305.97
    Total SMSP Elapsed Cycles        cycle      361,720
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.409%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.60% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.787%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.71% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.409%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.60% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.076%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 64.43% above the average, while the minimum instance value is 83.52% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.15
    Elapsed Cycles                cycle       80,988
    Memory Throughput                 %        72.84
    DRAM Throughput                   %        41.30
    Duration                         us        99.10
    L1/TEX Cache Throughput           %        74.75
    L2 Cache Throughput               %        29.10
    SM Active Cycles              cycle    78,803.60
    Compute (SM) Throughput           %        82.02
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.66
    Achieved Active Warps Per SM           warp        43.52
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,141.33
    Total DRAM Elapsed Cycles        cycle    3,561,472
    Average L1 Active Cycles         cycle    78,803.60
    Total L1 Elapsed Cycles          cycle    2,426,210
    Average L2 Active Cycles         cycle    72,870.25
    Total L2 Elapsed Cycles          cycle    1,818,768
    Average SM Active Cycles         cycle    78,803.60
    Total SM Elapsed Cycles          cycle    2,426,210
    Average SMSP Active Cycles       cycle    78,714.54
    Total SMSP Elapsed Cycles        cycle    9,704,840
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.15
    Elapsed Cycles                cycle       80,987
    Memory Throughput                 %        72.89
    DRAM Throughput                   %        41.27
    Duration                         us        99.10
    L1/TEX Cache Throughput           %        74.74
    L2 Cache Throughput               %        29.04
    SM Active Cycles              cycle    78,814.57
    Compute (SM) Throughput           %        82.07
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.66
    Achieved Active Warps Per SM           warp        43.52
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,928
    Total DRAM Elapsed Cycles        cycle    3,560,448
    Average L1 Active Cycles         cycle    78,814.57
    Total L1 Elapsed Cycles          cycle    2,424,700
    Average L2 Active Cycles         cycle    72,833.71
    Total L2 Elapsed Cycles          cycle    1,818,576
    Average SM Active Cycles         cycle    78,814.57
    Total SM Elapsed Cycles          cycle    2,424,700
    Average SMSP Active Cycles       cycle    78,636.57
    Total SMSP Elapsed Cycles        cycle    9,698,800
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.82
    SM Frequency                    Mhz       795.49
    Elapsed Cycles                cycle        3,057
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.33
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       428.10
    Compute (SM) Throughput           %         0.54
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.20
    Achieved Active Warps Per SM           warp         5.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.8%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        74.67
    Total DRAM Elapsed Cycles        cycle      134,144
    Average L1 Active Cycles         cycle       428.10
    Total L1 Elapsed Cycles          cycle       91,120
    Average L2 Active Cycles         cycle       227.92
    Total L2 Elapsed Cycles          cycle       68,688
    Average SM Active Cycles         cycle       428.10
    Total SM Elapsed Cycles          cycle       91,120
    Average SMSP Active Cycles       cycle       305.43
    Total SMSP Elapsed Cycles        cycle      364,480
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.534%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.64% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.899%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.55% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.534%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.64% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.17
    Elapsed Cycles                cycle       81,096
    Memory Throughput                 %        72.78
    DRAM Throughput                   %        41.20
    Duration                         us        99.23
    L1/TEX Cache Throughput           %        74.84
    L2 Cache Throughput               %        29.08
    SM Active Cycles              cycle       78,715
    Compute (SM) Throughput           %        81.95
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.63
    Achieved Active Warps Per SM           warp        43.50
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,882.67
    Total DRAM Elapsed Cycles        cycle    3,566,592
    Average L1 Active Cycles         cycle       78,715
    Total L1 Elapsed Cycles          cycle    2,428,330
    Average L2 Active Cycles         cycle    72,921.38
    Total L2 Elapsed Cycles          cycle    1,821,192
    Average SM Active Cycles         cycle       78,715
    Total SM Elapsed Cycles          cycle    2,428,330
    Average SMSP Active Cycles       cycle    78,604.30
    Total SMSP Elapsed Cycles        cycle    9,713,320
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.29
    Elapsed Cycles                cycle       80,845
    Memory Throughput                 %        72.98
    DRAM Throughput                   %        41.42
    Duration                         us        98.91
    L1/TEX Cache Throughput           %        74.70
    L2 Cache Throughput               %        29.14
    SM Active Cycles              cycle    78,861.63
    Compute (SM) Throughput           %        82.18
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.67
    Achieved Active Warps Per SM           warp        43.52
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,336
    Total DRAM Elapsed Cycles        cycle    3,554,304
    Average L1 Active Cycles         cycle    78,861.63
    Total L1 Elapsed Cycles          cycle    2,421,410
    Average L2 Active Cycles         cycle    72,820.17
    Total L2 Elapsed Cycles          cycle    1,815,432
    Average SM Active Cycles         cycle    78,861.63
    Total SM Elapsed Cycles          cycle    2,421,410
    Average SMSP Active Cycles       cycle    78,767.35
    Total SMSP Elapsed Cycles        cycle    9,685,640
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       798.99
    Elapsed Cycles                cycle        3,019
    Memory Throughput                 %         0.89
    DRAM Throughput                   %         0.40
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.84
    L2 Cache Throughput               %         0.89
    SM Active Cycles              cycle       421.90
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.07
    Achieved Active Warps Per SM           warp         5.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.93%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           88
    Total DRAM Elapsed Cycles        cycle      132,096
    Average L1 Active Cycles         cycle       421.90
    Total L1 Elapsed Cycles          cycle       89,450
    Average L2 Active Cycles         cycle       224.79
    Total L2 Elapsed Cycles          cycle       67,704
    Average SM Active Cycles         cycle       421.90
    Total SM Elapsed Cycles          cycle       89,450
    Average SMSP Active Cycles       cycle       294.67
    Total SMSP Elapsed Cycles        cycle      357,800
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.543%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.45% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.591%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.82% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.543%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.45% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.01
    Elapsed Cycles                cycle       81,025
    Memory Throughput                 %        72.82
    DRAM Throughput                   %        41.40
    Duration                         us        99.17
    L1/TEX Cache Throughput           %        74.69
    L2 Cache Throughput               %        29.08
    SM Active Cycles              cycle    78,872.87
    Compute (SM) Throughput           %        81.99
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.71
    Achieved Active Warps Per SM           warp        43.54
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,789.33
    Total DRAM Elapsed Cycles        cycle    3,562,496
    Average L1 Active Cycles         cycle    78,872.87
    Total L1 Elapsed Cycles          cycle    2,427,000
    Average L2 Active Cycles         cycle    72,905.12
    Total L2 Elapsed Cycles          cycle    1,819,536
    Average SM Active Cycles         cycle    78,872.87
    Total SM Elapsed Cycles          cycle    2,427,000
    Average SMSP Active Cycles       cycle    78,723.77
    Total SMSP Elapsed Cycles        cycle    9,708,000
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       796.13
    Elapsed Cycles                cycle        3,033
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.36
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.73
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       439.57
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.34
    Achieved Active Warps Per SM           warp         5.45
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.66%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      133,120
    Average L1 Active Cycles         cycle       439.57
    Total L1 Elapsed Cycles          cycle       89,810
    Average L2 Active Cycles         cycle       224.29
    Total L2 Elapsed Cycles          cycle       68,160
    Average SM Active Cycles         cycle       439.57
    Total SM Elapsed Cycles          cycle       89,810
    Average SMSP Active Cycles       cycle       304.56
    Total SMSP Elapsed Cycles        cycle      359,240
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.93%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.63% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.801%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.68% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.93%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.63% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.30
    Elapsed Cycles                cycle       80,820
    Memory Throughput                 %        72.87
    DRAM Throughput                   %        41.34
    Duration                         us        98.88
    L1/TEX Cache Throughput           %        74.78
    L2 Cache Throughput               %        29.17
    SM Active Cycles              cycle    78,778.23
    Compute (SM) Throughput           %        82.05
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.63
    Achieved Active Warps Per SM           warp        43.50
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,917.33
    Total DRAM Elapsed Cycles        cycle    3,554,304
    Average L1 Active Cycles         cycle    78,778.23
    Total L1 Elapsed Cycles          cycle    2,425,270
    Average L2 Active Cycles         cycle    72,860.42
    Total L2 Elapsed Cycles          cycle    1,815,000
    Average SM Active Cycles         cycle    78,778.23
    Total SM Elapsed Cycles          cycle    2,425,270
    Average SMSP Active Cycles       cycle    78,731.32
    Total SMSP Elapsed Cycles        cycle    9,701,080
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.39
    Elapsed Cycles                cycle       81,088
    Memory Throughput                 %        72.77
    DRAM Throughput                   %        41.23
    Duration                         us        99.20
    L1/TEX Cache Throughput           %        74.81
    L2 Cache Throughput               %        29.04
    SM Active Cycles              cycle    78,741.47
    Compute (SM) Throughput           %        81.93
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.66
    Achieved Active Warps Per SM           warp        43.52
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,002.67
    Total DRAM Elapsed Cycles        cycle    3,565,568
    Average L1 Active Cycles         cycle    78,741.47
    Total L1 Elapsed Cycles          cycle    2,428,690
    Average L2 Active Cycles         cycle    72,890.50
    Total L2 Elapsed Cycles          cycle    1,821,096
    Average SM Active Cycles         cycle    78,741.47
    Total SM Elapsed Cycles          cycle    2,428,690
    Average SMSP Active Cycles       cycle    78,632.01
    Total SMSP Elapsed Cycles        cycle    9,714,760
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.06
    Elapsed Cycles                cycle       80,951
    Memory Throughput                 %        73.01
    DRAM Throughput                   %        41.26
    Duration                         us        99.07
    L1/TEX Cache Throughput           %        74.72
    L2 Cache Throughput               %        29.10
    SM Active Cycles              cycle    78,839.87
    Compute (SM) Throughput           %        82.20
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.68
    Achieved Active Warps Per SM           warp        43.53
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,792
    Total DRAM Elapsed Cycles        cycle    3,559,424
    Average L1 Active Cycles         cycle    78,839.87
    Total L1 Elapsed Cycles          cycle    2,420,490
    Average L2 Active Cycles         cycle    72,795.79
    Total L2 Elapsed Cycles          cycle    1,817,952
    Average SM Active Cycles         cycle    78,839.87
    Total SM Elapsed Cycles          cycle    2,420,490
    Average SMSP Active Cycles       cycle    78,714.01
    Total SMSP Elapsed Cycles        cycle    9,681,960
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.31
    Elapsed Cycles                cycle       81,056
    Memory Throughput                 %        72.93
    DRAM Throughput                   %        41.27
    Duration                         us        99.17
    L1/TEX Cache Throughput           %        74.81
    L2 Cache Throughput               %        29.11
    SM Active Cycles              cycle    78,743.13
    Compute (SM) Throughput           %        82.10
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.61
    Achieved Active Warps Per SM           warp        43.49
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,136
    Total DRAM Elapsed Cycles        cycle    3,563,520
    Average L1 Active Cycles         cycle    78,743.13
    Total L1 Elapsed Cycles          cycle    2,423,130
    Average L2 Active Cycles         cycle    72,862.33
    Total L2 Elapsed Cycles          cycle    1,820,064
    Average SM Active Cycles         cycle    78,743.13
    Total SM Elapsed Cycles          cycle    2,423,130
    Average SMSP Active Cycles       cycle    78,621.21
    Total SMSP Elapsed Cycles        cycle    9,692,520
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       816.99
    Elapsed Cycles                cycle       80,919
    Memory Throughput                 %        72.83
    DRAM Throughput                   %        41.34
    Duration                         us        99.04
    L1/TEX Cache Throughput           %        74.82
    L2 Cache Throughput               %        29.13
    SM Active Cycles              cycle    78,728.93
    Compute (SM) Throughput           %        81.98
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.60
    Achieved Active Warps Per SM           warp        43.49
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,202.67
    Total DRAM Elapsed Cycles        cycle    3,558,400
    Average L1 Active Cycles         cycle    78,728.93
    Total L1 Elapsed Cycles          cycle    2,426,490
    Average L2 Active Cycles         cycle    72,792.46
    Total L2 Elapsed Cycles          cycle    1,817,280
    Average SM Active Cycles         cycle    78,728.93
    Total SM Elapsed Cycles          cycle    2,426,490
    Average SMSP Active Cycles       cycle    78,743.10
    Total SMSP Elapsed Cycles        cycle    9,705,960
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.19
    Elapsed Cycles                cycle       80,990
    Memory Throughput                 %        72.87
    DRAM Throughput                   %        41.29
    Duration                         us        99.10
    L1/TEX Cache Throughput           %        74.75
    L2 Cache Throughput               %        29.09
    SM Active Cycles              cycle    78,806.23
    Compute (SM) Throughput           %        82.01
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.70
    Achieved Active Warps Per SM           warp        43.54
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,074.67
    Total DRAM Elapsed Cycles        cycle    3,561,472
    Average L1 Active Cycles         cycle    78,806.23
    Total L1 Elapsed Cycles          cycle    2,425,330
    Average L2 Active Cycles         cycle    72,932.33
    Total L2 Elapsed Cycles          cycle    1,818,840
    Average SM Active Cycles         cycle    78,806.23
    Total SM Elapsed Cycles          cycle    2,425,330
    Average SMSP Active Cycles       cycle    78,655.12
    Total SMSP Elapsed Cycles        cycle    9,701,320
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.86
    SM Frequency                    Mhz       797.61
    Elapsed Cycles                cycle        3,091
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.33
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       428.50
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.22
    Achieved Active Warps Per SM           warp         5.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.78%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        74.67
    Total DRAM Elapsed Cycles        cycle      136,192
    Average L1 Active Cycles         cycle       428.50
    Total L1 Elapsed Cycles          cycle       88,960
    Average L2 Active Cycles         cycle       226.75
    Total L2 Elapsed Cycles          cycle       69,360
    Average SM Active Cycles         cycle       428.50
    Total SM Elapsed Cycles          cycle       88,960
    Average SMSP Active Cycles       cycle       304.81
    Total SMSP Elapsed Cycles        cycle      355,840
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.756%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.51% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.876%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.63% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.756%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.51% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.29
    Elapsed Cycles                cycle       80,897
    Memory Throughput                 %        72.90
    DRAM Throughput                   %        41.30
    Duration                         us        98.98
    L1/TEX Cache Throughput           %        74.82
    L2 Cache Throughput               %        29.11
    SM Active Cycles              cycle    78,729.40
    Compute (SM) Throughput           %        82.04
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.63
    Achieved Active Warps Per SM           warp        43.50
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,816
    Total DRAM Elapsed Cycles        cycle    3,556,352
    Average L1 Active Cycles         cycle    78,729.40
    Total L1 Elapsed Cycles          cycle    2,424,180
    Average L2 Active Cycles         cycle    72,835.88
    Total L2 Elapsed Cycles          cycle    1,816,512
    Average SM Active Cycles         cycle    78,729.40
    Total SM Elapsed Cycles          cycle    2,424,180
    Average SMSP Active Cycles       cycle    78,645.21
    Total SMSP Elapsed Cycles        cycle    9,696,720
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.16
    Elapsed Cycles                cycle       80,857
    Memory Throughput                 %        73.00
    DRAM Throughput                   %        41.35
    Duration                         us        98.94
    L1/TEX Cache Throughput           %        74.80
    L2 Cache Throughput               %        29.16
    SM Active Cycles              cycle    78,755.97
    Compute (SM) Throughput           %        82.14
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.67
    Achieved Active Warps Per SM           warp        43.52
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,013.33
    Total DRAM Elapsed Cycles        cycle    3,555,328
    Average L1 Active Cycles         cycle    78,755.97
    Total L1 Elapsed Cycles          cycle    2,420,880
    Average L2 Active Cycles         cycle    72,866.58
    Total L2 Elapsed Cycles          cycle    1,815,840
    Average SM Active Cycles         cycle    78,755.97
    Total SM Elapsed Cycles          cycle    2,420,880
    Average SMSP Active Cycles       cycle    78,723.65
    Total SMSP Elapsed Cycles        cycle    9,683,520
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.87
    SM Frequency                    Mhz       799.37
    Elapsed Cycles                cycle        3,046
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.32
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.89
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       415.83
    Compute (SM) Throughput           %         0.51
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.02
    Achieved Active Warps Per SM           warp         5.29
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.98%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           72
    Total DRAM Elapsed Cycles        cycle      134,144
    Average L1 Active Cycles         cycle       415.83
    Total L1 Elapsed Cycles          cycle       90,050
    Average L2 Active Cycles         cycle          234
    Total L2 Elapsed Cycles          cycle       68,352
    Average SM Active Cycles         cycle       415.83
    Total SM Elapsed Cycles          cycle       90,050
    Average SMSP Active Cycles       cycle       294.71
    Total SMSP Elapsed Cycles        cycle      360,200
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.325%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.31% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.659%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.01% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.325%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.31% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.38
    Elapsed Cycles                cycle       80,801
    Memory Throughput                 %        72.86
    DRAM Throughput                   %        41.53
    Duration                         us        98.85
    L1/TEX Cache Throughput           %        74.87
    L2 Cache Throughput               %        29.13
    SM Active Cycles              cycle    78,676.63
    Compute (SM) Throughput           %        81.97
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.56
    Achieved Active Warps Per SM           warp        43.47
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,954.67
    Total DRAM Elapsed Cycles        cycle    3,553,280
    Average L1 Active Cycles         cycle    78,676.63
    Total L1 Elapsed Cycles          cycle    2,425,380
    Average L2 Active Cycles         cycle       72,861
    Total L2 Elapsed Cycles          cycle    1,814,376
    Average SM Active Cycles         cycle    78,676.63
    Total SM Elapsed Cycles          cycle    2,425,380
    Average SMSP Active Cycles       cycle    78,740.92
    Total SMSP Elapsed Cycles        cycle    9,701,520
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.87
    SM Frequency                    Mhz       800.07
    Elapsed Cycles                cycle        3,047
    Memory Throughput                 %         0.90
    DRAM Throughput                   %         0.37
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.85
    L2 Cache Throughput               %         0.90
    SM Active Cycles              cycle       420.87
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.08
    Achieved Active Warps Per SM           warp         5.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.92%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        82.67
    Total DRAM Elapsed Cycles        cycle      134,144
    Average L1 Active Cycles         cycle       420.87
    Total L1 Elapsed Cycles          cycle       90,180
    Average L2 Active Cycles         cycle       236.58
    Total L2 Elapsed Cycles          cycle       68,424
    Average SM Active Cycles         cycle       420.87
    Total SM Elapsed Cycles          cycle       90,180
    Average SMSP Active Cycles       cycle       293.05
    Total SMSP Elapsed Cycles        cycle      360,720
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.465%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.60% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.519%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.12% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.465%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.60% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.17
    Elapsed Cycles                cycle       80,936
    Memory Throughput                 %        72.94
    DRAM Throughput                   %        41.52
    Duration                         us        99.04
    L1/TEX Cache Throughput           %        74.90
    L2 Cache Throughput               %        29.09
    SM Active Cycles              cycle    78,645.70
    Compute (SM) Throughput           %        82.04
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.68
    Achieved Active Warps Per SM           warp        43.53
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,333.33
    Total DRAM Elapsed Cycles        cycle    3,559,424
    Average L1 Active Cycles         cycle    78,645.70
    Total L1 Elapsed Cycles          cycle    2,422,980
    Average L2 Active Cycles         cycle    72,815.96
    Total L2 Elapsed Cycles          cycle    1,817,664
    Average SM Active Cycles         cycle    78,645.70
    Total SM Elapsed Cycles          cycle    2,422,980
    Average SMSP Active Cycles       cycle    78,708.27
    Total SMSP Elapsed Cycles        cycle    9,691,920
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.81
    SM Frequency                    Mhz       798.50
    Elapsed Cycles                cycle        3,118
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.39
    Duration                         us         3.90
    L1/TEX Cache Throughput           %         2.84
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       423.27
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.05
    Achieved Active Warps Per SM           warp         5.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.95%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           88
    Total DRAM Elapsed Cycles        cycle      136,192
    Average L1 Active Cycles         cycle       423.27
    Total L1 Elapsed Cycles          cycle       91,380
    Average L2 Active Cycles         cycle       211.04
    Total L2 Elapsed Cycles          cycle       70,032
    Average SM Active Cycles         cycle       423.27
    Total SM Elapsed Cycles          cycle       91,380
    Average SMSP Active Cycles       cycle       303.29
    Total SMSP Elapsed Cycles        cycle      365,520
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.389%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.57% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.654%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.87% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.389%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.57% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.22
    Elapsed Cycles                cycle       80,890
    Memory Throughput                 %        72.89
    DRAM Throughput                   %        41.30
    Duration                         us        98.98
    L1/TEX Cache Throughput           %        74.86
    L2 Cache Throughput               %        29.15
    SM Active Cycles              cycle    78,692.43
    Compute (SM) Throughput           %        81.96
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.59
    Achieved Active Warps Per SM           warp        43.48
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,890.67
    Total DRAM Elapsed Cycles        cycle    3,557,376
    Average L1 Active Cycles         cycle    78,692.43
    Total L1 Elapsed Cycles          cycle    2,424,660
    Average L2 Active Cycles         cycle    72,829.08
    Total L2 Elapsed Cycles          cycle    1,816,560
    Average SM Active Cycles         cycle    78,692.43
    Total SM Elapsed Cycles          cycle    2,424,660
    Average SMSP Active Cycles       cycle    78,621.10
    Total SMSP Elapsed Cycles        cycle    9,698,640
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.91
    SM Frequency                    Mhz       801.65
    Elapsed Cycles                cycle        3,104
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.31
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.82
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       424.90
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.94
    Achieved Active Warps Per SM           warp         5.25
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.06%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           72
    Total DRAM Elapsed Cycles        cycle      137,216
    Average L1 Active Cycles         cycle       424.90
    Total L1 Elapsed Cycles          cycle       90,870
    Average L2 Active Cycles         cycle       235.67
    Total L2 Elapsed Cycles          cycle       69,768
    Average SM Active Cycles         cycle       424.90
    Total SM Elapsed Cycles          cycle       90,870
    Average SMSP Active Cycles       cycle       299.07
    Total SMSP Elapsed Cycles        cycle      363,480
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.812%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 69.95% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.678%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.76% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.812%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 69.95% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.43
    Elapsed Cycles                cycle       80,963
    Memory Throughput                 %        73.06
    DRAM Throughput                   %        41.26
    Duration                         us        99.04
    L1/TEX Cache Throughput           %        74.79
    L2 Cache Throughput               %        29.08
    SM Active Cycles              cycle    78,767.17
    Compute (SM) Throughput           %        82.14
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.56
    Achieved Active Warps Per SM           warp        43.47
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,757.33
    Total DRAM Elapsed Cycles        cycle    3,559,424
    Average L1 Active Cycles         cycle    78,767.17
    Total L1 Elapsed Cycles          cycle    2,419,050
    Average L2 Active Cycles         cycle    72,780.67
    Total L2 Elapsed Cycles          cycle    1,818,072
    Average SM Active Cycles         cycle    78,767.17
    Total SM Elapsed Cycles          cycle    2,419,050
    Average SMSP Active Cycles       cycle    78,666.82
    Total SMSP Elapsed Cycles        cycle    9,676,200
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.41
    Elapsed Cycles                cycle       80,751
    Memory Throughput                 %        72.92
    DRAM Throughput                   %        41.39
    Duration                         us        98.78
    L1/TEX Cache Throughput           %        74.80
    L2 Cache Throughput               %        29.17
    SM Active Cycles              cycle    78,751.27
    Compute (SM) Throughput           %        81.97
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.51
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,962.67
    Total DRAM Elapsed Cycles        cycle    3,551,232
    Average L1 Active Cycles         cycle    78,751.27
    Total L1 Elapsed Cycles          cycle    2,423,470
    Average L2 Active Cycles         cycle    72,804.58
    Total L2 Elapsed Cycles          cycle    1,813,464
    Average SM Active Cycles         cycle    78,751.27
    Total SM Elapsed Cycles          cycle    2,423,470
    Average SMSP Active Cycles       cycle    78,642.30
    Total SMSP Elapsed Cycles        cycle    9,693,880
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.27
    Elapsed Cycles                cycle       81,026
    Memory Throughput                 %        72.88
    DRAM Throughput                   %        41.30
    Duration                         us        99.14
    L1/TEX Cache Throughput           %        74.92
    L2 Cache Throughput               %        29.07
    SM Active Cycles              cycle       78,624
    Compute (SM) Throughput           %        81.89
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.58
    Achieved Active Warps Per SM           warp        43.48
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,197.33
    Total DRAM Elapsed Cycles        cycle    3,562,496
    Average L1 Active Cycles         cycle       78,624
    Total L1 Elapsed Cycles          cycle    2,425,040
    Average L2 Active Cycles         cycle    72,796.29
    Total L2 Elapsed Cycles          cycle    1,819,632
    Average SM Active Cycles         cycle       78,624
    Total SM Elapsed Cycles          cycle    2,425,040
    Average SMSP Active Cycles       cycle    78,586.05
    Total SMSP Elapsed Cycles        cycle    9,700,160
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.21
    Elapsed Cycles                cycle       80,786
    Memory Throughput                 %        73.13
    DRAM Throughput                   %        41.37
    Duration                         us        98.85
    L1/TEX Cache Throughput           %        74.99
    L2 Cache Throughput               %        29.17
    SM Active Cycles              cycle    78,557.90
    Compute (SM) Throughput           %        82.15
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.57
    Achieved Active Warps Per SM           warp        43.48
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,917.33
    Total DRAM Elapsed Cycles        cycle    3,552,256
    Average L1 Active Cycles         cycle    78,557.90
    Total L1 Elapsed Cycles          cycle    2,416,640
    Average L2 Active Cycles         cycle    72,827.92
    Total L2 Elapsed Cycles          cycle    1,814,064
    Average SM Active Cycles         cycle    78,557.90
    Total SM Elapsed Cycles          cycle    2,416,640
    Average SMSP Active Cycles       cycle    78,525.06
    Total SMSP Elapsed Cycles        cycle    9,666,560
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.14
    Elapsed Cycles                cycle       80,909
    Memory Throughput                 %        72.89
    DRAM Throughput                   %        41.27
    Duration                         us        99.01
    L1/TEX Cache Throughput           %        74.80
    L2 Cache Throughput               %        29.12
    SM Active Cycles              cycle    78,751.67
    Compute (SM) Throughput           %        81.87
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.54
    Achieved Active Warps Per SM           warp        43.46
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,701.33
    Total DRAM Elapsed Cycles        cycle    3,557,376
    Average L1 Active Cycles         cycle    78,751.67
    Total L1 Elapsed Cycles          cycle    2,424,400
    Average L2 Active Cycles         cycle    72,731.50
    Total L2 Elapsed Cycles          cycle    1,817,064
    Average SM Active Cycles         cycle    78,751.67
    Total SM Elapsed Cycles          cycle    2,424,400
    Average SMSP Active Cycles       cycle    78,598.50
    Total SMSP Elapsed Cycles        cycle    9,697,600
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.55
    Elapsed Cycles                cycle       80,739
    Memory Throughput                 %        72.84
    DRAM Throughput                   %        41.43
    Duration                         us        98.75
    L1/TEX Cache Throughput           %        74.85
    L2 Cache Throughput               %        29.17
    SM Active Cycles              cycle    78,703.67
    Compute (SM) Throughput           %        81.79
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.56
    Achieved Active Warps Per SM           warp        43.47
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,042.67
    Total DRAM Elapsed Cycles        cycle    3,549,184
    Average L1 Active Cycles         cycle    78,703.67
    Total L1 Elapsed Cycles          cycle    2,426,090
    Average L2 Active Cycles         cycle    72,763.83
    Total L2 Elapsed Cycles          cycle    1,812,984
    Average SM Active Cycles         cycle    78,703.67
    Total SM Elapsed Cycles          cycle    2,426,090
    Average SMSP Active Cycles       cycle    78,501.84
    Total SMSP Elapsed Cycles        cycle    9,704,360
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.06
    Elapsed Cycles                cycle       80,744
    Memory Throughput                 %        72.98
    DRAM Throughput                   %        41.38
    Duration                         us        98.82
    L1/TEX Cache Throughput           %        74.89
    L2 Cache Throughput               %        29.19
    SM Active Cycles              cycle    78,657.80
    Compute (SM) Throughput           %        81.92
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.58
    Achieved Active Warps Per SM           warp        43.48
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,861.33
    Total DRAM Elapsed Cycles        cycle    3,550,208
    Average L1 Active Cycles         cycle    78,657.80
    Total L1 Elapsed Cycles          cycle    2,421,700
    Average L2 Active Cycles         cycle       72,728
    Total L2 Elapsed Cycles          cycle    1,813,200
    Average SM Active Cycles         cycle    78,657.80
    Total SM Elapsed Cycles          cycle    2,421,700
    Average SMSP Active Cycles       cycle    78,474.68
    Total SMSP Elapsed Cycles        cycle    9,686,800
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.82
    SM Frequency                    Mhz       797.40
    Elapsed Cycles                cycle        3,063
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.35
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.76
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       434.30
    Compute (SM) Throughput           %         0.50
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.59
    Achieved Active Warps Per SM           warp         5.08
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.41%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      134,144
    Average L1 Active Cycles         cycle       434.30
    Total L1 Elapsed Cycles          cycle       90,870
    Average L2 Active Cycles         cycle       218.83
    Total L2 Elapsed Cycles          cycle       68,784
    Average SM Active Cycles         cycle       434.30
    Total SM Elapsed Cycles          cycle       90,870
    Average SMSP Active Cycles       cycle       290.18
    Total SMSP Elapsed Cycles        cycle      363,480
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.729%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.85% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.398%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.22% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.729%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.85% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.017%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 65.70% above the average, while the minimum instance value is 83.09% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.37
    Elapsed Cycles                cycle       80,825
    Memory Throughput                 %        72.95
    DRAM Throughput                   %        41.41
    Duration                         us        98.88
    L1/TEX Cache Throughput           %        74.93
    L2 Cache Throughput               %        29.14
    SM Active Cycles              cycle    78,620.40
    Compute (SM) Throughput           %        81.86
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.57
    Achieved Active Warps Per SM           warp        43.47
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,237.33
    Total DRAM Elapsed Cycles        cycle    3,553,280
    Average L1 Active Cycles         cycle    78,620.40
    Total L1 Elapsed Cycles          cycle    2,422,580
    Average L2 Active Cycles         cycle    72,844.21
    Total L2 Elapsed Cycles          cycle    1,814,952
    Average SM Active Cycles         cycle    78,620.40
    Total SM Elapsed Cycles          cycle    2,422,580
    Average SMSP Active Cycles       cycle    78,604.54
    Total SMSP Elapsed Cycles        cycle    9,690,320
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.91
    SM Frequency                    Mhz       803.21
    Elapsed Cycles                cycle        3,086
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.40
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.86
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       418.90
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.04
    Achieved Active Warps Per SM           warp         5.30
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.96%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        90.67
    Total DRAM Elapsed Cycles        cycle      136,192
    Average L1 Active Cycles         cycle       418.90
    Total L1 Elapsed Cycles          cycle       90,060
    Average L2 Active Cycles         cycle       192.79
    Total L2 Elapsed Cycles          cycle       69,312
    Average SM Active Cycles         cycle       418.90
    Total SM Elapsed Cycles          cycle       90,060
    Average SMSP Active Cycles       cycle       293.76
    Total SMSP Elapsed Cycles        cycle      360,240
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.602%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 68.81% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.611%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.78% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.602%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 68.81% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.39
    Elapsed Cycles                cycle       81,011
    Memory Throughput                 %        73.08
    DRAM Throughput                   %        41.44
    Duration                         us        99.10
    L1/TEX Cache Throughput           %        74.97
    L2 Cache Throughput               %        29.12
    SM Active Cycles              cycle    78,572.23
    Compute (SM) Throughput           %        81.98
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.52
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,997.33
    Total DRAM Elapsed Cycles        cycle    3,561,472
    Average L1 Active Cycles         cycle    78,572.23
    Total L1 Elapsed Cycles          cycle    2,418,230
    Average L2 Active Cycles         cycle    72,843.67
    Total L2 Elapsed Cycles          cycle    1,819,152
    Average SM Active Cycles         cycle    78,572.23
    Total SM Elapsed Cycles          cycle    2,418,230
    Average SMSP Active Cycles       cycle    78,447.11
    Total SMSP Elapsed Cycles        cycle    9,672,920
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.48
    Elapsed Cycles                cycle       80,784
    Memory Throughput                 %        73.04
    DRAM Throughput                   %        41.62
    Duration                         us        98.82
    L1/TEX Cache Throughput           %        74.96
    L2 Cache Throughput               %        29.19
    SM Active Cycles              cycle    78,589.87
    Compute (SM) Throughput           %        81.91
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.51
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,434.67
    Total DRAM Elapsed Cycles        cycle    3,552,256
    Average L1 Active Cycles         cycle    78,589.87
    Total L1 Elapsed Cycles          cycle    2,419,650
    Average L2 Active Cycles         cycle    72,731.71
    Total L2 Elapsed Cycles          cycle    1,814,232
    Average SM Active Cycles         cycle    78,589.87
    Total SM Elapsed Cycles          cycle    2,419,650
    Average SMSP Active Cycles       cycle    78,474.67
    Total SMSP Elapsed Cycles        cycle    9,678,600
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.87
    SM Frequency                    Mhz       800.25
    Elapsed Cycles                cycle        3,048
    Memory Throughput                 %         0.89
    DRAM Throughput                   %         0.37
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.81
    L2 Cache Throughput               %         0.89
    SM Active Cycles              cycle       427.50
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.25
    Achieved Active Warps Per SM           warp         5.40
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.75%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        82.67
    Total DRAM Elapsed Cycles        cycle      134,144
    Average L1 Active Cycles         cycle       427.50
    Total L1 Elapsed Cycles          cycle       89,280
    Average L2 Active Cycles         cycle       238.25
    Total L2 Elapsed Cycles          cycle       68,448
    Average SM Active Cycles         cycle       427.50
    Total SM Elapsed Cycles          cycle       89,280
    Average SMSP Active Cycles       cycle       304.53
    Total SMSP Elapsed Cycles        cycle      357,120
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.748%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.86% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.861%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.82% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.748%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.86% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.128%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 61.39% above the average, while the minimum instance value is 84.47% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.33
    Elapsed Cycles                cycle       80,795
    Memory Throughput                 %        73.11
    DRAM Throughput                   %        41.38
    Duration                         us        98.85
    L1/TEX Cache Throughput           %        74.91
    L2 Cache Throughput               %        29.17
    SM Active Cycles              cycle    78,643.67
    Compute (SM) Throughput           %        81.96
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.54
    Achieved Active Warps Per SM           warp        43.46
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,061.33
    Total DRAM Elapsed Cycles        cycle    3,553,280
    Average L1 Active Cycles         cycle    78,643.67
    Total L1 Elapsed Cycles          cycle    2,417,320
    Average L2 Active Cycles         cycle    72,772.67
    Total L2 Elapsed Cycles          cycle    1,814,232
    Average SM Active Cycles         cycle    78,643.67
    Total SM Elapsed Cycles          cycle    2,417,320
    Average SMSP Active Cycles       cycle    78,479.38
    Total SMSP Elapsed Cycles        cycle    9,669,280
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.92
    SM Frequency                    Mhz       803.66
    Elapsed Cycles                cycle        3,062
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.34
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.70
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       443.73
    Compute (SM) Throughput           %         0.52
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.87
    Achieved Active Warps Per SM           warp         5.22
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.13%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      135,168
    Average L1 Active Cycles         cycle       443.73
    Total L1 Elapsed Cycles          cycle       89,240
    Average L2 Active Cycles         cycle       226.71
    Total L2 Elapsed Cycles          cycle       68,760
    Average SM Active Cycles         cycle       443.73
    Total SM Elapsed Cycles          cycle       89,240
    Average SMSP Active Cycles       cycle       303.27
    Total SMSP Elapsed Cycles        cycle      356,960
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.19%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 68.28% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.815%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.65% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.19%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 68.28% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.127%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 64.80% above the average, while the minimum instance value is 83.68% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.28
    Elapsed Cycles                cycle       80,817
    Memory Throughput                 %        73.00
    DRAM Throughput                   %        41.37
    Duration                         us        98.88
    L1/TEX Cache Throughput           %        75.03
    L2 Cache Throughput               %        29.15
    SM Active Cycles              cycle    78,509.67
    Compute (SM) Throughput           %        81.80
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.49
    Achieved Active Warps Per SM           warp        43.44
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,010.67
    Total DRAM Elapsed Cycles        cycle    3,553,280
    Average L1 Active Cycles         cycle    78,509.67
    Total L1 Elapsed Cycles          cycle    2,421,000
    Average L2 Active Cycles         cycle    72,754.71
    Total L2 Elapsed Cycles          cycle    1,814,784
    Average SM Active Cycles         cycle    78,509.67
    Total SM Elapsed Cycles          cycle    2,421,000
    Average SMSP Active Cycles       cycle    78,437.50
    Total SMSP Elapsed Cycles        cycle    9,684,000
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.27
    Elapsed Cycles                cycle       80,738
    Memory Throughput                 %        73.09
    DRAM Throughput                   %        41.49
    Duration                         us        98.78
    L1/TEX Cache Throughput           %        74.98
    L2 Cache Throughput               %        29.20
    SM Active Cycles              cycle    78,563.07
    Compute (SM) Throughput           %        81.87
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.55
    Achieved Active Warps Per SM           warp        43.46
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,514.67
    Total DRAM Elapsed Cycles        cycle    3,550,208
    Average L1 Active Cycles         cycle    78,563.07
    Total L1 Elapsed Cycles          cycle    2,417,790
    Average L2 Active Cycles         cycle    72,681.08
    Total L2 Elapsed Cycles          cycle    1,813,152
    Average SM Active Cycles         cycle    78,563.07
    Total SM Elapsed Cycles          cycle    2,417,790
    Average SMSP Active Cycles       cycle    78,427.88
    Total SMSP Elapsed Cycles        cycle    9,671,160
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.87
    SM Frequency                    Mhz       799.72
    Elapsed Cycles                cycle        3,048
    Memory Throughput                 %         0.90
    DRAM Throughput                   %         0.35
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.78
    L2 Cache Throughput               %         0.90
    SM Active Cycles              cycle       431.63
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.34
    Achieved Active Warps Per SM           warp         5.44
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.66%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      134,144
    Average L1 Active Cycles         cycle       431.63
    Total L1 Elapsed Cycles          cycle       89,670
    Average L2 Active Cycles         cycle       264.75
    Total L2 Elapsed Cycles          cycle       68,376
    Average SM Active Cycles         cycle       431.63
    Total SM Elapsed Cycles          cycle       89,670
    Average SMSP Active Cycles       cycle       293.20
    Total SMSP Elapsed Cycles        cycle      358,680
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.729%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.37% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.527%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.73% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.729%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.37% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.32
    Elapsed Cycles                cycle       80,741
    Memory Throughput                 %        73.13
    DRAM Throughput                   %        41.43
    Duration                         us        98.78
    L1/TEX Cache Throughput           %        75.03
    L2 Cache Throughput               %        29.20
    SM Active Cycles              cycle    78,511.93
    Compute (SM) Throughput           %        81.88
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.47
    Achieved Active Warps Per SM           warp        43.43
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,165.33
    Total DRAM Elapsed Cycles        cycle    3,550,208
    Average L1 Active Cycles         cycle    78,511.93
    Total L1 Elapsed Cycles          cycle    2,416,460
    Average L2 Active Cycles         cycle    72,630.29
    Total L2 Elapsed Cycles          cycle    1,813,128
    Average SM Active Cycles         cycle    78,511.93
    Total SM Elapsed Cycles          cycle    2,416,460
    Average SMSP Active Cycles       cycle    78,375.73
    Total SMSP Elapsed Cycles        cycle    9,665,840
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.48
    Elapsed Cycles                cycle       80,835
    Memory Throughput                 %        73.12
    DRAM Throughput                   %        41.53
    Duration                         us        98.88
    L1/TEX Cache Throughput           %        75.12
    L2 Cache Throughput               %        28.89
    SM Active Cycles              cycle    78,414.93
    Compute (SM) Throughput           %        81.83
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.49
    Achieved Active Warps Per SM           warp        43.44
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,042.67
    Total DRAM Elapsed Cycles        cycle    3,554,304
    Average L1 Active Cycles         cycle    78,414.93
    Total L1 Elapsed Cycles          cycle    2,416,850
    Average L2 Active Cycles         cycle    73,348.04
    Total L2 Elapsed Cycles          cycle    1,833,120
    Average SM Active Cycles         cycle    78,414.93
    Total SM Elapsed Cycles          cycle    2,416,850
    Average SMSP Active Cycles       cycle       78,343
    Total SMSP Elapsed Cycles        cycle    9,667,400
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.41
    Elapsed Cycles                cycle       80,752
    Memory Throughput                 %        73.10
    DRAM Throughput                   %        41.41
    Duration                         us        98.78
    L1/TEX Cache Throughput           %        75.08
    L2 Cache Throughput               %        28.85
    SM Active Cycles              cycle    78,458.50
    Compute (SM) Throughput           %        81.75
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.46
    Achieved Active Warps Per SM           warp        43.42
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,109.33
    Total DRAM Elapsed Cycles        cycle    3,551,232
    Average L1 Active Cycles         cycle    78,458.50
    Total L1 Elapsed Cycles          cycle    2,417,510
    Average L2 Active Cycles         cycle    73,249.54
    Total L2 Elapsed Cycles          cycle    1,831,224
    Average SM Active Cycles         cycle    78,458.50
    Total SM Elapsed Cycles          cycle    2,417,510
    Average SMSP Active Cycles       cycle    78,374.86
    Total SMSP Elapsed Cycles        cycle    9,670,040
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.28
    Elapsed Cycles                cycle       80,529
    Memory Throughput                 %        73.00
    DRAM Throughput                   %        41.52
    Duration                         us        98.53
    L1/TEX Cache Throughput           %        75.14
    L2 Cache Throughput               %        28.98
    SM Active Cycles              cycle    78,394.90
    Compute (SM) Throughput           %        81.59
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.46
    Achieved Active Warps Per SM           warp        43.42
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,058.67
    Total DRAM Elapsed Cycles        cycle    3,540,992
    Average L1 Active Cycles         cycle    78,394.90
    Total L1 Elapsed Cycles          cycle    2,420,990
    Average L2 Active Cycles         cycle    73,260.21
    Total L2 Elapsed Cycles          cycle    1,826,160
    Average SM Active Cycles         cycle    78,394.90
    Total SM Elapsed Cycles          cycle    2,420,990
    Average SMSP Active Cycles       cycle    78,325.18
    Total SMSP Elapsed Cycles        cycle    9,683,960
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.15
    Elapsed Cycles                cycle       80,543
    Memory Throughput                 %        73.25
    DRAM Throughput                   %        41.45
    Duration                         us        98.56
    L1/TEX Cache Throughput           %        75.16
    L2 Cache Throughput               %        28.98
    SM Active Cycles              cycle    78,376.23
    Compute (SM) Throughput           %        81.82
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.48
    Achieved Active Warps Per SM           warp        43.43
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,704
    Total DRAM Elapsed Cycles        cycle    3,542,016
    Average L1 Active Cycles         cycle    78,376.23
    Total L1 Elapsed Cycles          cycle    2,412,710
    Average L2 Active Cycles         cycle    73,247.96
    Total L2 Elapsed Cycles          cycle    1,826,184
    Average SM Active Cycles         cycle    78,376.23
    Total SM Elapsed Cycles          cycle    2,412,710
    Average SMSP Active Cycles       cycle    78,246.98
    Total SMSP Elapsed Cycles        cycle    9,650,840
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.88
    SM Frequency                    Mhz       801.01
    Elapsed Cycles                cycle        3,002
    Memory Throughput                 %         0.89
    DRAM Throughput                   %         0.35
    Duration                         us         3.74
    L1/TEX Cache Throughput           %         2.85
    L2 Cache Throughput               %         0.89
    SM Active Cycles              cycle       420.50
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.10
    Achieved Active Warps Per SM           warp         5.33
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.9%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      132,096
    Average L1 Active Cycles         cycle       420.50
    Total L1 Elapsed Cycles          cycle       90,380
    Average L2 Active Cycles         cycle       237.17
    Total L2 Elapsed Cycles          cycle       68,064
    Average SM Active Cycles         cycle       420.50
    Total SM Elapsed Cycles          cycle       90,380
    Average SMSP Active Cycles       cycle       294.79
    Total SMSP Elapsed Cycles        cycle      361,520
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.494%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 68.02% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.642%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.10% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.494%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 68.02% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.24
    Elapsed Cycles                cycle       80,577
    Memory Throughput                 %        73.09
    DRAM Throughput                   %        41.62
    Duration                         us        98.59
    L1/TEX Cache Throughput           %        75.16
    L2 Cache Throughput               %        28.95
    SM Active Cycles              cycle    78,377.23
    Compute (SM) Throughput           %        81.60
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.42
    Achieved Active Warps Per SM           warp        43.40
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,792
    Total DRAM Elapsed Cycles        cycle    3,543,040
    Average L1 Active Cycles         cycle    78,377.23
    Total L1 Elapsed Cycles          cycle    2,417,780
    Average L2 Active Cycles         cycle    73,213.92
    Total L2 Elapsed Cycles          cycle    1,827,240
    Average SM Active Cycles         cycle    78,377.23
    Total SM Elapsed Cycles          cycle    2,417,780
    Average SMSP Active Cycles       cycle    78,263.14
    Total SMSP Elapsed Cycles        cycle    9,671,120
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.21
    Elapsed Cycles                cycle       80,416
    Memory Throughput                 %        73.39
    DRAM Throughput                   %        41.75
    Duration                         us        98.40
    L1/TEX Cache Throughput           %        75.24
    L2 Cache Throughput               %        29.03
    SM Active Cycles              cycle    78,298.20
    Compute (SM) Throughput           %        81.88
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.41
    Achieved Active Warps Per SM           warp        43.40
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,037.33
    Total DRAM Elapsed Cycles        cycle    3,535,872
    Average L1 Active Cycles         cycle    78,298.20
    Total L1 Elapsed Cycles          cycle    2,407,980
    Average L2 Active Cycles         cycle    73,171.33
    Total L2 Elapsed Cycles          cycle    1,823,688
    Average SM Active Cycles         cycle    78,298.20
    Total SM Elapsed Cycles          cycle    2,407,980
    Average SMSP Active Cycles       cycle    78,252.34
    Total SMSP Elapsed Cycles        cycle    9,631,920
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.35
    Elapsed Cycles                cycle       80,433
    Memory Throughput                 %        73.19
    DRAM Throughput                   %        41.73
    Duration                         us        98.40
    L1/TEX Cache Throughput           %        75.25
    L2 Cache Throughput               %        29.02
    SM Active Cycles              cycle    78,284.57
    Compute (SM) Throughput           %        81.61
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.42
    Achieved Active Warps Per SM           warp        43.40
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      246,056
    Total DRAM Elapsed Cycles        cycle    3,537,920
    Average L1 Active Cycles         cycle    78,284.57
    Total L1 Elapsed Cycles          cycle    2,414,590
    Average L2 Active Cycles         cycle    73,211.46
    Total L2 Elapsed Cycles          cycle    1,823,856
    Average SM Active Cycles         cycle    78,284.57
    Total SM Elapsed Cycles          cycle    2,414,590
    Average SMSP Active Cycles       cycle    78,235.69
    Total SMSP Elapsed Cycles        cycle    9,658,360
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       795.11
    Elapsed Cycles                cycle        3,005
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.36
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.84
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       422.57
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.96
    Achieved Active Warps Per SM           warp         5.26
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.04%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      132,096
    Average L1 Active Cycles         cycle       422.57
    Total L1 Elapsed Cycles          cycle       90,600
    Average L2 Active Cycles         cycle       216.71
    Total L2 Elapsed Cycles          cycle       68,160
    Average SM Active Cycles         cycle       422.57
    Total SM Elapsed Cycles          cycle       90,600
    Average SMSP Active Cycles       cycle       298.27
    Total SMSP Elapsed Cycles        cycle      362,400
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.533%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 68.13% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.605%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.00% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.533%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 68.13% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.25
    Elapsed Cycles                cycle       80,448
    Memory Throughput                 %        73.22
    DRAM Throughput                   %        41.53
    Duration                         us        98.43
    L1/TEX Cache Throughput           %        75.24
    L2 Cache Throughput               %        29.02
    SM Active Cycles              cycle    78,294.20
    Compute (SM) Throughput           %        81.59
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.40
    Achieved Active Warps Per SM           warp        43.39
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,856
    Total DRAM Elapsed Cycles        cycle    3,537,920
    Average L1 Active Cycles         cycle    78,294.20
    Total L1 Elapsed Cycles          cycle    2,413,700
    Average L2 Active Cycles         cycle    73,126.50
    Total L2 Elapsed Cycles          cycle    1,824,096
    Average SM Active Cycles         cycle    78,294.20
    Total SM Elapsed Cycles          cycle    2,413,700
    Average SMSP Active Cycles       cycle    78,239.23
    Total SMSP Elapsed Cycles        cycle    9,654,800
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.36
    Elapsed Cycles                cycle       80,509
    Memory Throughput                 %        73.32
    DRAM Throughput                   %        41.54
    Duration                         us        98.50
    L1/TEX Cache Throughput           %        75.27
    L2 Cache Throughput               %        28.98
    SM Active Cycles              cycle    78,260.97
    Compute (SM) Throughput           %        81.65
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.45
    Achieved Active Warps Per SM           warp        43.41
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,005.33
    Total DRAM Elapsed Cycles        cycle    3,538,944
    Average L1 Active Cycles         cycle    78,260.97
    Total L1 Elapsed Cycles          cycle    2,410,240
    Average L2 Active Cycles         cycle    73,148.08
    Total L2 Elapsed Cycles          cycle    1,825,776
    Average SM Active Cycles         cycle    78,260.97
    Total SM Elapsed Cycles          cycle    2,410,240
    Average SMSP Active Cycles       cycle    78,091.93
    Total SMSP Elapsed Cycles        cycle    9,640,960
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.91
    SM Frequency                    Mhz       799.41
    Elapsed Cycles                cycle        3,098
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.34
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       427.93
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.24
    Achieved Active Warps Per SM           warp         5.39
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.76%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      137,216
    Average L1 Active Cycles         cycle       427.93
    Total L1 Elapsed Cycles          cycle       88,380
    Average L2 Active Cycles         cycle       209.96
    Total L2 Elapsed Cycles          cycle       70,248
    Average SM Active Cycles         cycle       427.93
    Total SM Elapsed Cycles          cycle       88,380
    Average SMSP Active Cycles       cycle       306.98
    Total SMSP Elapsed Cycles        cycle      353,520
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.834%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.70% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.08%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.54% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.834%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.70% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.46
    Elapsed Cycles                cycle       80,417
    Memory Throughput                 %        73.47
    DRAM Throughput                   %        41.58
    Duration                         us        98.37
    L1/TEX Cache Throughput           %        75.30
    L2 Cache Throughput               %        28.99
    SM Active Cycles              cycle    78,230.43
    Compute (SM) Throughput           %        81.75
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.39
    Achieved Active Warps Per SM           warp        43.39
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,024
    Total DRAM Elapsed Cycles        cycle    3,535,872
    Average L1 Active Cycles         cycle    78,230.43
    Total L1 Elapsed Cycles          cycle    2,405,300
    Average L2 Active Cycles         cycle    73,080.83
    Total L2 Elapsed Cycles          cycle    1,823,472
    Average SM Active Cycles         cycle    78,230.43
    Total SM Elapsed Cycles          cycle    2,405,300
    Average SMSP Active Cycles       cycle    78,122.93
    Total SMSP Elapsed Cycles        cycle    9,621,200
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.34
    Elapsed Cycles                cycle       80,456
    Memory Throughput                 %        73.40
    DRAM Throughput                   %        41.55
    Duration                         us        98.43
    L1/TEX Cache Throughput           %        75.33
    L2 Cache Throughput               %        29.01
    SM Active Cycles              cycle    78,197.93
    Compute (SM) Throughput           %        81.62
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.45
    Achieved Active Warps Per SM           warp        43.42
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,013.33
    Total DRAM Elapsed Cycles        cycle    3,537,920
    Average L1 Active Cycles         cycle    78,197.93
    Total L1 Elapsed Cycles          cycle    2,407,570
    Average L2 Active Cycles         cycle    73,097.33
    Total L2 Elapsed Cycles          cycle    1,824,456
    Average SM Active Cycles         cycle    78,197.93
    Total SM Elapsed Cycles          cycle    2,407,570
    Average SMSP Active Cycles       cycle    78,062.48
    Total SMSP Elapsed Cycles        cycle    9,630,280
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.82
    SM Frequency                    Mhz       796.92
    Elapsed Cycles                cycle        3,087
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.34
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.88
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       417.37
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.06
    Achieved Active Warps Per SM           warp         5.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.94%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      135,168
    Average L1 Active Cycles         cycle       417.37
    Total L1 Elapsed Cycles          cycle       89,400
    Average L2 Active Cycles         cycle       218.25
    Total L2 Elapsed Cycles          cycle       70,008
    Average SM Active Cycles         cycle       417.37
    Total SM Elapsed Cycles          cycle       89,400
    Average SMSP Active Cycles       cycle       293.49
    Total SMSP Elapsed Cycles        cycle      357,600
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.449%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.47% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.7%                                                                                            
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.18% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.449%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.47% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.34
    Elapsed Cycles                cycle       80,301
    Memory Throughput                 %        73.61
    DRAM Throughput                   %        41.61
    Duration                         us        98.24
    L1/TEX Cache Throughput           %        75.34
    L2 Cache Throughput               %        29.07
    SM Active Cycles              cycle    78,190.17
    Compute (SM) Throughput           %        81.79
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.37
    Achieved Active Warps Per SM           warp        43.38
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,869.33
    Total DRAM Elapsed Cycles        cycle    3,530,752
    Average L1 Active Cycles         cycle    78,190.17
    Total L1 Elapsed Cycles          cycle    2,400,840
    Average L2 Active Cycles         cycle    72,964.04
    Total L2 Elapsed Cycles          cycle    1,820,928
    Average SM Active Cycles         cycle    78,190.17
    Total SM Elapsed Cycles          cycle    2,400,840
    Average SMSP Active Cycles       cycle    78,192.97
    Total SMSP Elapsed Cycles        cycle    9,603,360
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.02
    Elapsed Cycles                cycle       80,269
    Memory Throughput                 %        73.59
    DRAM Throughput                   %        41.62
    Duration                         us        98.24
    L1/TEX Cache Throughput           %        75.47
    L2 Cache Throughput               %        29.07
    SM Active Cycles              cycle    78,058.47
    Compute (SM) Throughput           %        81.71
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.38
    Achieved Active Warps Per SM           warp        43.38
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,864
    Total DRAM Elapsed Cycles        cycle    3,529,728
    Average L1 Active Cycles         cycle    78,058.47
    Total L1 Elapsed Cycles          cycle    2,401,470
    Average L2 Active Cycles         cycle    72,927.50
    Total L2 Elapsed Cycles          cycle    1,820,256
    Average SM Active Cycles         cycle    78,058.47
    Total SM Elapsed Cycles          cycle    2,401,470
    Average SMSP Active Cycles       cycle    77,944.20
    Total SMSP Elapsed Cycles        cycle    9,605,880
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.23
    Elapsed Cycles                cycle       80,290
    Memory Throughput                 %        73.60
    DRAM Throughput                   %        41.69
    Duration                         us        98.24
    L1/TEX Cache Throughput           %        75.44
    L2 Cache Throughput               %        29.07
    SM Active Cycles              cycle    78,084.73
    Compute (SM) Throughput           %        81.67
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.33
    Achieved Active Warps Per SM           warp        43.36
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,346.67
    Total DRAM Elapsed Cycles        cycle    3,530,752
    Average L1 Active Cycles         cycle    78,084.73
    Total L1 Elapsed Cycles          cycle    2,401,020
    Average L2 Active Cycles         cycle    72,974.29
    Total L2 Elapsed Cycles          cycle    1,820,616
    Average SM Active Cycles         cycle    78,084.73
    Total SM Elapsed Cycles          cycle    2,401,020
    Average SMSP Active Cycles       cycle    77,992.23
    Total SMSP Elapsed Cycles        cycle    9,604,080
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.88
    SM Frequency                    Mhz       801.11
    Elapsed Cycles                cycle        3,027
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.38
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.85
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       420.73
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.00
    Achieved Active Warps Per SM           warp         5.28
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89%                                                                                       
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        85.33
    Total DRAM Elapsed Cycles        cycle      133,120
    Average L1 Active Cycles         cycle       420.73
    Total L1 Elapsed Cycles          cycle       89,800
    Average L2 Active Cycles         cycle       214.54
    Total L2 Elapsed Cycles          cycle       68,592
    Average SM Active Cycles         cycle       420.73
    Total SM Elapsed Cycles          cycle       89,800
    Average SMSP Active Cycles       cycle       292.95
    Total SMSP Elapsed Cycles        cycle      359,200
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.548%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.93% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.54%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.04% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.548%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.93% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.114%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 68.12% above the average, while the minimum instance value is 82.75% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.15
    Elapsed Cycles                cycle       80,280
    Memory Throughput                 %        73.52
    DRAM Throughput                   %        41.79
    Duration                         us        98.24
    L1/TEX Cache Throughput           %        75.49
    L2 Cache Throughput               %        29.07
    SM Active Cycles              cycle    78,032.30
    Compute (SM) Throughput           %        81.51
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.42
    Achieved Active Warps Per SM           warp        43.40
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,909.33
    Total DRAM Elapsed Cycles        cycle    3,530,752
    Average L1 Active Cycles         cycle    78,032.30
    Total L1 Elapsed Cycles          cycle    2,403,680
    Average L2 Active Cycles         cycle    72,978.92
    Total L2 Elapsed Cycles          cycle    1,820,352
    Average SM Active Cycles         cycle    78,032.30
    Total SM Elapsed Cycles          cycle    2,403,680
    Average SMSP Active Cycles       cycle    77,965.68
    Total SMSP Elapsed Cycles        cycle    9,614,720
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.88
    SM Frequency                    Mhz       797.40
    Elapsed Cycles                cycle        3,011
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.37
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.86
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       420.03
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.10
    Achieved Active Warps Per SM           warp         5.33
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.9%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        82.67
    Total DRAM Elapsed Cycles        cycle      133,120
    Average L1 Active Cycles         cycle       420.03
    Total L1 Elapsed Cycles          cycle       90,630
    Average L2 Active Cycles         cycle       254.83
    Total L2 Elapsed Cycles          cycle       68,328
    Average SM Active Cycles         cycle       420.03
    Total SM Elapsed Cycles          cycle       90,630
    Average SMSP Active Cycles       cycle       293.48
    Total SMSP Elapsed Cycles        cycle      362,520
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.422%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.76% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.51%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.30% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.422%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.76% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.678%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 63.44% above the average, while the minimum instance value is 85.48% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.35
    Elapsed Cycles                cycle       80,196
    Memory Throughput                 %        73.54
    DRAM Throughput                   %        41.65
    Duration                         us        98.11
    L1/TEX Cache Throughput           %        75.45
    L2 Cache Throughput               %        29.11
    SM Active Cycles              cycle    78,071.17
    Compute (SM) Throughput           %        81.45
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.30
    Achieved Active Warps Per SM           warp        43.35
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,816
    Total DRAM Elapsed Cycles        cycle    3,526,656
    Average L1 Active Cycles         cycle    78,071.17
    Total L1 Elapsed Cycles          cycle    2,403,260
    Average L2 Active Cycles         cycle    72,871.92
    Total L2 Elapsed Cycles          cycle    1,818,624
    Average SM Active Cycles         cycle    78,071.17
    Total SM Elapsed Cycles          cycle    2,403,260
    Average SMSP Active Cycles       cycle    77,918.11
    Total SMSP Elapsed Cycles        cycle    9,613,040
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       797.62
    Elapsed Cycles                cycle        3,039
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.35
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.89
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       415.63
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.08
    Achieved Active Warps Per SM           warp         5.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.92%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      133,120
    Average L1 Active Cycles         cycle       415.63
    Total L1 Elapsed Cycles          cycle       90,020
    Average L2 Active Cycles         cycle       233.75
    Total L2 Elapsed Cycles          cycle       68,832
    Average SM Active Cycles         cycle       415.63
    Total SM Elapsed Cycles          cycle       90,020
    Average SMSP Active Cycles       cycle       300.81
    Total SMSP Elapsed Cycles        cycle      360,080
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.392%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.81% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.74%                                                                                           
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.21% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.392%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.81% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.259%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 64.53% above the average, while the minimum instance value is 84.17% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.33
    Elapsed Cycles                cycle       80,194
    Memory Throughput                 %        73.49
    DRAM Throughput                   %        41.76
    Duration                         us        98.11
    L1/TEX Cache Throughput           %        75.45
    L2 Cache Throughput               %        29.10
    SM Active Cycles              cycle    78,077.27
    Compute (SM) Throughput           %        81.33
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.28
    Achieved Active Warps Per SM           warp        43.34
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,437.33
    Total DRAM Elapsed Cycles        cycle    3,526,656
    Average L1 Active Cycles         cycle    78,077.27
    Total L1 Elapsed Cycles          cycle    2,404,900
    Average L2 Active Cycles         cycle    72,969.42
    Total L2 Elapsed Cycles          cycle    1,818,504
    Average SM Active Cycles         cycle    78,077.27
    Total SM Elapsed Cycles          cycle    2,404,900
    Average SMSP Active Cycles       cycle    77,930.18
    Total SMSP Elapsed Cycles        cycle    9,619,600
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.88
    SM Frequency                    Mhz       802.53
    Elapsed Cycles                cycle        3,006
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.36
    Duration                         us         3.74
    L1/TEX Cache Throughput           %         2.86
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       419.33
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.09
    Achieved Active Warps Per SM           warp         5.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.91%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      132,096
    Average L1 Active Cycles         cycle       419.33
    Total L1 Elapsed Cycles          cycle       90,550
    Average L2 Active Cycles         cycle       203.25
    Total L2 Elapsed Cycles          cycle       68,160
    Average SM Active Cycles         cycle       419.33
    Total SM Elapsed Cycles          cycle       90,550
    Average SMSP Active Cycles       cycle       295.26
    Total SMSP Elapsed Cycles        cycle      362,200
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.412%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.74% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.536%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.04% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.412%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.74% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.54
    Elapsed Cycles                cycle       80,110
    Memory Throughput                 %        73.73
    DRAM Throughput                   %        41.85
    Duration                         us        97.98
    L1/TEX Cache Throughput           %        75.55
    L2 Cache Throughput               %        29.15
    SM Active Cycles              cycle    77,970.93
    Compute (SM) Throughput           %        81.52
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.16
    Achieved Active Warps Per SM           warp        43.28
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,696
    Total DRAM Elapsed Cycles        cycle    3,522,560
    Average L1 Active Cycles         cycle    77,970.93
    Total L1 Elapsed Cycles          cycle    2,396,770
    Average L2 Active Cycles         cycle    72,803.38
    Total L2 Elapsed Cycles          cycle    1,816,560
    Average SM Active Cycles         cycle    77,970.93
    Total SM Elapsed Cycles          cycle    2,396,770
    Average SMSP Active Cycles       cycle    77,865.62
    Total SMSP Elapsed Cycles        cycle    9,587,080
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.42
    Elapsed Cycles                cycle       80,099
    Memory Throughput                 %        73.58
    DRAM Throughput                   %        41.75
    Duration                         us        97.98
    L1/TEX Cache Throughput           %        75.73
    L2 Cache Throughput               %        29.08
    SM Active Cycles              cycle    77,784.57
    Compute (SM) Throughput           %        81.28
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.27
    Achieved Active Warps Per SM           warp        43.33
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,066.67
    Total DRAM Elapsed Cycles        cycle    3,521,536
    Average L1 Active Cycles         cycle    77,784.57
    Total L1 Elapsed Cycles          cycle    2,401,750
    Average L2 Active Cycles         cycle    72,803.83
    Total L2 Elapsed Cycles          cycle    1,816,392
    Average SM Active Cycles         cycle    77,784.57
    Total SM Elapsed Cycles          cycle    2,401,750
    Average SMSP Active Cycles       cycle    77,841.25
    Total SMSP Elapsed Cycles        cycle    9,607,000
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.92
    SM Frequency                    Mhz       800.60
    Elapsed Cycles                cycle        3,049
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.34
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       428.93
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.21
    Achieved Active Warps Per SM           warp         5.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.79%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      135,168
    Average L1 Active Cycles         cycle       428.93
    Total L1 Elapsed Cycles          cycle       90,870
    Average L2 Active Cycles         cycle       234.79
    Total L2 Elapsed Cycles          cycle       69,096
    Average SM Active Cycles         cycle       428.93
    Total SM Elapsed Cycles          cycle       90,870
    Average SMSP Active Cycles       cycle       305.53
    Total SMSP Elapsed Cycles        cycle      363,480
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.587%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.70% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.887%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.19% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.587%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.70% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.16
    Elapsed Cycles                cycle       79,968
    Memory Throughput                 %        73.75
    DRAM Throughput                   %        41.78
    Duration                         us        97.86
    L1/TEX Cache Throughput           %        75.65
    L2 Cache Throughput               %        29.18
    SM Active Cycles              cycle    77,868.17
    Compute (SM) Throughput           %        81.39
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.20
    Achieved Active Warps Per SM           warp        43.30
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,784
    Total DRAM Elapsed Cycles        cycle    3,515,392
    Average L1 Active Cycles         cycle    77,868.17
    Total L1 Elapsed Cycles          cycle    2,396,150
    Average L2 Active Cycles         cycle    72,779.12
    Total L2 Elapsed Cycles          cycle    1,813,416
    Average SM Active Cycles         cycle    77,868.17
    Total SM Elapsed Cycles          cycle    2,396,150
    Average SMSP Active Cycles       cycle    77,707.46
    Total SMSP Elapsed Cycles        cycle    9,584,600
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.30
    Elapsed Cycles                cycle       80,164
    Memory Throughput                 %        73.52
    DRAM Throughput                   %        41.95
    Duration                         us        98.08
    L1/TEX Cache Throughput           %        75.70
    L2 Cache Throughput               %        29.10
    SM Active Cycles              cycle    77,818.17
    Compute (SM) Throughput           %        81.05
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.17
    Achieved Active Warps Per SM           warp        43.28
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,418.67
    Total DRAM Elapsed Cycles        cycle    3,524,608
    Average L1 Active Cycles         cycle    77,818.17
    Total L1 Elapsed Cycles          cycle    2,403,800
    Average L2 Active Cycles         cycle    72,760.71
    Total L2 Elapsed Cycles          cycle    1,817,928
    Average SM Active Cycles         cycle    77,818.17
    Total SM Elapsed Cycles          cycle    2,403,800
    Average SMSP Active Cycles       cycle    77,900.64
    Total SMSP Elapsed Cycles        cycle    9,615,200
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.20
    Elapsed Cycles                cycle       79,999
    Memory Throughput                 %        73.50
    DRAM Throughput                   %        41.96
    Duration                         us        97.89
    L1/TEX Cache Throughput           %        75.69
    L2 Cache Throughput               %        29.18
    SM Active Cycles              cycle    77,829.47
    Compute (SM) Throughput           %        80.95
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.16
    Achieved Active Warps Per SM           warp        43.28
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,997.33
    Total DRAM Elapsed Cycles        cycle    3,517,440
    Average L1 Active Cycles         cycle    77,829.47
    Total L1 Elapsed Cycles          cycle    2,404,460
    Average L2 Active Cycles         cycle    72,731.79
    Total L2 Elapsed Cycles          cycle    1,814,064
    Average SM Active Cycles         cycle    77,829.47
    Total SM Elapsed Cycles          cycle    2,404,460
    Average SMSP Active Cycles       cycle    77,716.97
    Total SMSP Elapsed Cycles        cycle    9,617,840
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.26
    Elapsed Cycles                cycle       79,768
    Memory Throughput                 %        73.93
    DRAM Throughput                   %        42.07
    Duration                         us        97.60
    L1/TEX Cache Throughput           %        75.81
    L2 Cache Throughput               %        29.26
    SM Active Cycles              cycle    77,708.80
    Compute (SM) Throughput           %        81.34
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.15
    Achieved Active Warps Per SM           warp        43.27
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      246,008
    Total DRAM Elapsed Cycles        cycle    3,508,224
    Average L1 Active Cycles         cycle    77,708.80
    Total L1 Elapsed Cycles          cycle    2,390,540
    Average L2 Active Cycles         cycle    72,611.21
    Total L2 Elapsed Cycles          cycle    1,808,856
    Average SM Active Cycles         cycle    77,708.80
    Total SM Elapsed Cycles          cycle    2,390,540
    Average SMSP Active Cycles       cycle    77,626.18
    Total SMSP Elapsed Cycles        cycle    9,562,160
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.53
    Elapsed Cycles                cycle       80,031
    Memory Throughput                 %        73.73
    DRAM Throughput                   %        41.92
    Duration                         us        97.89
    L1/TEX Cache Throughput           %        75.84
    L2 Cache Throughput               %        29.16
    SM Active Cycles              cycle    77,670.97
    Compute (SM) Throughput           %        81.04
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.08
    Achieved Active Warps Per SM           warp        43.24
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,914.67
    Total DRAM Elapsed Cycles        cycle    3,519,488
    Average L1 Active Cycles         cycle    77,670.97
    Total L1 Elapsed Cycles          cycle    2,396,990
    Average L2 Active Cycles         cycle    72,691.58
    Total L2 Elapsed Cycles          cycle    1,814,856
    Average SM Active Cycles         cycle    77,670.97
    Total SM Elapsed Cycles          cycle    2,396,990
    Average SMSP Active Cycles       cycle    77,599.08
    Total SMSP Elapsed Cycles        cycle    9,587,960
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.86
    SM Frequency                    Mhz       795.45
    Elapsed Cycles                cycle        3,081
    Memory Throughput                 %         0.97
    DRAM Throughput                   %         0.36
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.97
    SM Active Cycles              cycle       428.80
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.22
    Achieved Active Warps Per SM           warp         5.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.78%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        82.67
    Total DRAM Elapsed Cycles        cycle      136,192
    Average L1 Active Cycles         cycle       428.80
    Total L1 Elapsed Cycles          cycle       89,960
    Average L2 Active Cycles         cycle       238.50
    Total L2 Elapsed Cycles          cycle       69,912
    Average SM Active Cycles         cycle       428.80
    Total SM Elapsed Cycles          cycle       89,960
    Average SMSP Active Cycles       cycle       303.39
    Total SMSP Elapsed Cycles        cycle      359,840
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.626%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.32% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.731%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.41% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.626%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.32% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.41
    Elapsed Cycles                cycle       79,863
    Memory Throughput                 %        73.61
    DRAM Throughput                   %        41.83
    Duration                         us        97.70
    L1/TEX Cache Throughput           %        75.84
    L2 Cache Throughput               %        29.22
    SM Active Cycles              cycle    77,673.83
    Compute (SM) Throughput           %        80.83
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.09
    Achieved Active Warps Per SM           warp        43.24
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,773.33
    Total DRAM Elapsed Cycles        cycle    3,511,296
    Average L1 Active Cycles         cycle    77,673.83
    Total L1 Elapsed Cycles          cycle    2,400,850
    Average L2 Active Cycles         cycle    72,615.67
    Total L2 Elapsed Cycles          cycle    1,810,944
    Average SM Active Cycles         cycle    77,673.83
    Total SM Elapsed Cycles          cycle    2,400,850
    Average SMSP Active Cycles       cycle    77,515.32
    Total SMSP Elapsed Cycles        cycle    9,603,400
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.87
    SM Frequency                    Mhz       798.35
    Elapsed Cycles                cycle        3,067
    Memory Throughput                 %         0.89
    DRAM Throughput                   %         0.37
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.79
    L2 Cache Throughput               %         0.89
    SM Active Cycles              cycle       429.63
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.12
    Achieved Active Warps Per SM           warp         5.34
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.88%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        82.67
    Total DRAM Elapsed Cycles        cycle      135,168
    Average L1 Active Cycles         cycle       429.63
    Total L1 Elapsed Cycles          cycle       88,410
    Average L2 Active Cycles         cycle       234.75
    Total L2 Elapsed Cycles          cycle       69,576
    Average SM Active Cycles         cycle       429.63
    Total SM Elapsed Cycles          cycle       88,410
    Average SMSP Active Cycles       cycle       303.94
    Total SMSP Elapsed Cycles        cycle      353,640
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.88%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.77% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.913%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.73% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.88%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.77% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.28
    Elapsed Cycles                cycle       79,824
    Memory Throughput                 %        74.03
    DRAM Throughput                   %        41.90
    Duration                         us        97.66
    L1/TEX Cache Throughput           %        75.84
    L2 Cache Throughput               %        29.23
    SM Active Cycles              cycle    77,675.43
    Compute (SM) Throughput           %        81.22
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.05
    Achieved Active Warps Per SM           warp        43.23
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,085.33
    Total DRAM Elapsed Cycles        cycle    3,509,248
    Average L1 Active Cycles         cycle    77,675.43
    Total L1 Elapsed Cycles          cycle    2,387,140
    Average L2 Active Cycles         cycle    72,593.46
    Total L2 Elapsed Cycles          cycle    1,810,080
    Average SM Active Cycles         cycle    77,675.43
    Total SM Elapsed Cycles          cycle    2,387,140
    Average SMSP Active Cycles       cycle    77,513.92
    Total SMSP Elapsed Cycles        cycle    9,548,560
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.27
    Elapsed Cycles                cycle       80,031
    Memory Throughput                 %        73.75
    DRAM Throughput                   %        41.78
    Duration                         us        97.92
    L1/TEX Cache Throughput           %        75.81
    L2 Cache Throughput               %        29.15
    SM Active Cycles              cycle    77,702.90
    Compute (SM) Throughput           %        80.83
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.12
    Achieved Active Warps Per SM           warp        43.26
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,058.67
    Total DRAM Elapsed Cycles        cycle    3,519,488
    Average L1 Active Cycles         cycle    77,702.90
    Total L1 Elapsed Cycles          cycle    2,396,330
    Average L2 Active Cycles         cycle    72,608.25
    Total L2 Elapsed Cycles          cycle    1,814,808
    Average SM Active Cycles         cycle    77,702.90
    Total SM Elapsed Cycles          cycle    2,396,330
    Average SMSP Active Cycles       cycle    77,518.54
    Total SMSP Elapsed Cycles        cycle    9,585,320
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.10
    Elapsed Cycles                cycle       79,752
    Memory Throughput                 %        73.67
    DRAM Throughput                   %        41.90
    Duration                         us        97.60
    L1/TEX Cache Throughput           %        75.87
    L2 Cache Throughput               %        29.24
    SM Active Cycles              cycle    77,645.40
    Compute (SM) Throughput           %        80.66
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.93
    Achieved Active Warps Per SM           warp        43.17
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.07%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,840
    Total DRAM Elapsed Cycles        cycle    3,506,176
    Average L1 Active Cycles         cycle    77,645.40
    Total L1 Elapsed Cycles          cycle    2,399,030
    Average L2 Active Cycles         cycle    72,494.29
    Total L2 Elapsed Cycles          cycle    1,808,568
    Average SM Active Cycles         cycle    77,645.40
    Total SM Elapsed Cycles          cycle    2,399,030
    Average SMSP Active Cycles       cycle    77,496.52
    Total SMSP Elapsed Cycles        cycle    9,596,120
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.44
    Elapsed Cycles                cycle       79,943
    Memory Throughput                 %        73.96
    DRAM Throughput                   %        41.89
    Duration                         us        97.79
    L1/TEX Cache Throughput           %        75.98
    L2 Cache Throughput               %        29.17
    SM Active Cycles              cycle    77,529.23
    Compute (SM) Throughput           %        80.92
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.99
    Achieved Active Warps Per SM           warp        43.20
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.01%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (90.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,389.33
    Total DRAM Elapsed Cycles        cycle    3,514,368
    Average L1 Active Cycles         cycle    77,529.23
    Total L1 Elapsed Cycles          cycle    2,389,380
    Average L2 Active Cycles         cycle    72,462.25
    Total L2 Elapsed Cycles          cycle    1,812,912
    Average SM Active Cycles         cycle    77,529.23
    Total SM Elapsed Cycles          cycle    2,389,380
    Average SMSP Active Cycles       cycle    77,471.46
    Total SMSP Elapsed Cycles        cycle    9,557,520
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       793.17
    Elapsed Cycles                cycle        3,001
    Memory Throughput                 %         0.89
    DRAM Throughput                   %         0.35
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.87
    L2 Cache Throughput               %         0.89
    SM Active Cycles              cycle       417.67
    Compute (SM) Throughput           %         0.50
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.92
    Achieved Active Warps Per SM           warp         5.24
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.08%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      132,096
    Average L1 Active Cycles         cycle       417.67
    Total L1 Elapsed Cycles          cycle       90,160
    Average L2 Active Cycles         cycle       234.67
    Total L2 Elapsed Cycles          cycle       68,016
    Average SM Active Cycles         cycle       417.67
    Total SM Elapsed Cycles          cycle       90,160
    Average SMSP Active Cycles       cycle       294.58
    Total SMSP Elapsed Cycles        cycle      360,640
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.398%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.62% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.654%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.08% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.398%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.62% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.45
    Elapsed Cycles                cycle       79,578
    Memory Throughput                 %        74.01
    DRAM Throughput                   %        42.00
    Duration                         us        97.34
    L1/TEX Cache Throughput           %        76.03
    L2 Cache Throughput               %        29.33
    SM Active Cycles              cycle       77,483
    Compute (SM) Throughput           %        80.88
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.91
    Achieved Active Warps Per SM           warp        43.16
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.09%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,933.33
    Total DRAM Elapsed Cycles        cycle    3,499,008
    Average L1 Active Cycles         cycle       77,483
    Total L1 Elapsed Cycles          cycle    2,387,990
    Average L2 Active Cycles         cycle    72,477.29
    Total L2 Elapsed Cycles          cycle    1,804,392
    Average SM Active Cycles         cycle       77,483
    Total SM Elapsed Cycles          cycle    2,387,990
    Average SMSP Active Cycles       cycle    77,467.82
    Total SMSP Elapsed Cycles        cycle    9,551,960
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.10
    Elapsed Cycles                cycle       79,622
    Memory Throughput                 %        73.94
    DRAM Throughput                   %        41.98
    Duration                         us        97.44
    L1/TEX Cache Throughput           %        76.13
    L2 Cache Throughput               %        29.28
    SM Active Cycles              cycle    77,376.17
    Compute (SM) Throughput           %        80.72
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.95
    Achieved Active Warps Per SM           warp        43.18
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.05%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,042.67
    Total DRAM Elapsed Cycles        cycle    3,502,080
    Average L1 Active Cycles         cycle    77,376.17
    Total L1 Elapsed Cycles          cycle    2,390,220
    Average L2 Active Cycles         cycle    72,418.79
    Total L2 Elapsed Cycles          cycle    1,805,664
    Average SM Active Cycles         cycle    77,376.17
    Total SM Elapsed Cycles          cycle    2,390,220
    Average SMSP Active Cycles       cycle    77,356.09
    Total SMSP Elapsed Cycles        cycle    9,560,880
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.53
    Elapsed Cycles                cycle       79,535
    Memory Throughput                 %        74.22
    DRAM Throughput                   %        42.22
    Duration                         us        97.28
    L1/TEX Cache Throughput           %        76.09
    L2 Cache Throughput               %        29.26
    SM Active Cycles              cycle    77,415.77
    Compute (SM) Throughput           %        80.93
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.91
    Achieved Active Warps Per SM           warp        43.16
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.09%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      246,064
    Total DRAM Elapsed Cycles        cycle    3,496,960
    Average L1 Active Cycles         cycle    77,415.77
    Total L1 Elapsed Cycles          cycle    2,381,170
    Average L2 Active Cycles         cycle    72,404.83
    Total L2 Elapsed Cycles          cycle    1,803,528
    Average SM Active Cycles         cycle    77,415.77
    Total SM Elapsed Cycles          cycle    2,381,170
    Average SMSP Active Cycles       cycle    77,358.61
    Total SMSP Elapsed Cycles        cycle    9,524,680
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.30
    Elapsed Cycles                cycle       79,772
    Memory Throughput                 %        74.17
    DRAM Throughput                   %        42.07
    Duration                         us        97.60
    L1/TEX Cache Throughput           %        76.08
    L2 Cache Throughput               %        29.26
    SM Active Cycles              cycle    77,429.40
    Compute (SM) Throughput           %        80.80
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.80
    Achieved Active Warps Per SM           warp        43.11
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.2%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,968
    Total DRAM Elapsed Cycles        cycle    3,508,224
    Average L1 Active Cycles         cycle    77,429.40
    Total L1 Elapsed Cycles          cycle    2,382,570
    Average L2 Active Cycles         cycle    72,496.25
    Total L2 Elapsed Cycles          cycle    1,809,120
    Average SM Active Cycles         cycle    77,429.40
    Total SM Elapsed Cycles          cycle    2,382,570
    Average SMSP Active Cycles       cycle    77,405.60
    Total SMSP Elapsed Cycles        cycle    9,530,280
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.31
    Elapsed Cycles                cycle       79,405
    Memory Throughput                 %        74.16
    DRAM Throughput                   %        42.26
    Duration                         us        97.15
    L1/TEX Cache Throughput           %        76.07
    L2 Cache Throughput               %        29.39
    SM Active Cycles              cycle    77,439.67
    Compute (SM) Throughput           %        80.70
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.79
    Achieved Active Warps Per SM           warp        43.10
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.21%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,997.33
    Total DRAM Elapsed Cycles        cycle    3,492,864
    Average L1 Active Cycles         cycle    77,439.67
    Total L1 Elapsed Cycles          cycle    2,383,000
    Average L2 Active Cycles         cycle    72,317.71
    Total L2 Elapsed Cycles          cycle    1,800,600
    Average SM Active Cycles         cycle    77,439.67
    Total SM Elapsed Cycles          cycle    2,383,000
    Average SMSP Active Cycles       cycle    77,278.51
    Total SMSP Elapsed Cycles        cycle    9,532,000
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.24
    Elapsed Cycles                cycle       79,583
    Memory Throughput                 %        74.07
    DRAM Throughput                   %        42.19
    Duration                         us        97.38
    L1/TEX Cache Throughput           %        76.14
    L2 Cache Throughput               %        29.32
    SM Active Cycles              cycle    77,364.03
    Compute (SM) Throughput           %        80.52
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.76
    Achieved Active Warps Per SM           warp        43.08
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.24%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,138.67
    Total DRAM Elapsed Cycles        cycle    3,500,032
    Average L1 Active Cycles         cycle    77,364.03
    Total L1 Elapsed Cycles          cycle    2,386,080
    Average L2 Active Cycles         cycle    72,286.46
    Total L2 Elapsed Cycles          cycle    1,804,632
    Average SM Active Cycles         cycle    77,364.03
    Total SM Elapsed Cycles          cycle    2,386,080
    Average SMSP Active Cycles       cycle    77,328.44
    Total SMSP Elapsed Cycles        cycle    9,544,320
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       798.55
    Elapsed Cycles                cycle        3,017
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.42
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       428.83
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.21
    Achieved Active Warps Per SM           warp         5.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.79%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        93.33
    Total DRAM Elapsed Cycles        cycle      132,096
    Average L1 Active Cycles         cycle       428.83
    Total L1 Elapsed Cycles          cycle       89,590
    Average L2 Active Cycles         cycle       208.58
    Total L2 Elapsed Cycles          cycle       68,376
    Average SM Active Cycles         cycle       428.83
    Total SM Elapsed Cycles          cycle       89,590
    Average SMSP Active Cycles       cycle       331.92
    Total SMSP Elapsed Cycles        cycle      358,360
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.695%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.51% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.457%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.09% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.695%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.51% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.24
    Elapsed Cycles                cycle       79,532
    Memory Throughput                 %        74.23
    DRAM Throughput                   %        42.01
    Duration                         us        97.31
    L1/TEX Cache Throughput           %        76.08
    L2 Cache Throughput               %        29.33
    SM Active Cycles              cycle    77,426.70
    Compute (SM) Throughput           %        80.61
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.62
    Achieved Active Warps Per SM           warp        43.02
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.38%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,872
    Total DRAM Elapsed Cycles        cycle    3,496,960
    Average L1 Active Cycles         cycle    77,426.70
    Total L1 Elapsed Cycles          cycle    2,380,900
    Average L2 Active Cycles         cycle    72,217.04
    Total L2 Elapsed Cycles          cycle    1,803,576
    Average SM Active Cycles         cycle    77,426.70
    Total SM Elapsed Cycles          cycle    2,380,900
    Average SMSP Active Cycles       cycle    77,205.07
    Total SMSP Elapsed Cycles        cycle    9,523,600
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.87
    SM Frequency                    Mhz       799.05
    Elapsed Cycles                cycle        3,070
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.34
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.79
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       430.10
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.17
    Achieved Active Warps Per SM           warp         5.36
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.83%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      135,168
    Average L1 Active Cycles         cycle       430.10
    Total L1 Elapsed Cycles          cycle       88,920
    Average L2 Active Cycles         cycle       228.33
    Total L2 Elapsed Cycles          cycle       69,624
    Average SM Active Cycles         cycle       430.10
    Total SM Elapsed Cycles          cycle       88,920
    Average SMSP Active Cycles       cycle       329.12
    Total SMSP Elapsed Cycles        cycle      355,680
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.808%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.59% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.461%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.20% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.808%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.59% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.37
    Elapsed Cycles                cycle       79,544
    Memory Throughput                 %        74.17
    DRAM Throughput                   %        42.03
    Duration                         us        97.31
    L1/TEX Cache Throughput           %        76.19
    L2 Cache Throughput               %        29.30
    SM Active Cycles              cycle    77,313.83
    Compute (SM) Throughput           %        80.45
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.66
    Achieved Active Warps Per SM           warp        43.03
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.34%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,989.33
    Total DRAM Elapsed Cycles        cycle    3,496,960
    Average L1 Active Cycles         cycle    77,313.83
    Total L1 Elapsed Cycles          cycle    2,382,710
    Average L2 Active Cycles         cycle    72,254.33
    Total L2 Elapsed Cycles          cycle    1,803,792
    Average SM Active Cycles         cycle    77,313.83
    Total SM Elapsed Cycles          cycle    2,382,710
    Average SMSP Active Cycles       cycle    77,409.52
    Total SMSP Elapsed Cycles        cycle    9,530,840
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.82
    SM Frequency                    Mhz       797.14
    Elapsed Cycles                cycle        3,061
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.33
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.72
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       440.83
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.89
    Achieved Active Warps Per SM           warp         5.23
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.11%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        74.67
    Total DRAM Elapsed Cycles        cycle      134,144
    Average L1 Active Cycles         cycle       440.83
    Total L1 Elapsed Cycles          cycle       87,990
    Average L2 Active Cycles         cycle       237.92
    Total L2 Elapsed Cycles          cycle       69,480
    Average SM Active Cycles         cycle       440.83
    Total SM Elapsed Cycles          cycle       87,990
    Average SMSP Active Cycles       cycle       305.69
    Total SMSP Elapsed Cycles        cycle      351,960
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.23%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 68.08% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.977%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.54% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.23%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 68.08% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.43
    Elapsed Cycles                cycle       79,551
    Memory Throughput                 %        74.32
    DRAM Throughput                   %        41.96
    Duration                         us        97.31
    L1/TEX Cache Throughput           %        76.32
    L2 Cache Throughput               %        29.33
    SM Active Cycles              cycle    77,181.43
    Compute (SM) Throughput           %        80.53
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.58
    Achieved Active Warps Per SM           warp        43.00
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.42%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,608
    Total DRAM Elapsed Cycles        cycle    3,497,984
    Average L1 Active Cycles         cycle    77,181.43
    Total L1 Elapsed Cycles          cycle    2,377,760
    Average L2 Active Cycles         cycle    72,274.12
    Total L2 Elapsed Cycles          cycle    1,803,960
    Average SM Active Cycles         cycle    77,181.43
    Total SM Elapsed Cycles          cycle    2,377,760
    Average SMSP Active Cycles       cycle    77,232.61
    Total SMSP Elapsed Cycles        cycle    9,511,040
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       799.54
    Elapsed Cycles                cycle        3,046
    Memory Throughput                 %         0.91
    DRAM Throughput                   %         0.36
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.68
    L2 Cache Throughput               %         0.91
    SM Active Cycles              cycle       448.30
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.39
    Achieved Active Warps Per SM           warp         5.47
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.61%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      133,120
    Average L1 Active Cycles         cycle       448.30
    Total L1 Elapsed Cycles          cycle       89,250
    Average L2 Active Cycles         cycle       226.96
    Total L2 Elapsed Cycles          cycle       69,024
    Average SM Active Cycles         cycle       448.30
    Total SM Elapsed Cycles          cycle       89,250
    Average SMSP Active Cycles       cycle       303.06
    Total SMSP Elapsed Cycles        cycle      357,000
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.16%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.42% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.814%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.71% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.16%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.42% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.36
    Elapsed Cycles                cycle       79,439
    Memory Throughput                 %        74.30
    DRAM Throughput                   %        42.03
    Duration                         us        97.18
    L1/TEX Cache Throughput           %        76.18
    L2 Cache Throughput               %        29.38
    SM Active Cycles              cycle    77,328.57
    Compute (SM) Throughput           %        80.42
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.50
    Achieved Active Warps Per SM           warp        42.96
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.5%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,693.33
    Total DRAM Elapsed Cycles        cycle    3,492,864
    Average L1 Active Cycles         cycle    77,328.57
    Total L1 Elapsed Cycles          cycle    2,378,520
    Average L2 Active Cycles         cycle    72,256.83
    Total L2 Elapsed Cycles          cycle    1,801,416
    Average SM Active Cycles         cycle    77,328.57
    Total SM Elapsed Cycles          cycle    2,378,520
    Average SMSP Active Cycles       cycle    77,106.90
    Total SMSP Elapsed Cycles        cycle    9,514,080
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       799.08
    Elapsed Cycles                cycle        3,019
    Memory Throughput                 %         0.89
    DRAM Throughput                   %         0.40
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.89
    SM Active Cycles              cycle       428.57
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.22
    Achieved Active Warps Per SM           warp         5.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.78%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           88
    Total DRAM Elapsed Cycles        cycle      132,096
    Average L1 Active Cycles         cycle       428.57
    Total L1 Elapsed Cycles          cycle       87,920
    Average L2 Active Cycles         cycle       220.17
    Total L2 Elapsed Cycles          cycle       68,280
    Average SM Active Cycles         cycle       428.57
    Total SM Elapsed Cycles          cycle       87,920
    Average SMSP Active Cycles       cycle       304.13
    Total SMSP Elapsed Cycles        cycle      351,680
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.814%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.11% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.963%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.73% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.814%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.11% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.26
    Elapsed Cycles                cycle       79,219
    Memory Throughput                 %        74.23
    DRAM Throughput                   %        42.40
    Duration                         us        96.93
    L1/TEX Cache Throughput           %        76.33
    L2 Cache Throughput               %        29.41
    SM Active Cycles              cycle    77,175.97
    Compute (SM) Throughput           %        80.25
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.43
    Achieved Active Warps Per SM           warp        42.93
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.57%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      246,160
    Total DRAM Elapsed Cycles        cycle    3,483,648
    Average L1 Active Cycles         cycle    77,175.97
    Total L1 Elapsed Cycles          cycle    2,380,650
    Average L2 Active Cycles         cycle    72,264.83
    Total L2 Elapsed Cycles          cycle    1,796,520
    Average SM Active Cycles         cycle    77,175.97
    Total SM Elapsed Cycles          cycle    2,380,650
    Average SMSP Active Cycles       cycle    77,156.55
    Total SMSP Elapsed Cycles        cycle    9,522,600
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.40
    Elapsed Cycles                cycle       79,339
    Memory Throughput                 %        74.35
    DRAM Throughput                   %        42.33
    Duration                         us        97.06
    L1/TEX Cache Throughput           %        76.30
    L2 Cache Throughput               %        29.41
    SM Active Cycles              cycle    77,208.93
    Compute (SM) Throughput           %        80.29
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.46
    Achieved Active Warps Per SM           warp        42.94
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.54%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,069.33
    Total DRAM Elapsed Cycles        cycle    3,487,744
    Average L1 Active Cycles         cycle    77,208.93
    Total L1 Elapsed Cycles          cycle    2,376,870
    Average L2 Active Cycles         cycle    72,240.50
    Total L2 Elapsed Cycles          cycle    1,799,184
    Average SM Active Cycles         cycle    77,208.93
    Total SM Elapsed Cycles          cycle    2,376,870
    Average SMSP Active Cycles       cycle       77,229
    Total SMSP Elapsed Cycles        cycle    9,507,480
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.46
    Elapsed Cycles                cycle       79,187
    Memory Throughput                 %        74.23
    DRAM Throughput                   %        42.47
    Duration                         us        96.86
    L1/TEX Cache Throughput           %        76.45
    L2 Cache Throughput               %        29.46
    SM Active Cycles              cycle    77,058.83
    Compute (SM) Throughput           %        80.05
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.51
    Achieved Active Warps Per SM           warp        42.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.49%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,394.67
    Total DRAM Elapsed Cycles        cycle    3,480,576
    Average L1 Active Cycles         cycle    77,058.83
    Total L1 Elapsed Cycles          cycle    2,380,900
    Average L2 Active Cycles         cycle    72,075.96
    Total L2 Elapsed Cycles          cycle    1,795,728
    Average SM Active Cycles         cycle    77,058.83
    Total SM Elapsed Cycles          cycle    2,380,900
    Average SMSP Active Cycles       cycle    77,009.26
    Total SMSP Elapsed Cycles        cycle    9,523,600
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       796.88
    Elapsed Cycles                cycle        3,010
    Memory Throughput                 %         0.89
    DRAM Throughput                   %         0.35
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.77
    L2 Cache Throughput               %         0.89
    SM Active Cycles              cycle       433.30
    Compute (SM) Throughput           %         0.58
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.14
    Achieved Active Warps Per SM           warp         5.35
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.86%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      132,096
    Average L1 Active Cycles         cycle       433.30
    Total L1 Elapsed Cycles          cycle       87,710
    Average L2 Active Cycles         cycle       228.96
    Total L2 Elapsed Cycles          cycle       68,256
    Average SM Active Cycles         cycle       433.30
    Total SM Elapsed Cycles          cycle       87,710
    Average SMSP Active Cycles       cycle       304.72
    Total SMSP Elapsed Cycles        cycle      350,840
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.04%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.71% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.978%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.54% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.04%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.71% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.37
    Elapsed Cycles                cycle       79,387
    Memory Throughput                 %        74.46
    DRAM Throughput                   %        42.09
    Duration                         us        97.12
    L1/TEX Cache Throughput           %        76.50
    L2 Cache Throughput               %        29.39
    SM Active Cycles              cycle    77,008.87
    Compute (SM) Throughput           %        80.20
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.48
    Achieved Active Warps Per SM           warp        42.95
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.52%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,821.33
    Total DRAM Elapsed Cycles        cycle    3,489,792
    Average L1 Active Cycles         cycle    77,008.87
    Total L1 Elapsed Cycles          cycle    2,373,350
    Average L2 Active Cycles         cycle    72,085.12
    Total L2 Elapsed Cycles          cycle    1,800,168
    Average SM Active Cycles         cycle    77,008.87
    Total SM Elapsed Cycles          cycle    2,373,350
    Average SMSP Active Cycles       cycle    76,982.81
    Total SMSP Elapsed Cycles        cycle    9,493,400
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.33
    Elapsed Cycles                cycle       79,098
    Memory Throughput                 %        74.55
    DRAM Throughput                   %        42.31
    Duration                         us        96.77
    L1/TEX Cache Throughput           %        76.45
    L2 Cache Throughput               %        29.48
    SM Active Cycles              cycle    77,056.07
    Compute (SM) Throughput           %        80.20
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.40
    Achieved Active Warps Per SM           warp        42.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.6%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,224
    Total DRAM Elapsed Cycles        cycle    3,477,504
    Average L1 Active Cycles         cycle    77,056.07
    Total L1 Elapsed Cycles          cycle    2,370,670
    Average L2 Active Cycles         cycle    72,018.92
    Total L2 Elapsed Cycles          cycle    1,793,496
    Average SM Active Cycles         cycle    77,056.07
    Total SM Elapsed Cycles          cycle    2,370,670
    Average SMSP Active Cycles       cycle    76,969.95
    Total SMSP Elapsed Cycles        cycle    9,482,680
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.24
    Elapsed Cycles                cycle       79,296
    Memory Throughput                 %        74.32
    DRAM Throughput                   %        42.15
    Duration                         us        97.02
    L1/TEX Cache Throughput           %        76.53
    L2 Cache Throughput               %        29.39
    SM Active Cycles              cycle    76,970.47
    Compute (SM) Throughput           %        79.85
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.39
    Achieved Active Warps Per SM           warp        42.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.61%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,042.67
    Total DRAM Elapsed Cycles        cycle    3,487,744
    Average L1 Active Cycles         cycle    76,970.47
    Total L1 Elapsed Cycles          cycle    2,378,020
    Average L2 Active Cycles         cycle    71,963.46
    Total L2 Elapsed Cycles          cycle    1,798,128
    Average SM Active Cycles         cycle    76,970.47
    Total SM Elapsed Cycles          cycle    2,378,020
    Average SMSP Active Cycles       cycle    76,951.52
    Total SMSP Elapsed Cycles        cycle    9,512,080
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.87
    SM Frequency                    Mhz       795.40
    Elapsed Cycles                cycle        3,055
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.36
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.61
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       459.97
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.55
    Achieved Active Warps Per SM           warp         5.55
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.45%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      135,168
    Average L1 Active Cycles         cycle       459.97
    Total L1 Elapsed Cycles          cycle       88,420
    Average L2 Active Cycles         cycle       239.04
    Total L2 Elapsed Cycles          cycle       69,264
    Average SM Active Cycles         cycle       459.97
    Total SM Elapsed Cycles          cycle       88,420
    Average SMSP Active Cycles       cycle       303.33
    Total SMSP Elapsed Cycles        cycle      353,680
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.53%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.45% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.9%                                                                                            
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.76% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.53%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.45% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.301%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 64.00% above the average, while the minimum instance value is 84.52% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.30
    Elapsed Cycles                cycle       79,144
    Memory Throughput                 %        74.41
    DRAM Throughput                   %        42.26
    Duration                         us        96.83
    L1/TEX Cache Throughput           %        76.56
    L2 Cache Throughput               %        29.40
    SM Active Cycles              cycle    76,941.77
    Compute (SM) Throughput           %        79.88
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.35
    Achieved Active Warps Per SM           warp        42.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.65%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,157.33
    Total DRAM Elapsed Cycles        cycle    3,480,576
    Average L1 Active Cycles         cycle    76,941.77
    Total L1 Elapsed Cycles          cycle    2,374,860
    Average L2 Active Cycles         cycle    71,954.79
    Total L2 Elapsed Cycles          cycle    1,794,792
    Average SM Active Cycles         cycle    76,941.77
    Total SM Elapsed Cycles          cycle    2,374,860
    Average SMSP Active Cycles       cycle    76,910.80
    Total SMSP Elapsed Cycles        cycle    9,499,440
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.46
    Elapsed Cycles                cycle       79,082
    Memory Throughput                 %        74.34
    DRAM Throughput                   %        42.26
    Duration                         us        96.74
    L1/TEX Cache Throughput           %        76.54
    L2 Cache Throughput               %        29.47
    SM Active Cycles              cycle    76,965.67
    Compute (SM) Throughput           %        79.72
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.35
    Achieved Active Warps Per SM           warp        42.89
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.65%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,954.67
    Total DRAM Elapsed Cycles        cycle    3,477,504
    Average L1 Active Cycles         cycle    76,965.67
    Total L1 Elapsed Cycles          cycle    2,377,320
    Average L2 Active Cycles         cycle    71,911.71
    Total L2 Elapsed Cycles          cycle    1,793,256
    Average SM Active Cycles         cycle    76,965.67
    Total SM Elapsed Cycles          cycle    2,377,320
    Average SMSP Active Cycles       cycle    76,953.81
    Total SMSP Elapsed Cycles        cycle    9,509,280
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.34
    Elapsed Cycles                cycle       79,229
    Memory Throughput                 %        74.45
    DRAM Throughput                   %        42.15
    Duration                         us        96.93
    L1/TEX Cache Throughput           %        76.61
    L2 Cache Throughput               %        29.44
    SM Active Cycles              cycle    76,895.73
    Compute (SM) Throughput           %        79.77
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.27
    Achieved Active Warps Per SM           warp        42.85
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.73%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,738.67
    Total DRAM Elapsed Cycles        cycle    3,483,648
    Average L1 Active Cycles         cycle    76,895.73
    Total L1 Elapsed Cycles          cycle    2,373,790
    Average L2 Active Cycles         cycle    72,029.58
    Total L2 Elapsed Cycles          cycle    1,796,640
    Average SM Active Cycles         cycle    76,895.73
    Total SM Elapsed Cycles          cycle    2,373,790
    Average SMSP Active Cycles       cycle    76,860.74
    Total SMSP Elapsed Cycles        cycle    9,495,160
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       796.57
    Elapsed Cycles                cycle        3,034
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.35
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.73
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       439.20
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.26
    Achieved Active Warps Per SM           warp         5.41
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.74%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      133,120
    Average L1 Active Cycles         cycle       439.20
    Total L1 Elapsed Cycles          cycle       88,140
    Average L2 Active Cycles         cycle       226.33
    Total L2 Elapsed Cycles          cycle       68,736
    Average SM Active Cycles         cycle       439.20
    Total SM Elapsed Cycles          cycle       88,140
    Average SMSP Active Cycles       cycle          317
    Total SMSP Elapsed Cycles        cycle      352,560
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.11%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.61% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.267%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.62% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.11%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.61% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.13
    Elapsed Cycles                cycle       79,130
    Memory Throughput                 %        74.37
    DRAM Throughput                   %        42.39
    Duration                         us        96.83
    L1/TEX Cache Throughput           %        76.60
    L2 Cache Throughput               %        29.46
    SM Active Cycles              cycle    76,906.63
    Compute (SM) Throughput           %        79.63
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.21
    Achieved Active Warps Per SM           warp        42.82
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.79%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,802.67
    Total DRAM Elapsed Cycles        cycle    3,479,552
    Average L1 Active Cycles         cycle    76,906.63
    Total L1 Elapsed Cycles          cycle    2,376,310
    Average L2 Active Cycles         cycle       72,035
    Total L2 Elapsed Cycles          cycle    1,794,168
    Average SM Active Cycles         cycle    76,906.63
    Total SM Elapsed Cycles          cycle    2,376,310
    Average SMSP Active Cycles       cycle    76,974.90
    Total SMSP Elapsed Cycles        cycle    9,505,240
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.23
    Elapsed Cycles                cycle       79,087
    Memory Throughput                 %        74.62
    DRAM Throughput                   %        42.47
    Duration                         us        96.77
    L1/TEX Cache Throughput           %        76.43
    L2 Cache Throughput               %        29.48
    SM Active Cycles              cycle    77,078.57
    Compute (SM) Throughput           %        79.87
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.13
    Achieved Active Warps Per SM           warp        42.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.87%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   246,154.67
    Total DRAM Elapsed Cycles        cycle    3,477,504
    Average L1 Active Cycles         cycle    77,078.57
    Total L1 Elapsed Cycles          cycle    2,368,490
    Average L2 Active Cycles         cycle    72,017.71
    Total L2 Elapsed Cycles          cycle    1,793,496
    Average SM Active Cycles         cycle    77,078.57
    Total SM Elapsed Cycles          cycle    2,368,490
    Average SMSP Active Cycles       cycle    76,969.03
    Total SMSP Elapsed Cycles        cycle    9,473,960
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.88
    SM Frequency                    Mhz       799.70
    Elapsed Cycles                cycle        3,022
    Memory Throughput                 %         0.89
    DRAM Throughput                   %         0.36
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.88
    L2 Cache Throughput               %         0.89
    SM Active Cycles              cycle       417.07
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.08
    Achieved Active Warps Per SM           warp         5.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.92%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      133,120
    Average L1 Active Cycles         cycle       417.07
    Total L1 Elapsed Cycles          cycle       89,270
    Average L2 Active Cycles         cycle       238.92
    Total L2 Elapsed Cycles          cycle       68,424
    Average SM Active Cycles         cycle       417.07
    Total SM Elapsed Cycles          cycle       89,270
    Average SMSP Active Cycles       cycle       294.71
    Total SMSP Elapsed Cycles        cycle      357,080
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.477%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.62% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.625%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.99% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.477%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.62% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.48
    Elapsed Cycles                cycle       79,214
    Memory Throughput                 %        74.36
    DRAM Throughput                   %        42.19
    Duration                         us        96.90
    L1/TEX Cache Throughput           %        76.48
    L2 Cache Throughput               %        29.41
    SM Active Cycles              cycle    77,022.90
    Compute (SM) Throughput           %        79.55
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.09
    Achieved Active Warps Per SM           warp        42.76
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.91%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,872
    Total DRAM Elapsed Cycles        cycle    3,482,624
    Average L1 Active Cycles         cycle    77,022.90
    Total L1 Elapsed Cycles          cycle    2,376,760
    Average L2 Active Cycles         cycle    72,080.83
    Total L2 Elapsed Cycles          cycle    1,796,400
    Average SM Active Cycles         cycle    77,022.90
    Total SM Elapsed Cycles          cycle    2,376,760
    Average SMSP Active Cycles       cycle    77,049.79
    Total SMSP Elapsed Cycles        cycle    9,507,040
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.86
    SM Frequency                    Mhz       798.84
    Elapsed Cycles                cycle        3,119
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.34
    Duration                         us         3.90
    L1/TEX Cache Throughput           %         2.79
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       430.30
    Compute (SM) Throughput           %         0.51
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.68
    Achieved Active Warps Per SM           warp         5.13
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.32%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      137,216
    Average L1 Active Cycles         cycle       430.30
    Total L1 Elapsed Cycles          cycle       89,810
    Average L2 Active Cycles         cycle       225.38
    Total L2 Elapsed Cycles          cycle       70,776
    Average SM Active Cycles         cycle       430.30
    Total SM Elapsed Cycles          cycle       89,810
    Average SMSP Active Cycles       cycle       292.52
    Total SMSP Elapsed Cycles        cycle      359,240
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.792%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 68.13% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.634%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.12% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.792%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 68.13% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.34
    Elapsed Cycles                cycle       79,384
    Memory Throughput                 %        74.58
    DRAM Throughput                   %        42.08
    Duration                         us        97.12
    L1/TEX Cache Throughput           %        76.36
    L2 Cache Throughput               %        29.37
    SM Active Cycles              cycle    77,147.17
    Compute (SM) Throughput           %        79.73
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.05
    Achieved Active Warps Per SM           warp        42.75
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.95%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,810.67
    Total DRAM Elapsed Cycles        cycle    3,490,816
    Average L1 Active Cycles         cycle    77,147.17
    Total L1 Elapsed Cycles          cycle    2,369,690
    Average L2 Active Cycles         cycle    72,091.83
    Total L2 Elapsed Cycles          cycle    1,799,976
    Average SM Active Cycles         cycle    77,147.17
    Total SM Elapsed Cycles          cycle    2,369,690
    Average SMSP Active Cycles       cycle    76,985.39
    Total SMSP Elapsed Cycles        cycle    9,478,760
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.49
    Elapsed Cycles                cycle       79,501
    Memory Throughput                 %        74.17
    DRAM Throughput                   %        42.01
    Duration                         us        97.25
    L1/TEX Cache Throughput           %        76.47
    L2 Cache Throughput               %        29.31
    SM Active Cycles              cycle    77,032.53
    Compute (SM) Throughput           %        79.23
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.88
    Achieved Active Warps Per SM           warp        42.66
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.12%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,757.33
    Total DRAM Elapsed Cycles        cycle    3,495,936
    Average L1 Active Cycles         cycle    77,032.53
    Total L1 Elapsed Cycles          cycle    2,382,670
    Average L2 Active Cycles         cycle    72,079.67
    Total L2 Elapsed Cycles          cycle    1,802,904
    Average SM Active Cycles         cycle    77,032.53
    Total SM Elapsed Cycles          cycle    2,382,670
    Average SMSP Active Cycles       cycle    77,016.12
    Total SMSP Elapsed Cycles        cycle    9,530,680
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.10
    Elapsed Cycles                cycle       79,388
    Memory Throughput                 %        74.45
    DRAM Throughput                   %        42.16
    Duration                         us        97.15
    L1/TEX Cache Throughput           %        76.51
    L2 Cache Throughput               %        29.33
    SM Active Cycles              cycle       76,998
    Compute (SM) Throughput           %        79.44
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.99
    Achieved Active Warps Per SM           warp        42.71
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.01%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,272
    Total DRAM Elapsed Cycles        cycle    3,490,816
    Average L1 Active Cycles         cycle       76,998
    Total L1 Elapsed Cycles          cycle    2,373,760
    Average L2 Active Cycles         cycle    72,067.46
    Total L2 Elapsed Cycles          cycle    1,800,336
    Average SM Active Cycles         cycle       76,998
    Total SM Elapsed Cycles          cycle    2,373,760
    Average SMSP Active Cycles       cycle    76,958.61
    Total SMSP Elapsed Cycles        cycle    9,495,040
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.47
    Elapsed Cycles                cycle       79,606
    Memory Throughput                 %        74.34
    DRAM Throughput                   %        41.98
    Duration                         us        97.38
    L1/TEX Cache Throughput           %        76.55
    L2 Cache Throughput               %        29.25
    SM Active Cycles              cycle    76,953.10
    Compute (SM) Throughput           %        79.24
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.86
    Achieved Active Warps Per SM           warp        42.65
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.14%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,880
    Total DRAM Elapsed Cycles        cycle    3,500,032
    Average L1 Active Cycles         cycle    76,953.10
    Total L1 Elapsed Cycles          cycle    2,377,320
    Average L2 Active Cycles         cycle    71,904.88
    Total L2 Elapsed Cycles          cycle    1,805,064
    Average SM Active Cycles         cycle    76,953.10
    Total SM Elapsed Cycles          cycle    2,377,320
    Average SMSP Active Cycles       cycle    76,826.91
    Total SMSP Elapsed Cycles        cycle    9,509,280
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.83
    SM Frequency                    Mhz       797.88
    Elapsed Cycles                cycle        3,042
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.31
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       428.97
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.23
    Achieved Active Warps Per SM           warp         5.39
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.77%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        69.33
    Total DRAM Elapsed Cycles        cycle      133,120
    Average L1 Active Cycles         cycle       428.97
    Total L1 Elapsed Cycles          cycle       90,330
    Average L2 Active Cycles         cycle       229.96
    Total L2 Elapsed Cycles          cycle       68,928
    Average SM Active Cycles         cycle       428.97
    Total SM Elapsed Cycles          cycle       90,330
    Average SMSP Active Cycles       cycle       303.73
    Total SMSP Elapsed Cycles        cycle      361,320
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.634%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.63% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.747%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.80% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.634%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.63% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.99
    SM Frequency                    Mhz       817.29
    Elapsed Cycles                cycle       79,405
    Memory Throughput                 %        74.46
    DRAM Throughput                   %        42.06
    Duration                         us        97.15
    L1/TEX Cache Throughput           %        76.64
    L2 Cache Throughput               %        29.34
    SM Active Cycles              cycle    76,868.57
    Compute (SM) Throughput           %        79.27
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.89
    Achieved Active Warps Per SM           warp        42.67
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.11%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,685.33
    Total DRAM Elapsed Cycles        cycle    3,490,816
    Average L1 Active Cycles         cycle    76,868.57
    Total L1 Elapsed Cycles          cycle    2,373,470
    Average L2 Active Cycles         cycle    71,906.08
    Total L2 Elapsed Cycles          cycle    1,800,720
    Average SM Active Cycles         cycle    76,868.57
    Total SM Elapsed Cycles          cycle    2,373,470
    Average SMSP Active Cycles       cycle    76,763.34
    Total SMSP Elapsed Cycles        cycle    9,493,880
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.87
    SM Frequency                    Mhz       799.72
    Elapsed Cycles                cycle        3,046
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.35
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.82
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       425.13
    Compute (SM) Throughput           %         0.58
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.26
    Achieved Active Warps Per SM           warp         5.41
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.74%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      134,144
    Average L1 Active Cycles         cycle       425.13
    Total L1 Elapsed Cycles          cycle       87,780
    Average L2 Active Cycles         cycle       223.75
    Total L2 Elapsed Cycles          cycle       69,048
    Average SM Active Cycles         cycle       425.13
    Total SM Elapsed Cycles          cycle       87,780
    Average SMSP Active Cycles       cycle       303.99
    Total SMSP Elapsed Cycles        cycle      351,120
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.868%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.91% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.978%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.79% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.868%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.91% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

