==PROF== Connected to process 21430 (/home/driffyn/Documents/CMDA4634/heat_eq/optimized/cuda_heat_equation)
==PROF== Profiling "heat_kernel_2d_fused" - 0: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 1: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 2: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 3: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 4: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 5: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 6: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 7: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 8: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 9: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 10: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 11: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 12: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 13: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 14: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 15: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 16: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 17: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 18: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 19: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 20: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 21: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 22: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 23: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 24: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 25: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 26: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 27: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 28: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 29: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 30: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 31: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 32: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 33: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 34: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 35: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 36: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 37: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 38: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 39: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 40: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 41: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 42: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 43: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 44: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 45: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 46: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 47: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 48: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 49: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 50: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 51: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 52: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 53: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 54: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 55: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 56: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 57: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 58: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 59: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 60: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 61: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 62: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 63: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 64: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 65: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 66: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 67: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 68: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 69: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 70: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 71: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 72: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 73: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 74: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 75: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 76: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 77: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 78: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 79: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 80: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 81: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 82: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 83: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 84: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 85: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 86: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 87: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 88: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 89: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 90: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 91: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 92: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 93: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 94: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 95: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 96: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 97: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 98: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 99: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 100: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 101: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 102: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 103: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 104: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 105: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 106: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 107: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 108: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 109: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 110: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 111: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 112: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 113: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 114: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 115: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 116: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 117: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 118: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 119: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 120: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 121: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 122: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 123: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 124: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 125: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 126: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 127: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 128: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 129: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 130: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 131: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 132: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 133: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 134: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 135: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 136: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 137: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 138: 0%....50%....100% - 8 passes
==PROF== Profiling "heat_kernel_2d_fused" - 139: 0%....50%....100% - 8 passes
==PROF== Profiling "add_heat_kernel_2d" - 140: 0%....50%....100% - 8 passes
==PROF== Disconnected from process 21430
[21430] cuda_heat_equation@127.0.0.1
  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.22
    Elapsed Cycles                cycle       81,568
    Memory Throughput                 %        69.94
    DRAM Throughput                   %        44.67
    Duration                         us        99.81
    L1/TEX Cache Throughput           %        71.79
    L2 Cache Throughput               %        28.66
    SM Active Cycles              cycle    79,340.97
    Compute (SM) Throughput           %        81.22
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.51
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,770.67
    Total DRAM Elapsed Cycles        cycle    3,288,064
    Average L1 Active Cycles         cycle    79,340.97
    Total L1 Elapsed Cycles          cycle    2,442,980
    Average L2 Active Cycles         cycle    73,825.33
    Total L2 Elapsed Cycles          cycle    1,849,776
    Average SM Active Cycles         cycle    79,340.97
    Total SM Elapsed Cycles          cycle    2,442,980
    Average SMSP Active Cycles       cycle    79,066.07
    Total SMSP Elapsed Cycles        cycle    9,771,920
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.14
    Elapsed Cycles                cycle       81,404
    Memory Throughput                 %        69.79
    DRAM Throughput                   %        42.49
    Duration                         us        99.62
    L1/TEX Cache Throughput           %        71.83
    L2 Cache Throughput               %        28.71
    SM Active Cycles              cycle    79,293.10
    Compute (SM) Throughput           %        81.04
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.52
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,357.33
    Total DRAM Elapsed Cycles        cycle    3,280,896
    Average L1 Active Cycles         cycle    79,293.10
    Total L1 Elapsed Cycles          cycle    2,448,300
    Average L2 Active Cycles         cycle    73,803.50
    Total L2 Elapsed Cycles          cycle    1,845,792
    Average SM Active Cycles         cycle    79,293.10
    Total SM Elapsed Cycles          cycle    2,448,300
    Average SMSP Active Cycles       cycle    79,120.26
    Total SMSP Elapsed Cycles        cycle    9,793,200
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.41
    Elapsed Cycles                cycle       81,484
    Memory Throughput                 %        69.69
    DRAM Throughput                   %        42.21
    Duration                         us        99.68
    L1/TEX Cache Throughput           %        71.78
    L2 Cache Throughput               %        28.65
    SM Active Cycles              cycle    79,345.90
    Compute (SM) Throughput           %        80.92
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.53
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,002.67
    Total DRAM Elapsed Cycles        cycle    3,283,968
    Average L1 Active Cycles         cycle    79,345.90
    Total L1 Elapsed Cycles          cycle    2,451,980
    Average L2 Active Cycles         cycle    73,840.46
    Total L2 Elapsed Cycles          cycle    1,847,688
    Average SM Active Cycles         cycle    79,345.90
    Total SM Elapsed Cycles          cycle    2,451,980
    Average SMSP Active Cycles       cycle    79,073.52
    Total SMSP Elapsed Cycles        cycle    9,807,920
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.22
    Elapsed Cycles                cycle       81,519
    Memory Throughput                 %        69.97
    DRAM Throughput                   %        42.32
    Duration                         us        99.74
    L1/TEX Cache Throughput           %        71.74
    L2 Cache Throughput               %        28.64
    SM Active Cycles              cycle    79,399.97
    Compute (SM) Throughput           %        81.25
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.48
    Achieved Active Warps Per SM           warp        43.43
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,845.33
    Total DRAM Elapsed Cycles        cycle    3,287,040
    Average L1 Active Cycles         cycle    79,399.97
    Total L1 Elapsed Cycles          cycle    2,441,930
    Average L2 Active Cycles         cycle    73,883.29
    Total L2 Elapsed Cycles          cycle    1,848,552
    Average SM Active Cycles         cycle    79,399.97
    Total SM Elapsed Cycles          cycle    2,441,930
    Average SMSP Active Cycles       cycle    79,025.49
    Total SMSP Elapsed Cycles        cycle    9,767,720
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       801.47
    Elapsed Cycles                cycle        3,027
    Memory Throughput                 %         0.90
    DRAM Throughput                   %         0.45
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.67
    L2 Cache Throughput               %         0.90
    SM Active Cycles              cycle       448.67
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.07
    Achieved Active Warps Per SM           warp         5.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.93%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        90.67
    Total DRAM Elapsed Cycles        cycle      120,832
    Average L1 Active Cycles         cycle       448.67
    Total L1 Elapsed Cycles          cycle       89,450
    Average L2 Active Cycles         cycle       282.50
    Total L2 Elapsed Cycles          cycle       68,640
    Average SM Active Cycles         cycle       448.67
    Total SM Elapsed Cycles          cycle       89,450
    Average SMSP Active Cycles       cycle       311.21
    Total SMSP Elapsed Cycles        cycle      357,800
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.13%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.35% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.012%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.76% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.13%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.35% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.953%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 60.27% above the average, while the minimum instance value is 86.90% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.22
    Elapsed Cycles                cycle       81,464
    Memory Throughput                 %        69.94
    DRAM Throughput                   %        42.33
    Duration                         us        99.68
    L1/TEX Cache Throughput           %        71.85
    L2 Cache Throughput               %        28.73
    SM Active Cycles              cycle    79,276.03
    Compute (SM) Throughput           %        81.21
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.53
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,594.67
    Total DRAM Elapsed Cycles        cycle    3,282,944
    Average L1 Active Cycles         cycle    79,276.03
    Total L1 Elapsed Cycles          cycle    2,443,150
    Average L2 Active Cycles         cycle    73,928.50
    Total L2 Elapsed Cycles          cycle    1,847,256
    Average SM Active Cycles         cycle    79,276.03
    Total SM Elapsed Cycles          cycle    2,443,150
    Average SMSP Active Cycles       cycle    79,052.82
    Total SMSP Elapsed Cycles        cycle    9,772,600
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.49
    Elapsed Cycles                cycle       81,387
    Memory Throughput                 %        69.99
    DRAM Throughput                   %        42.44
    Duration                         us        99.55
    L1/TEX Cache Throughput           %        71.75
    L2 Cache Throughput               %        28.73
    SM Active Cycles              cycle    79,380.60
    Compute (SM) Throughput           %        81.27
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.53
    Achieved Active Warps Per SM           warp        43.46
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      232,080
    Total DRAM Elapsed Cycles        cycle    3,280,896
    Average L1 Active Cycles         cycle    79,380.60
    Total L1 Elapsed Cycles          cycle    2,441,290
    Average L2 Active Cycles         cycle    73,886.42
    Total L2 Elapsed Cycles          cycle    1,845,504
    Average SM Active Cycles         cycle    79,380.60
    Total SM Elapsed Cycles          cycle    2,441,290
    Average SMSP Active Cycles       cycle    79,204.53
    Total SMSP Elapsed Cycles        cycle    9,765,160
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.14
    Elapsed Cycles                cycle       81,614
    Memory Throughput                 %        69.92
    DRAM Throughput                   %        42.14
    Duration                         us        99.87
    L1/TEX Cache Throughput           %        71.84
    L2 Cache Throughput               %        28.64
    SM Active Cycles              cycle    79,280.43
    Compute (SM) Throughput           %        81.19
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.57
    Achieved Active Warps Per SM           warp        43.47
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   230,994.67
    Total DRAM Elapsed Cycles        cycle    3,289,088
    Average L1 Active Cycles         cycle    79,280.43
    Total L1 Elapsed Cycles          cycle    2,443,700
    Average L2 Active Cycles         cycle    73,853.83
    Total L2 Elapsed Cycles          cycle    1,850,784
    Average SM Active Cycles         cycle    79,280.43
    Total SM Elapsed Cycles          cycle    2,443,700
    Average SMSP Active Cycles       cycle    79,076.69
    Total SMSP Elapsed Cycles        cycle    9,774,800
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.37
    Elapsed Cycles                cycle       81,507
    Memory Throughput                 %        69.93
    DRAM Throughput                   %        42.66
    Duration                         us        99.71
    L1/TEX Cache Throughput           %        71.74
    L2 Cache Throughput               %        28.66
    SM Active Cycles              cycle    79,400.37
    Compute (SM) Throughput           %        81.20
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.45
    Achieved Active Warps Per SM           warp        43.41
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      233,648
    Total DRAM Elapsed Cycles        cycle    3,286,016
    Average L1 Active Cycles         cycle    79,400.37
    Total L1 Elapsed Cycles          cycle    2,443,400
    Average L2 Active Cycles         cycle    73,991.71
    Total L2 Elapsed Cycles          cycle    1,848,264
    Average SM Active Cycles         cycle    79,400.37
    Total SM Elapsed Cycles          cycle    2,443,400
    Average SMSP Active Cycles       cycle    79,069.18
    Total SMSP Elapsed Cycles        cycle    9,773,600
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.42
    SM Frequency                    Mhz       803.32
    Elapsed Cycles                cycle        3,034
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.48
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.78
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       431.27
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.07
    Achieved Active Warps Per SM           warp         5.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.93%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        98.67
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       431.27
    Total L1 Elapsed Cycles          cycle       91,190
    Average L2 Active Cycles         cycle       344.71
    Total L2 Elapsed Cycles          cycle       68,808
    Average SM Active Cycles         cycle       431.27
    Total SM Elapsed Cycles          cycle       91,190
    Average SMSP Active Cycles       cycle       306.08
    Total SMSP Elapsed Cycles        cycle      364,760
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.545%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.28% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.726%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.72% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.545%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.28% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.541%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 54.40% above the average, while the minimum instance value is 80.85% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.15
    Elapsed Cycles                cycle       81,376
    Memory Throughput                 %        69.95
    DRAM Throughput                   %        42.49
    Duration                         us        99.58
    L1/TEX Cache Throughput           %        71.57
    L2 Cache Throughput               %        28.75
    SM Active Cycles              cycle    79,584.17
    Compute (SM) Throughput           %        81.22
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.56
    Achieved Active Warps Per SM           warp        43.47
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,365.33
    Total DRAM Elapsed Cycles        cycle    3,280,896
    Average L1 Active Cycles         cycle    79,584.17
    Total L1 Elapsed Cycles          cycle    2,442,870
    Average L2 Active Cycles         cycle    73,847.67
    Total L2 Elapsed Cycles          cycle    1,845,456
    Average SM Active Cycles         cycle    79,584.17
    Total SM Elapsed Cycles          cycle    2,442,870
    Average SMSP Active Cycles       cycle    79,080.23
    Total SMSP Elapsed Cycles        cycle    9,771,480
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.38
    Elapsed Cycles                cycle       81,560
    Memory Throughput                 %        70.01
    DRAM Throughput                   %        42.39
    Duration                         us        99.78
    L1/TEX Cache Throughput           %        71.80
    L2 Cache Throughput               %        28.66
    SM Active Cycles              cycle    79,330.87
    Compute (SM) Throughput           %        81.29
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.51
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,298.67
    Total DRAM Elapsed Cycles        cycle    3,288,064
    Average L1 Active Cycles         cycle    79,330.87
    Total L1 Elapsed Cycles          cycle    2,440,840
    Average L2 Active Cycles         cycle    73,837.50
    Total L2 Elapsed Cycles          cycle    1,849,464
    Average SM Active Cycles         cycle    79,330.87
    Total SM Elapsed Cycles          cycle    2,440,840
    Average SMSP Active Cycles       cycle    79,125.43
    Total SMSP Elapsed Cycles        cycle    9,763,360
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.20
    Elapsed Cycles                cycle       81,646
    Memory Throughput                 %        69.92
    DRAM Throughput                   %        42.16
    Duration                         us        99.90
    L1/TEX Cache Throughput           %        71.69
    L2 Cache Throughput               %        28.71
    SM Active Cycles              cycle    79,455.57
    Compute (SM) Throughput           %        81.18
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.48
    Achieved Active Warps Per SM           warp        43.43
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,333.33
    Total DRAM Elapsed Cycles        cycle    3,292,160
    Average L1 Active Cycles         cycle    79,455.57
    Total L1 Elapsed Cycles          cycle    2,443,960
    Average L2 Active Cycles         cycle    73,854.62
    Total L2 Elapsed Cycles          cycle    1,851,336
    Average SM Active Cycles         cycle    79,455.57
    Total SM Elapsed Cycles          cycle    2,443,960
    Average SMSP Active Cycles       cycle    79,082.62
    Total SMSP Elapsed Cycles        cycle    9,775,840
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.28
    Elapsed Cycles                cycle       81,391
    Memory Throughput                 %        69.93
    DRAM Throughput                   %        44.73
    Duration                         us        99.58
    L1/TEX Cache Throughput           %        71.85
    L2 Cache Throughput               %        28.74
    SM Active Cycles              cycle    79,277.17
    Compute (SM) Throughput           %        81.20
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.51
    Achieved Active Warps Per SM           warp        43.44
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,576
    Total DRAM Elapsed Cycles        cycle    3,280,896
    Average L1 Active Cycles         cycle    79,277.17
    Total L1 Elapsed Cycles          cycle    2,443,470
    Average L2 Active Cycles         cycle    73,778.46
    Total L2 Elapsed Cycles          cycle    1,845,624
    Average SM Active Cycles         cycle    79,277.17
    Total SM Elapsed Cycles          cycle    2,443,470
    Average SMSP Active Cycles       cycle    79,109.39
    Total SMSP Elapsed Cycles        cycle    9,773,880
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       801.38
    Elapsed Cycles                cycle        3,053
    Memory Throughput                 %         0.95
    DRAM Throughput                   %         0.38
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.73
    L2 Cache Throughput               %         0.95
    SM Active Cycles              cycle       439.93
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.18
    Achieved Active Warps Per SM           warp         5.37
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.82%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       439.93
    Total L1 Elapsed Cycles          cycle       91,250
    Average L2 Active Cycles         cycle       322.50
    Total L2 Elapsed Cycles          cycle       69,192
    Average SM Active Cycles         cycle       439.93
    Total SM Elapsed Cycles          cycle       91,250
    Average SMSP Active Cycles       cycle       312.33
    Total SMSP Elapsed Cycles        cycle      365,000
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.792%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.70% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.884%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.78% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.792%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.70% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.243%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 46.87% above the average, while the minimum instance value is 77.05% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.18
    Elapsed Cycles                cycle       81,408
    Memory Throughput                 %        70.04
    DRAM Throughput                   %        42.33
    Duration                         us        99.62
    L1/TEX Cache Throughput           %        71.81
    L2 Cache Throughput               %        28.67
    SM Active Cycles              cycle    79,313.73
    Compute (SM) Throughput           %        81.32
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.51
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      231,536
    Total DRAM Elapsed Cycles        cycle    3,281,920
    Average L1 Active Cycles         cycle    79,313.73
    Total L1 Elapsed Cycles          cycle    2,439,660
    Average L2 Active Cycles         cycle    73,800.92
    Total L2 Elapsed Cycles          cycle    1,846,128
    Average SM Active Cycles         cycle    79,313.73
    Total SM Elapsed Cycles          cycle    2,439,660
    Average SMSP Active Cycles       cycle    78,998.33
    Total SMSP Elapsed Cycles        cycle    9,758,640
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.46
    Elapsed Cycles                cycle       81,488
    Memory Throughput                 %        70.00
    DRAM Throughput                   %        44.78
    Duration                         us        99.68
    L1/TEX Cache Throughput           %        71.80
    L2 Cache Throughput               %        28.66
    SM Active Cycles              cycle    79,331.17
    Compute (SM) Throughput           %        81.27
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.49
    Achieved Active Warps Per SM           warp        43.43
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,112
    Total DRAM Elapsed Cycles        cycle    3,283,968
    Average L1 Active Cycles         cycle    79,331.17
    Total L1 Elapsed Cycles          cycle    2,441,080
    Average L2 Active Cycles         cycle    73,818.67
    Total L2 Elapsed Cycles          cycle    1,847,736
    Average SM Active Cycles         cycle    79,331.17
    Total SM Elapsed Cycles          cycle    2,441,080
    Average SMSP Active Cycles       cycle    79,245.54
    Total SMSP Elapsed Cycles        cycle    9,764,320
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       799.02
    Elapsed Cycles                cycle        3,043
    Memory Throughput                 %         1.37
    DRAM Throughput                   %         0.38
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.74
    L2 Cache Throughput               %         1.37
    SM Active Cycles              cycle       438.27
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.17
    Achieved Active Warps Per SM           warp         5.36
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.83%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       438.27
    Total L1 Elapsed Cycles          cycle       90,830
    Average L2 Active Cycles         cycle       267.92
    Total L2 Elapsed Cycles          cycle       69,000
    Average SM Active Cycles         cycle       438.27
    Total SM Elapsed Cycles          cycle       90,830
    Average SMSP Active Cycles       cycle       299.24
    Total SMSP Elapsed Cycles        cycle      363,320
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.776%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.54% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.634%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.24% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.776%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.54% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.122%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 65.70% above the average, while the minimum instance value is 86.19% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.26
    Elapsed Cycles                cycle       81,600
    Memory Throughput                 %        69.62
    DRAM Throughput                   %        42.18
    Duration                         us        99.84
    L1/TEX Cache Throughput           %        71.77
    L2 Cache Throughput               %        28.69
    SM Active Cycles              cycle    79,366.10
    Compute (SM) Throughput           %        80.83
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.58
    Achieved Active Warps Per SM           warp        43.48
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      231,216
    Total DRAM Elapsed Cycles        cycle    3,289,088
    Average L1 Active Cycles         cycle    79,366.10
    Total L1 Elapsed Cycles          cycle    2,454,340
    Average L2 Active Cycles         cycle    73,880.75
    Total L2 Elapsed Cycles          cycle    1,850,472
    Average SM Active Cycles         cycle    79,366.10
    Total SM Elapsed Cycles          cycle    2,454,340
    Average SMSP Active Cycles       cycle    79,006.94
    Total SMSP Elapsed Cycles        cycle    9,817,360
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.25
    Elapsed Cycles                cycle       81,337
    Memory Throughput                 %        69.93
    DRAM Throughput                   %        44.84
    Duration                         us        99.52
    L1/TEX Cache Throughput           %        71.81
    L2 Cache Throughput               %        28.77
    SM Active Cycles              cycle    79,318.20
    Compute (SM) Throughput           %        81.19
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.49
    Achieved Active Warps Per SM           warp        43.43
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,138.67
    Total DRAM Elapsed Cycles        cycle    3,279,872
    Average L1 Active Cycles         cycle    79,318.20
    Total L1 Elapsed Cycles          cycle    2,443,530
    Average L2 Active Cycles         cycle    73,699.42
    Total L2 Elapsed Cycles          cycle    1,844,424
    Average SM Active Cycles         cycle    79,318.20
    Total SM Elapsed Cycles          cycle    2,443,530
    Average SMSP Active Cycles       cycle    79,057.07
    Total SMSP Elapsed Cycles        cycle    9,774,120
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       799.59
    Elapsed Cycles                cycle        3,096
    Memory Throughput                 %         0.92
    DRAM Throughput                   %         0.41
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.62
    L2 Cache Throughput               %         0.92
    SM Active Cycles              cycle       457.27
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.90
    Achieved Active Warps Per SM           warp         5.23
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.1%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        85.33
    Total DRAM Elapsed Cycles        cycle      123,904
    Average L1 Active Cycles         cycle       457.27
    Total L1 Elapsed Cycles          cycle       89,390
    Average L2 Active Cycles         cycle       284.12
    Total L2 Elapsed Cycles          cycle       70,224
    Average SM Active Cycles         cycle       457.27
    Total SM Elapsed Cycles          cycle       89,390
    Average SMSP Active Cycles       cycle       319.37
    Total SMSP Elapsed Cycles        cycle      357,560
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.64%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 69.33% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.292%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.37% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.64%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 69.33% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.758%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 59.29% above the average, while the minimum instance value is 86.98% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.32
    Elapsed Cycles                cycle       81,811
    Memory Throughput                 %        70.07
    DRAM Throughput                   %        42.29
    Duration                         us       100.10
    L1/TEX Cache Throughput           %        71.61
    L2 Cache Throughput               %        28.59
    SM Active Cycles              cycle    79,533.63
    Compute (SM) Throughput           %        81.35
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.55
    Achieved Active Warps Per SM           warp        43.46
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,461.33
    Total DRAM Elapsed Cycles        cycle    3,298,304
    Average L1 Active Cycles         cycle    79,533.63
    Total L1 Elapsed Cycles          cycle    2,438,610
    Average L2 Active Cycles         cycle    73,887.83
    Total L2 Elapsed Cycles          cycle    1,855,272
    Average SM Active Cycles         cycle    79,533.63
    Total SM Elapsed Cycles          cycle    2,438,610
    Average SMSP Active Cycles       cycle    79,063.14
    Total SMSP Elapsed Cycles        cycle    9,754,440
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.30
    Elapsed Cycles                cycle       81,472
    Memory Throughput                 %        70.07
    DRAM Throughput                   %        42.42
    Duration                         us        99.68
    L1/TEX Cache Throughput           %        71.79
    L2 Cache Throughput               %        28.72
    SM Active Cycles              cycle       79,338
    Compute (SM) Throughput           %        81.35
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.49
    Achieved Active Warps Per SM           warp        43.43
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,170.67
    Total DRAM Elapsed Cycles        cycle    3,283,968
    Average L1 Active Cycles         cycle       79,338
    Total L1 Elapsed Cycles          cycle    2,438,620
    Average L2 Active Cycles         cycle    73,779.17
    Total L2 Elapsed Cycles          cycle    1,847,424
    Average SM Active Cycles         cycle       79,338
    Total SM Elapsed Cycles          cycle    2,438,620
    Average SMSP Active Cycles       cycle    78,984.79
    Total SMSP Elapsed Cycles        cycle    9,754,480
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       796.18
    Elapsed Cycles                cycle        3,058
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.41
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.77
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       433.77
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.99
    Achieved Active Warps Per SM           warp         5.27
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.01%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        85.33
    Total DRAM Elapsed Cycles        cycle      123,904
    Average L1 Active Cycles         cycle       433.77
    Total L1 Elapsed Cycles          cycle       90,070
    Average L2 Active Cycles         cycle       272.25
    Total L2 Elapsed Cycles          cycle       69,336
    Average SM Active Cycles         cycle       433.77
    Total SM Elapsed Cycles          cycle       90,070
    Average SMSP Active Cycles       cycle       317.22
    Total SMSP Elapsed Cycles        cycle      360,280
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.743%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.43% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.108%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.74% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.743%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.43% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.566%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 59.06% above the average, while the minimum instance value is 86.41% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.28
    Elapsed Cycles                cycle       81,733
    Memory Throughput                 %        69.96
    DRAM Throughput                   %        44.70
    Duration                         us          100
    L1/TEX Cache Throughput           %        71.81
    L2 Cache Throughput               %        28.64
    SM Active Cycles              cycle    79,315.73
    Compute (SM) Throughput           %        81.22
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.53
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,402.67
    Total DRAM Elapsed Cycles        cycle    3,294,208
    Average L1 Active Cycles         cycle    79,315.73
    Total L1 Elapsed Cycles          cycle    2,442,450
    Average L2 Active Cycles         cycle    73,848.08
    Total L2 Elapsed Cycles          cycle    1,853,352
    Average SM Active Cycles         cycle    79,315.73
    Total SM Elapsed Cycles          cycle    2,442,450
    Average SMSP Active Cycles       cycle    78,976.43
    Total SMSP Elapsed Cycles        cycle    9,769,800
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       797.92
    Elapsed Cycles                cycle        3,065
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.45
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.81
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       427.70
    Compute (SM) Throughput           %         0.53
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.02
    Achieved Active Warps Per SM           warp         5.29
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.98%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        93.33
    Total DRAM Elapsed Cycles        cycle      123,904
    Average L1 Active Cycles         cycle       427.70
    Total L1 Elapsed Cycles          cycle       92,770
    Average L2 Active Cycles         cycle       260.54
    Total L2 Elapsed Cycles          cycle       69,504
    Average SM Active Cycles         cycle       427.70
    Total SM Elapsed Cycles          cycle       92,770
    Average SMSP Active Cycles       cycle       329.36
    Total SMSP Elapsed Cycles        cycle      371,080
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.366%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.72% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.138%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.41% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.366%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.72% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.096%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 56.65% above the average, while the minimum instance value is 85.80% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.15
    Elapsed Cycles                cycle       81,693
    Memory Throughput                 %        70.12
    DRAM Throughput                   %        42.68
    Duration                         us        99.97
    L1/TEX Cache Throughput           %        71.76
    L2 Cache Throughput               %        28.66
    SM Active Cycles              cycle    79,374.67
    Compute (SM) Throughput           %        81.40
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.45
    Achieved Active Warps Per SM           warp        43.42
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   234,173.33
    Total DRAM Elapsed Cycles        cycle    3,292,160
    Average L1 Active Cycles         cycle    79,374.67
    Total L1 Elapsed Cycles          cycle    2,436,870
    Average L2 Active Cycles         cycle    73,752.54
    Total L2 Elapsed Cycles          cycle    1,852,560
    Average SM Active Cycles         cycle    79,374.67
    Total SM Elapsed Cycles          cycle    2,436,870
    Average SMSP Active Cycles       cycle    79,013.72
    Total SMSP Elapsed Cycles        cycle    9,747,480
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.37
    Elapsed Cycles                cycle       81,610
    Memory Throughput                 %        69.98
    DRAM Throughput                   %        42.37
    Duration                         us        99.84
    L1/TEX Cache Throughput           %        71.58
    L2 Cache Throughput               %        28.69
    SM Active Cycles              cycle    79,574.07
    Compute (SM) Throughput           %        81.24
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.52
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,349.33
    Total DRAM Elapsed Cycles        cycle    3,290,112
    Average L1 Active Cycles         cycle    79,574.07
    Total L1 Elapsed Cycles          cycle    2,441,630
    Average L2 Active Cycles         cycle    73,864.29
    Total L2 Elapsed Cycles          cycle    1,850,760
    Average SM Active Cycles         cycle    79,574.07
    Total SM Elapsed Cycles          cycle    2,441,630
    Average SMSP Active Cycles       cycle    79,151.27
    Total SMSP Elapsed Cycles        cycle    9,766,520
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.28
    Elapsed Cycles                cycle       81,523
    Memory Throughput                 %        69.99
    DRAM Throughput                   %        44.94
    Duration                         us        99.74
    L1/TEX Cache Throughput           %        71.72
    L2 Cache Throughput               %        28.65
    SM Active Cycles              cycle    79,422.07
    Compute (SM) Throughput           %        81.23
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.43
    Achieved Active Warps Per SM           warp        43.40
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      246,216
    Total DRAM Elapsed Cycles        cycle    3,287,040
    Average L1 Active Cycles         cycle    79,422.07
    Total L1 Elapsed Cycles          cycle    2,441,480
    Average L2 Active Cycles         cycle    73,817.54
    Total L2 Elapsed Cycles          cycle    1,848,648
    Average SM Active Cycles         cycle    79,422.07
    Total SM Elapsed Cycles          cycle    2,441,480
    Average SMSP Active Cycles       cycle    79,161.18
    Total SMSP Elapsed Cycles        cycle    9,765,920
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.40
    Elapsed Cycles                cycle       81,666
    Memory Throughput                 %        69.82
    DRAM Throughput                   %        42.35
    Duration                         us        99.90
    L1/TEX Cache Throughput           %        71.72
    L2 Cache Throughput               %        28.66
    SM Active Cycles              cycle    79,415.67
    Compute (SM) Throughput           %        81.03
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.51
    Achieved Active Warps Per SM           warp        43.45
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,397.33
    Total DRAM Elapsed Cycles        cycle    3,292,160
    Average L1 Active Cycles         cycle    79,415.67
    Total L1 Elapsed Cycles          cycle    2,447,350
    Average L2 Active Cycles         cycle    73,882.38
    Total L2 Elapsed Cycles          cycle    1,851,840
    Average SM Active Cycles         cycle    79,415.67
    Total SM Elapsed Cycles          cycle    2,447,350
    Average SMSP Active Cycles       cycle    79,062.72
    Total SMSP Elapsed Cycles        cycle    9,789,400
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.30
    Elapsed Cycles                cycle       81,499
    Memory Throughput                 %        69.99
    DRAM Throughput                   %        44.94
    Duration                         us        99.71
    L1/TEX Cache Throughput           %        71.76
    L2 Cache Throughput               %        28.73
    SM Active Cycles              cycle    79,378.20
    Compute (SM) Throughput           %        81.22
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.42
    Achieved Active Warps Per SM           warp        43.40
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      246,024
    Total DRAM Elapsed Cycles        cycle    3,284,992
    Average L1 Active Cycles         cycle    79,378.20
    Total L1 Elapsed Cycles          cycle    2,441,470
    Average L2 Active Cycles         cycle    73,748.42
    Total L2 Elapsed Cycles          cycle    1,848,096
    Average SM Active Cycles         cycle    79,378.20
    Total SM Elapsed Cycles          cycle    2,441,470
    Average SMSP Active Cycles       cycle    78,995.07
    Total SMSP Elapsed Cycles        cycle    9,765,880
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.25
    Elapsed Cycles                cycle       81,545
    Memory Throughput                 %        69.97
    DRAM Throughput                   %        42.23
    Duration                         us        99.78
    L1/TEX Cache Throughput           %        71.74
    L2 Cache Throughput               %        28.71
    SM Active Cycles              cycle    79,397.10
    Compute (SM) Throughput           %        81.20
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.46
    Achieved Active Warps Per SM           warp        43.42
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,285.33
    Total DRAM Elapsed Cycles        cycle    3,286,016
    Average L1 Active Cycles         cycle    79,397.10
    Total L1 Elapsed Cycles          cycle    2,441,960
    Average L2 Active Cycles         cycle    73,909.75
    Total L2 Elapsed Cycles          cycle    1,849,152
    Average SM Active Cycles         cycle    79,397.10
    Total SM Elapsed Cycles          cycle    2,441,960
    Average SMSP Active Cycles       cycle    79,025.03
    Total SMSP Elapsed Cycles        cycle    9,767,840
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz          800
    Elapsed Cycles                cycle        3,074
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.39
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.73
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       439.77
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.17
    Achieved Active Warps Per SM           warp         5.36
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.83%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      123,904
    Average L1 Active Cycles         cycle       439.77
    Total L1 Elapsed Cycles          cycle       89,250
    Average L2 Active Cycles         cycle       252.62
    Total L2 Elapsed Cycles          cycle       69,672
    Average SM Active Cycles         cycle       439.77
    Total SM Elapsed Cycles          cycle       89,250
    Average SMSP Active Cycles       cycle       311.14
    Total SMSP Elapsed Cycles        cycle      357,000
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.96%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.38% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.023%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.71% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.96%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.38% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.346%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 61.43% above the average, while the minimum instance value is 85.35% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.49
    Elapsed Cycles                cycle       81,492
    Memory Throughput                 %        70.12
    DRAM Throughput                   %        44.74
    Duration                         us        99.68
    L1/TEX Cache Throughput           %        71.76
    L2 Cache Throughput               %        28.73
    SM Active Cycles              cycle    79,373.07
    Compute (SM) Throughput           %        81.36
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.42
    Achieved Active Warps Per SM           warp        43.40
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,957.33
    Total DRAM Elapsed Cycles        cycle    3,284,992
    Average L1 Active Cycles         cycle    79,373.07
    Total L1 Elapsed Cycles          cycle    2,436,850
    Average L2 Active Cycles         cycle    73,785.12
    Total L2 Elapsed Cycles          cycle    1,847,688
    Average SM Active Cycles         cycle    79,373.07
    Total SM Elapsed Cycles          cycle    2,436,850
    Average SMSP Active Cycles       cycle    79,042.73
    Total SMSP Elapsed Cycles        cycle    9,747,400
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.53
    Elapsed Cycles                cycle       81,601
    Memory Throughput                 %        69.98
    DRAM Throughput                   %        44.70
    Duration                         us        99.81
    L1/TEX Cache Throughput           %        71.88
    L2 Cache Throughput               %        28.68
    SM Active Cycles              cycle    79,237.20
    Compute (SM) Throughput           %        81.18
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.46
    Achieved Active Warps Per SM           warp        43.42
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,970.67
    Total DRAM Elapsed Cycles        cycle    3,288,064
    Average L1 Active Cycles         cycle    79,237.20
    Total L1 Elapsed Cycles          cycle    2,441,780
    Average L2 Active Cycles         cycle    73,774.25
    Total L2 Elapsed Cycles          cycle    1,850,400
    Average SM Active Cycles         cycle    79,237.20
    Total SM Elapsed Cycles          cycle    2,441,780
    Average SMSP Active Cycles       cycle    78,977.21
    Total SMSP Elapsed Cycles        cycle    9,767,120
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       796.48
    Elapsed Cycles                cycle        3,036
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.44
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.83
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       424.57
    Compute (SM) Throughput           %         0.51
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.91
    Achieved Active Warps Per SM           warp         5.24
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.09%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        90.67
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       424.57
    Total L1 Elapsed Cycles          cycle       89,390
    Average L2 Active Cycles         cycle       264.12
    Total L2 Elapsed Cycles          cycle       68,880
    Average SM Active Cycles         cycle       424.57
    Total SM Elapsed Cycles          cycle       89,390
    Average SMSP Active Cycles       cycle       308.09
    Total SMSP Elapsed Cycles        cycle      357,560
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.588%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.29% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.003%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.40% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.588%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.29% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.14
    Elapsed Cycles                cycle       81,404
    Memory Throughput                 %        70.03
    DRAM Throughput                   %        44.82
    Duration                         us        99.62
    L1/TEX Cache Throughput           %        71.76
    L2 Cache Throughput               %        28.74
    SM Active Cycles              cycle    79,377.33
    Compute (SM) Throughput           %        81.23
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.36
    Achieved Active Warps Per SM           warp        43.37
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,157.33
    Total DRAM Elapsed Cycles        cycle    3,281,920
    Average L1 Active Cycles         cycle    79,377.33
    Total L1 Elapsed Cycles          cycle    2,439,910
    Average L2 Active Cycles         cycle    73,814.46
    Total L2 Elapsed Cycles          cycle    1,846,032
    Average SM Active Cycles         cycle    79,377.33
    Total SM Elapsed Cycles          cycle    2,439,910
    Average SMSP Active Cycles       cycle    79,200.93
    Total SMSP Elapsed Cycles        cycle    9,759,640
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.42
    SM Frequency                    Mhz       802.17
    Elapsed Cycles                cycle        3,055
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.39
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.74
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       438.40
    Compute (SM) Throughput           %         0.54
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.88
    Achieved Active Warps Per SM           warp         5.22
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.12%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      123,904
    Average L1 Active Cycles         cycle       438.40
    Total L1 Elapsed Cycles          cycle       93,750
    Average L2 Active Cycles         cycle       271.38
    Total L2 Elapsed Cycles          cycle       69,216
    Average SM Active Cycles         cycle       438.40
    Total SM Elapsed Cycles          cycle       93,750
    Average SMSP Active Cycles       cycle       303.43
    Total SMSP Elapsed Cycles        cycle      375,000
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.868%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 70.34% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.551%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.77% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.868%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 70.34% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.517%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 58.63% above the average, while the minimum instance value is 86.37% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.27
    Elapsed Cycles                cycle       81,548
    Memory Throughput                 %        70.00
    DRAM Throughput                   %        44.80
    Duration                         us        99.78
    L1/TEX Cache Throughput           %        71.79
    L2 Cache Throughput               %        28.63
    SM Active Cycles              cycle    79,345.07
    Compute (SM) Throughput           %        81.18
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.45
    Achieved Active Warps Per SM           warp        43.42
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,493.33
    Total DRAM Elapsed Cycles        cycle    3,288,064
    Average L1 Active Cycles         cycle    79,345.07
    Total L1 Elapsed Cycles          cycle    2,440,900
    Average L2 Active Cycles         cycle    73,828.83
    Total L2 Elapsed Cycles          cycle    1,849,032
    Average SM Active Cycles         cycle    79,345.07
    Total SM Elapsed Cycles          cycle    2,440,900
    Average SMSP Active Cycles       cycle    79,118.12
    Total SMSP Elapsed Cycles        cycle    9,763,600
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       795.49
    Elapsed Cycles                cycle        3,059
    Memory Throughput                 %         0.89
    DRAM Throughput                   %         0.44
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.76
    L2 Cache Throughput               %         0.89
    SM Active Cycles              cycle       435.33
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.99
    Achieved Active Warps Per SM           warp         5.28
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.01%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        90.67
    Total DRAM Elapsed Cycles        cycle      123,904
    Average L1 Active Cycles         cycle       435.33
    Total L1 Elapsed Cycles          cycle       91,080
    Average L2 Active Cycles         cycle       240.62
    Total L2 Elapsed Cycles          cycle       69,288
    Average SM Active Cycles         cycle       435.33
    Total SM Elapsed Cycles          cycle       91,080
    Average SMSP Active Cycles       cycle       299.07
    Total SMSP Elapsed Cycles        cycle      364,320
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.732%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.87% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.622%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.38% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.732%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.87% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.268%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 63.21% above the average, while the minimum instance value is 84.62% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.22
    Elapsed Cycles                cycle       81,411
    Memory Throughput                 %        69.95
    DRAM Throughput                   %        44.78
    Duration                         us        99.62
    L1/TEX Cache Throughput           %        71.82
    L2 Cache Throughput               %        28.73
    SM Active Cycles              cycle    79,310.87
    Compute (SM) Throughput           %        81.10
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.39
    Achieved Active Warps Per SM           warp        43.39
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,952
    Total DRAM Elapsed Cycles        cycle    3,281,920
    Average L1 Active Cycles         cycle    79,310.87
    Total L1 Elapsed Cycles          cycle    2,442,790
    Average L2 Active Cycles         cycle    73,722.29
    Total L2 Elapsed Cycles          cycle    1,846,152
    Average SM Active Cycles         cycle    79,310.87
    Total SM Elapsed Cycles          cycle    2,442,790
    Average SMSP Active Cycles       cycle    79,066.38
    Total SMSP Elapsed Cycles        cycle    9,771,160
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       802.08
    Elapsed Cycles                cycle        3,082
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.36
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.75
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       435.83
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.07
    Achieved Active Warps Per SM           warp         5.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.93%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        74.67
    Total DRAM Elapsed Cycles        cycle      123,904
    Average L1 Active Cycles         cycle       435.83
    Total L1 Elapsed Cycles          cycle       92,210
    Average L2 Active Cycles         cycle       256.25
    Total L2 Elapsed Cycles          cycle       69,840
    Average SM Active Cycles         cycle       435.83
    Total SM Elapsed Cycles          cycle       92,210
    Average SMSP Active Cycles       cycle       302.43
    Total SMSP Elapsed Cycles        cycle      368,840
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.605%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.74% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.599%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.23% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.605%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.74% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.55%                                                                                           
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 63.02% above the average, while the minimum instance value is 85.56% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.28
    Elapsed Cycles                cycle       81,444
    Memory Throughput                 %        70.07
    DRAM Throughput                   %        42.49
    Duration                         us        99.65
    L1/TEX Cache Throughput           %        71.89
    L2 Cache Throughput               %        28.77
    SM Active Cycles              cycle    79,232.63
    Compute (SM) Throughput           %        81.22
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.40
    Achieved Active Warps Per SM           warp        43.39
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,477.33
    Total DRAM Elapsed Cycles        cycle    3,282,944
    Average L1 Active Cycles         cycle    79,232.63
    Total L1 Elapsed Cycles          cycle    2,438,550
    Average L2 Active Cycles         cycle    73,840.79
    Total L2 Elapsed Cycles          cycle    1,846,848
    Average SM Active Cycles         cycle    79,232.63
    Total SM Elapsed Cycles          cycle    2,438,550
    Average SMSP Active Cycles       cycle    78,970.48
    Total SMSP Elapsed Cycles        cycle    9,754,200
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.31
    Elapsed Cycles                cycle       81,395
    Memory Throughput                 %        70.12
    DRAM Throughput                   %        44.87
    Duration                         us        99.58
    L1/TEX Cache Throughput           %        71.80
    L2 Cache Throughput               %        28.75
    SM Active Cycles              cycle    79,328.93
    Compute (SM) Throughput           %        81.27
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.40
    Achieved Active Warps Per SM           warp        43.39
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,373.33
    Total DRAM Elapsed Cycles        cycle    3,280,896
    Average L1 Active Cycles         cycle    79,328.93
    Total L1 Elapsed Cycles          cycle    2,436,710
    Average L2 Active Cycles         cycle    73,684.38
    Total L2 Elapsed Cycles          cycle    1,845,768
    Average SM Active Cycles         cycle    79,328.93
    Total SM Elapsed Cycles          cycle    2,436,710
    Average SMSP Active Cycles       cycle    78,988.60
    Total SMSP Elapsed Cycles        cycle    9,746,840
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.08
    Elapsed Cycles                cycle       81,554
    Memory Throughput                 %        70.04
    DRAM Throughput                   %        42.38
    Duration                         us        99.81
    L1/TEX Cache Throughput           %        71.81
    L2 Cache Throughput               %        28.73
    SM Active Cycles              cycle    79,319.63
    Compute (SM) Throughput           %        81.15
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.41
    Achieved Active Warps Per SM           warp        43.40
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,165.33
    Total DRAM Elapsed Cycles        cycle    3,287,040
    Average L1 Active Cycles         cycle    79,319.63
    Total L1 Elapsed Cycles          cycle    2,439,590
    Average L2 Active Cycles         cycle    73,852.33
    Total L2 Elapsed Cycles          cycle    1,849,320
    Average SM Active Cycles         cycle    79,319.63
    Total SM Elapsed Cycles          cycle    2,439,590
    Average SMSP Active Cycles       cycle    78,964.32
    Total SMSP Elapsed Cycles        cycle    9,758,360
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.01
    Elapsed Cycles                cycle       81,394
    Memory Throughput                 %        69.91
    DRAM Throughput                   %        42.52
    Duration                         us        99.62
    L1/TEX Cache Throughput           %        71.85
    L2 Cache Throughput               %        28.74
    SM Active Cycles              cycle    79,268.27
    Compute (SM) Throughput           %        80.98
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.36
    Achieved Active Warps Per SM           warp        43.37
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,525.33
    Total DRAM Elapsed Cycles        cycle    3,280,896
    Average L1 Active Cycles         cycle    79,268.27
    Total L1 Elapsed Cycles          cycle    2,444,130
    Average L2 Active Cycles         cycle    73,835.33
    Total L2 Elapsed Cycles          cycle    1,845,696
    Average SM Active Cycles         cycle    79,268.27
    Total SM Elapsed Cycles          cycle    2,444,130
    Average SMSP Active Cycles       cycle    78,863.34
    Total SMSP Elapsed Cycles        cycle    9,776,520
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.24
    Elapsed Cycles                cycle       81,387
    Memory Throughput                 %        70.13
    DRAM Throughput                   %        42.48
    Duration                         us        99.58
    L1/TEX Cache Throughput           %        71.91
    L2 Cache Throughput               %        28.75
    SM Active Cycles              cycle    79,206.23
    Compute (SM) Throughput           %        81.21
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.39
    Achieved Active Warps Per SM           warp        43.39
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,285.33
    Total DRAM Elapsed Cycles        cycle    3,280,896
    Average L1 Active Cycles         cycle    79,206.23
    Total L1 Elapsed Cycles          cycle    2,436,360
    Average L2 Active Cycles         cycle    73,718.04
    Total L2 Elapsed Cycles          cycle    1,845,624
    Average SM Active Cycles         cycle    79,206.23
    Total SM Elapsed Cycles          cycle    2,436,360
    Average SMSP Active Cycles       cycle    78,877.98
    Total SMSP Elapsed Cycles        cycle    9,745,440
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.30
    Elapsed Cycles                cycle       81,369
    Memory Throughput                 %        70.05
    DRAM Throughput                   %        42.85
    Duration                         us        99.55
    L1/TEX Cache Throughput           %        71.90
    L2 Cache Throughput               %        28.71
    SM Active Cycles              cycle    79,213.57
    Compute (SM) Throughput           %        81.09
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.40
    Achieved Active Warps Per SM           warp        43.39
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   234,154.67
    Total DRAM Elapsed Cycles        cycle    3,278,848
    Average L1 Active Cycles         cycle    79,213.57
    Total L1 Elapsed Cycles          cycle    2,439,320
    Average L2 Active Cycles         cycle    73,780.62
    Total L2 Elapsed Cycles          cycle    1,845,168
    Average SM Active Cycles         cycle    79,213.57
    Total SM Elapsed Cycles          cycle    2,439,320
    Average SMSP Active Cycles       cycle    78,801.14
    Total SMSP Elapsed Cycles        cycle    9,757,280
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.28
    Elapsed Cycles                cycle       81,417
    Memory Throughput                 %        70.16
    DRAM Throughput                   %        42.47
    Duration                         us        99.62
    L1/TEX Cache Throughput           %        71.96
    L2 Cache Throughput               %        28.68
    SM Active Cycles              cycle    79,149.63
    Compute (SM) Throughput           %        81.20
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.42
    Achieved Active Warps Per SM           warp        43.40
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,378.67
    Total DRAM Elapsed Cycles        cycle    3,282,944
    Average L1 Active Cycles         cycle    79,149.63
    Total L1 Elapsed Cycles          cycle    2,435,370
    Average L2 Active Cycles         cycle    73,639.33
    Total L2 Elapsed Cycles          cycle    1,846,344
    Average SM Active Cycles         cycle    79,149.63
    Total SM Elapsed Cycles          cycle    2,435,370
    Average SMSP Active Cycles       cycle    78,905.50
    Total SMSP Elapsed Cycles        cycle    9,741,480
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.42
    SM Frequency                    Mhz       797.05
    Elapsed Cycles                cycle        3,064
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.37
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       429.03
    Compute (SM) Throughput           %         0.49
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.83
    Achieved Active Warps Per SM           warp         5.20
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.17%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      124,928
    Average L1 Active Cycles         cycle       429.03
    Total L1 Elapsed Cycles          cycle       93,720
    Average L2 Active Cycles         cycle       273.92
    Total L2 Elapsed Cycles          cycle       69,480
    Average SM Active Cycles         cycle       429.03
    Total SM Elapsed Cycles          cycle       93,720
    Average SMSP Active Cycles       cycle       297.20
    Total SMSP Elapsed Cycles        cycle      374,880
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.31%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.79% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.355%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.31% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.31%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.79% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.559%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 58.75% above the average, while the minimum instance value is 86.49% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.29
    Elapsed Cycles                cycle       81,316
    Memory Throughput                 %        70.18
    DRAM Throughput                   %        44.79
    Duration                         us        99.49
    L1/TEX Cache Throughput           %        71.88
    L2 Cache Throughput               %        28.79
    SM Active Cycles              cycle    79,236.87
    Compute (SM) Throughput           %        81.19
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.40
    Achieved Active Warps Per SM           warp        43.39
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,674.67
    Total DRAM Elapsed Cycles        cycle    3,277,824
    Average L1 Active Cycles         cycle    79,236.87
    Total L1 Elapsed Cycles          cycle    2,434,740
    Average L2 Active Cycles         cycle    73,667.21
    Total L2 Elapsed Cycles          cycle    1,843,992
    Average SM Active Cycles         cycle    79,236.87
    Total SM Elapsed Cycles          cycle    2,434,740
    Average SMSP Active Cycles       cycle    78,777.28
    Total SMSP Elapsed Cycles        cycle    9,738,960
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.42
    SM Frequency                    Mhz       798.99
    Elapsed Cycles                cycle        3,018
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.36
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.78
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       431.80
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.08
    Achieved Active Warps Per SM           warp         5.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.92%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        74.67
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       431.80
    Total L1 Elapsed Cycles          cycle       91,700
    Average L2 Active Cycles         cycle       213.42
    Total L2 Elapsed Cycles          cycle       68,472
    Average SM Active Cycles         cycle       431.80
    Total SM Elapsed Cycles          cycle       91,700
    Average SMSP Active Cycles       cycle       301.53
    Total SMSP Elapsed Cycles        cycle      366,800
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.523%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.41% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.598%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.02% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.523%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.41% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.29
    Elapsed Cycles                cycle       81,524
    Memory Throughput                 %        70.04
    DRAM Throughput                   %        44.75
    Duration                         us        99.74
    L1/TEX Cache Throughput           %        71.95
    L2 Cache Throughput               %        28.71
    SM Active Cycles              cycle    79,158.93
    Compute (SM) Throughput           %        81.01
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.38
    Achieved Active Warps Per SM           warp        43.38
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,981.33
    Total DRAM Elapsed Cycles        cycle    3,284,992
    Average L1 Active Cycles         cycle    79,158.93
    Total L1 Elapsed Cycles          cycle    2,439,540
    Average L2 Active Cycles         cycle    73,697.29
    Total L2 Elapsed Cycles          cycle    1,848,624
    Average SM Active Cycles         cycle    79,158.93
    Total SM Elapsed Cycles          cycle    2,439,540
    Average SMSP Active Cycles       cycle    79,001.86
    Total SMSP Elapsed Cycles        cycle    9,758,160
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.47
    Elapsed Cycles                cycle       81,204
    Memory Throughput                 %        70.10
    DRAM Throughput                   %        45.02
    Duration                         us        99.33
    L1/TEX Cache Throughput           %        72.04
    L2 Cache Throughput               %        28.80
    SM Active Cycles              cycle    79,061.83
    Compute (SM) Throughput           %        81.05
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.32
    Achieved Active Warps Per SM           warp        43.35
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,541.33
    Total DRAM Elapsed Cycles        cycle    3,272,704
    Average L1 Active Cycles         cycle    79,061.83
    Total L1 Elapsed Cycles          cycle    2,437,420
    Average L2 Active Cycles         cycle    73,518.17
    Total L2 Elapsed Cycles          cycle    1,841,424
    Average SM Active Cycles         cycle    79,061.83
    Total SM Elapsed Cycles          cycle    2,437,420
    Average SMSP Active Cycles       cycle    78,756.83
    Total SMSP Elapsed Cycles        cycle    9,749,680
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       796.23
    Elapsed Cycles                cycle        3,084
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.44
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.66
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       451.77
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.99
    Achieved Active Warps Per SM           warp         5.27
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.01%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        90.67
    Total DRAM Elapsed Cycles        cycle      124,928
    Average L1 Active Cycles         cycle       451.77
    Total L1 Elapsed Cycles          cycle       92,300
    Average L2 Active Cycles         cycle       240.88
    Total L2 Elapsed Cycles          cycle       69,960
    Average SM Active Cycles         cycle       451.77
    Total SM Elapsed Cycles          cycle       92,300
    Average SMSP Active Cycles       cycle       315.62
    Total SMSP Elapsed Cycles        cycle      369,200
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.949%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.75% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.029%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.26% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.949%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.75% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.114%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 61.89% above the average, while the minimum instance value is 84.64% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.20
    Elapsed Cycles                cycle       81,384
    Memory Throughput                 %        70.17
    DRAM Throughput                   %        42.43
    Duration                         us        99.58
    L1/TEX Cache Throughput           %        72.03
    L2 Cache Throughput               %        28.74
    SM Active Cycles              cycle    79,080.03
    Compute (SM) Throughput           %        81.11
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.38
    Achieved Active Warps Per SM           warp        43.38
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,962.67
    Total DRAM Elapsed Cycles        cycle    3,279,872
    Average L1 Active Cycles         cycle    79,080.03
    Total L1 Elapsed Cycles          cycle    2,435,020
    Average L2 Active Cycles         cycle    73,657.21
    Total L2 Elapsed Cycles          cycle    1,845,600
    Average SM Active Cycles         cycle    79,080.03
    Total SM Elapsed Cycles          cycle    2,435,020
    Average SMSP Active Cycles       cycle    78,785.07
    Total SMSP Elapsed Cycles        cycle    9,740,080
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       794.94
    Elapsed Cycles                cycle        3,079
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.39
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.61
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       459.97
    Compute (SM) Throughput           %         0.51
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.29
    Achieved Active Warps Per SM           warp         5.42
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.71%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      123,904
    Average L1 Active Cycles         cycle       459.97
    Total L1 Elapsed Cycles          cycle       91,330
    Average L2 Active Cycles         cycle       242.71
    Total L2 Elapsed Cycles          cycle       69,864
    Average SM Active Cycles         cycle       459.97
    Total SM Elapsed Cycles          cycle       91,330
    Average SMSP Active Cycles       cycle       313.43
    Total SMSP Elapsed Cycles        cycle      365,320
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.17%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.29% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.902%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.75% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.17%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.29% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.463%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 65.52% above the average, while the minimum instance value is 84.76% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.38
    Elapsed Cycles                cycle       81,269
    Memory Throughput                 %        70.10
    DRAM Throughput                   %        44.84
    Duration                         us        99.42
    L1/TEX Cache Throughput           %        72.11
    L2 Cache Throughput               %        28.81
    SM Active Cycles              cycle    78,987.60
    Compute (SM) Throughput           %        80.99
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.32
    Achieved Active Warps Per SM           warp        43.35
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,746.67
    Total DRAM Elapsed Cycles        cycle    3,274,752
    Average L1 Active Cycles         cycle    78,987.60
    Total L1 Elapsed Cycles          cycle    2,437,580
    Average L2 Active Cycles         cycle    73,707.62
    Total L2 Elapsed Cycles          cycle    1,842,960
    Average SM Active Cycles         cycle    78,987.60
    Total SM Elapsed Cycles          cycle    2,437,580
    Average SMSP Active Cycles       cycle    78,899.59
    Total SMSP Elapsed Cycles        cycle    9,750,320
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.40
    Elapsed Cycles                cycle       81,299
    Memory Throughput                 %        70.11
    DRAM Throughput                   %        44.83
    Duration                         us        99.46
    L1/TEX Cache Throughput           %        72.02
    L2 Cache Throughput               %        28.78
    SM Active Cycles              cycle    79,089.17
    Compute (SM) Throughput           %        80.96
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.35
    Achieved Active Warps Per SM           warp        43.37
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,770.67
    Total DRAM Elapsed Cycles        cycle    3,275,776
    Average L1 Active Cycles         cycle    79,089.17
    Total L1 Elapsed Cycles          cycle    2,437,360
    Average L2 Active Cycles         cycle    73,634.21
    Total L2 Elapsed Cycles          cycle    1,843,632
    Average SM Active Cycles         cycle    79,089.17
    Total SM Elapsed Cycles          cycle    2,437,360
    Average SMSP Active Cycles       cycle    78,734.71
    Total SMSP Elapsed Cycles        cycle    9,749,440
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       795.82
    Elapsed Cycles                cycle        3,007
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.39
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.81
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       427.13
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.11
    Achieved Active Warps Per SM           warp         5.33
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.89%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      121,856
    Average L1 Active Cycles         cycle       427.13
    Total L1 Elapsed Cycles          cycle       90,440
    Average L2 Active Cycles         cycle       263.92
    Total L2 Elapsed Cycles          cycle       68,184
    Average SM Active Cycles         cycle       427.13
    Total SM Elapsed Cycles          cycle       90,440
    Average SMSP Active Cycles       cycle       308.74
    Total SMSP Elapsed Cycles        cycle      361,760
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.538%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.32% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.842%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.57% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.538%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.32% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.7%                                                                                            
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 61.36% above the average, while the minimum instance value is 85.98% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.30
    Elapsed Cycles                cycle       81,160
    Memory Throughput                 %        70.06
    DRAM Throughput                   %        45.10
    Duration                         us        99.30
    L1/TEX Cache Throughput           %        72.02
    L2 Cache Throughput               %        28.82
    SM Active Cycles              cycle    79,083.63
    Compute (SM) Throughput           %        80.87
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.32
    Achieved Active Warps Per SM           warp        43.35
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,856
    Total DRAM Elapsed Cycles        cycle    3,270,656
    Average L1 Active Cycles         cycle    79,083.63
    Total L1 Elapsed Cycles          cycle    2,438,940
    Average L2 Active Cycles         cycle    73,457.58
    Total L2 Elapsed Cycles          cycle    1,840,464
    Average SM Active Cycles         cycle    79,083.63
    Total SM Elapsed Cycles          cycle    2,438,940
    Average SMSP Active Cycles       cycle    78,717.02
    Total SMSP Elapsed Cycles        cycle    9,755,760
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.41
    Elapsed Cycles                cycle       81,273
    Memory Throughput                 %        70.27
    DRAM Throughput                   %        42.72
    Duration                         us        99.42
    L1/TEX Cache Throughput           %        72.12
    L2 Cache Throughput               %        28.81
    SM Active Cycles              cycle    78,977.07
    Compute (SM) Throughput           %        81.07
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.31
    Achieved Active Warps Per SM           warp        43.35
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      233,232
    Total DRAM Elapsed Cycles        cycle    3,275,776
    Average L1 Active Cycles         cycle    78,977.07
    Total L1 Elapsed Cycles          cycle    2,431,610
    Average L2 Active Cycles         cycle    73,548.38
    Total L2 Elapsed Cycles          cycle    1,842,840
    Average SM Active Cycles         cycle    78,977.07
    Total SM Elapsed Cycles          cycle    2,431,610
    Average SMSP Active Cycles       cycle    78,866.52
    Total SMSP Elapsed Cycles        cycle    9,726,440
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.40
    Elapsed Cycles                cycle       81,271
    Memory Throughput                 %        70.32
    DRAM Throughput                   %        44.93
    Duration                         us        99.42
    L1/TEX Cache Throughput           %        72.17
    L2 Cache Throughput               %        28.79
    SM Active Cycles              cycle    78,918.27
    Compute (SM) Throughput           %        81.08
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.28
    Achieved Active Warps Per SM           warp        43.33
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,376
    Total DRAM Elapsed Cycles        cycle    3,276,800
    Average L1 Active Cycles         cycle    78,918.27
    Total L1 Elapsed Cycles          cycle    2,430,010
    Average L2 Active Cycles         cycle    73,473.38
    Total L2 Elapsed Cycles          cycle    1,842,984
    Average SM Active Cycles         cycle    78,918.27
    Total SM Elapsed Cycles          cycle    2,430,010
    Average SMSP Active Cycles       cycle    78,619.69
    Total SMSP Elapsed Cycles        cycle    9,720,040
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.34
    Elapsed Cycles                cycle       81,243
    Memory Throughput                 %        70.23
    DRAM Throughput                   %        45.00
    Duration                         us        99.39
    L1/TEX Cache Throughput           %        72.15
    L2 Cache Throughput               %        28.80
    SM Active Cycles              cycle    78,947.07
    Compute (SM) Throughput           %        80.93
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.23
    Achieved Active Warps Per SM           warp        43.31
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,610.67
    Total DRAM Elapsed Cycles        cycle    3,274,752
    Average L1 Active Cycles         cycle    78,947.07
    Total L1 Elapsed Cycles          cycle    2,432,940
    Average L2 Active Cycles         cycle    73,526.04
    Total L2 Elapsed Cycles          cycle    1,842,336
    Average SM Active Cycles         cycle    78,947.07
    Total SM Elapsed Cycles          cycle    2,432,940
    Average SMSP Active Cycles       cycle    78,620.27
    Total SMSP Elapsed Cycles        cycle    9,731,760
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.38
    Elapsed Cycles                cycle       81,166
    Memory Throughput                 %        70.45
    DRAM Throughput                   %        42.61
    Duration                         us        99.30
    L1/TEX Cache Throughput           %        72.22
    L2 Cache Throughput               %        28.87
    SM Active Cycles              cycle    78,871.23
    Compute (SM) Throughput           %        81.13
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.22
    Achieved Active Warps Per SM           warp        43.30
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      232,264
    Total DRAM Elapsed Cycles        cycle    3,270,656
    Average L1 Active Cycles         cycle    78,871.23
    Total L1 Elapsed Cycles          cycle    2,425,470
    Average L2 Active Cycles         cycle    73,493.92
    Total L2 Elapsed Cycles          cycle    1,840,464
    Average SM Active Cycles         cycle    78,871.23
    Total SM Elapsed Cycles          cycle    2,425,470
    Average SMSP Active Cycles       cycle    78,672.43
    Total SMSP Elapsed Cycles        cycle    9,701,880
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       801.12
    Elapsed Cycles                cycle        3,054
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.39
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.78
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       431.57
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.08
    Achieved Active Warps Per SM           warp         5.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.92%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       431.57
    Total L1 Elapsed Cycles          cycle       92,500
    Average L2 Active Cycles         cycle          248
    Total L2 Elapsed Cycles          cycle       69,264
    Average SM Active Cycles         cycle       431.57
    Total SM Elapsed Cycles          cycle       92,500
    Average SMSP Active Cycles       cycle       299.28
    Total SMSP Elapsed Cycles        cycle      370,000
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.496%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.84% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.497%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.24% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.496%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.84% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.012%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 58.32% above the average, while the minimum instance value is 85.08% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.49
    Elapsed Cycles                cycle       81,204
    Memory Throughput                 %        70.40
    DRAM Throughput                   %        45.07
    Duration                         us        99.33
    L1/TEX Cache Throughput           %        72.15
    L2 Cache Throughput               %        28.77
    SM Active Cycles              cycle    78,939.07
    Compute (SM) Throughput           %        81.03
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.21
    Achieved Active Warps Per SM           warp        43.30
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,837.33
    Total DRAM Elapsed Cycles        cycle    3,272,704
    Average L1 Active Cycles         cycle    78,939.07
    Total L1 Elapsed Cycles          cycle    2,427,080
    Average L2 Active Cycles         cycle    73,559.50
    Total L2 Elapsed Cycles          cycle    1,841,448
    Average SM Active Cycles         cycle    78,939.07
    Total SM Elapsed Cycles          cycle    2,427,080
    Average SMSP Active Cycles       cycle    78,592.85
    Total SMSP Elapsed Cycles        cycle    9,708,320
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.19
    Elapsed Cycles                cycle       81,043
    Memory Throughput                 %        70.42
    DRAM Throughput                   %        45.07
    Duration                         us        99.17
    L1/TEX Cache Throughput           %        72.09
    L2 Cache Throughput               %        28.91
    SM Active Cycles              cycle    79,006.57
    Compute (SM) Throughput           %        81.00
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.17
    Achieved Active Warps Per SM           warp        43.28
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,474.67
    Total DRAM Elapsed Cycles        cycle    3,267,584
    Average L1 Active Cycles         cycle    79,006.57
    Total L1 Elapsed Cycles          cycle    2,426,560
    Average L2 Active Cycles         cycle    73,420.08
    Total L2 Elapsed Cycles          cycle    1,837,704
    Average SM Active Cycles         cycle    79,006.57
    Total SM Elapsed Cycles          cycle    2,426,560
    Average SMSP Active Cycles       cycle    78,712.89
    Total SMSP Elapsed Cycles        cycle    9,706,240
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.14
    Elapsed Cycles                cycle       80,962
    Memory Throughput                 %        70.40
    DRAM Throughput                   %        45.02
    Duration                         us        99.07
    L1/TEX Cache Throughput           %        72.24
    L2 Cache Throughput               %        28.89
    SM Active Cycles              cycle    78,840.17
    Compute (SM) Throughput           %        80.93
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.19
    Achieved Active Warps Per SM           warp        43.29
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,845.33
    Total DRAM Elapsed Cycles        cycle    3,263,488
    Average L1 Active Cycles         cycle    78,840.17
    Total L1 Elapsed Cycles          cycle    2,427,140
    Average L2 Active Cycles         cycle    73,399.96
    Total L2 Elapsed Cycles          cycle    1,835,712
    Average SM Active Cycles         cycle    78,840.17
    Total SM Elapsed Cycles          cycle    2,427,140
    Average SMSP Active Cycles       cycle    78,567.02
    Total SMSP Elapsed Cycles        cycle    9,708,560
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       796.09
    Elapsed Cycles                cycle        3,061
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.40
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.77
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       433.33
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.09
    Achieved Active Warps Per SM           warp         5.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.91%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        82.67
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       433.33
    Total L1 Elapsed Cycles          cycle       90,750
    Average L2 Active Cycles         cycle       300.08
    Total L2 Elapsed Cycles          cycle       69,408
    Average SM Active Cycles         cycle       433.33
    Total SM Elapsed Cycles          cycle       90,750
    Average SMSP Active Cycles       cycle       301.57
    Total SMSP Elapsed Cycles        cycle      363,000
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.734%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.95% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.792%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.16% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.734%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.95% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.426%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 52.29% above the average, while the minimum instance value is 87.67% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.35
    Elapsed Cycles                cycle       81,032
    Memory Throughput                 %        70.60
    DRAM Throughput                   %        44.97
    Duration                         us        99.14
    L1/TEX Cache Throughput           %        72.35
    L2 Cache Throughput               %        28.87
    SM Active Cycles              cycle    78,728.63
    Compute (SM) Throughput           %        81.10
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.14
    Achieved Active Warps Per SM           warp        43.27
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,752
    Total DRAM Elapsed Cycles        cycle    3,265,536
    Average L1 Active Cycles         cycle    78,728.63
    Total L1 Elapsed Cycles          cycle    2,420,360
    Average L2 Active Cycles         cycle    73,270.54
    Total L2 Elapsed Cycles          cycle    1,837,392
    Average SM Active Cycles         cycle    78,728.63
    Total SM Elapsed Cycles          cycle    2,420,360
    Average SMSP Active Cycles       cycle    78,449.74
    Total SMSP Elapsed Cycles        cycle    9,681,440
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.34
    Elapsed Cycles                cycle       81,114
    Memory Throughput                 %        70.47
    DRAM Throughput                   %        44.97
    Duration                         us        99.23
    L1/TEX Cache Throughput           %        72.35
    L2 Cache Throughput               %        28.84
    SM Active Cycles              cycle    78,721.87
    Compute (SM) Throughput           %        80.89
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.18
    Achieved Active Warps Per SM           warp        43.29
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,050.67
    Total DRAM Elapsed Cycles        cycle    3,269,632
    Average L1 Active Cycles         cycle    78,721.87
    Total L1 Elapsed Cycles          cycle    2,424,910
    Average L2 Active Cycles         cycle    73,269.25
    Total L2 Elapsed Cycles          cycle    1,839,312
    Average SM Active Cycles         cycle    78,721.87
    Total SM Elapsed Cycles          cycle    2,424,910
    Average SMSP Active Cycles       cycle    78,381.30
    Total SMSP Elapsed Cycles        cycle    9,699,640
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.42
    SM Frequency                    Mhz       800.28
    Elapsed Cycles                cycle        3,104
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.37
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.73
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       440.10
    Compute (SM) Throughput           %         0.54
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.16
    Achieved Active Warps Per SM           warp         5.36
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.84%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      125,952
    Average L1 Active Cycles         cycle       440.10
    Total L1 Elapsed Cycles          cycle       92,760
    Average L2 Active Cycles         cycle       262.21
    Total L2 Elapsed Cycles          cycle       70,272
    Average SM Active Cycles         cycle       440.10
    Total SM Elapsed Cycles          cycle       92,760
    Average SMSP Active Cycles       cycle       343.02
    Total SMSP Elapsed Cycles        cycle      371,040
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.634%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.69% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.457%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.23% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.634%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.69% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.18%                                                                                           
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 57.84% above the average, while the minimum instance value is 85.89% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.24
    Elapsed Cycles                cycle       80,734
    Memory Throughput                 %        70.56
    DRAM Throughput                   %        42.74
    Duration                         us        98.78
    L1/TEX Cache Throughput           %        72.47
    L2 Cache Throughput               %        28.99
    SM Active Cycles              cycle    78,600.60
    Compute (SM) Throughput           %        80.94
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.21
    Achieved Active Warps Per SM           warp        43.30
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,829.33
    Total DRAM Elapsed Cycles        cycle    3,254,272
    Average L1 Active Cycles         cycle    78,600.60
    Total L1 Elapsed Cycles          cycle    2,421,660
    Average L2 Active Cycles         cycle    73,295.38
    Total L2 Elapsed Cycles          cycle    1,830,768
    Average SM Active Cycles         cycle    78,600.60
    Total SM Elapsed Cycles          cycle    2,421,660
    Average SMSP Active Cycles       cycle    78,365.06
    Total SMSP Elapsed Cycles        cycle    9,686,640
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.27
    Elapsed Cycles                cycle       80,787
    Memory Throughput                 %        70.62
    DRAM Throughput                   %        42.72
    Duration                         us        98.85
    L1/TEX Cache Throughput           %        72.36
    L2 Cache Throughput               %        28.95
    SM Active Cycles              cycle    78,719.10
    Compute (SM) Throughput           %        80.95
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.18
    Achieved Active Warps Per SM           warp        43.28
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      231,840
    Total DRAM Elapsed Cycles        cycle    3,256,320
    Average L1 Active Cycles         cycle    78,719.10
    Total L1 Elapsed Cycles          cycle    2,419,520
    Average L2 Active Cycles         cycle    73,209.79
    Total L2 Elapsed Cycles          cycle    1,832,016
    Average SM Active Cycles         cycle    78,719.10
    Total SM Elapsed Cycles          cycle    2,419,520
    Average SMSP Active Cycles       cycle    78,382.02
    Total SMSP Elapsed Cycles        cycle    9,678,080
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.42
    SM Frequency                    Mhz       801.74
    Elapsed Cycles                cycle        3,158
    Memory Throughput                 %         0.84
    DRAM Throughput                   %         0.44
    Duration                         us         3.94
    L1/TEX Cache Throughput           %         2.78
    L2 Cache Throughput               %         0.84
    SM Active Cycles              cycle       431.37
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.03
    Achieved Active Warps Per SM           warp         5.29
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.97%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        93.33
    Total DRAM Elapsed Cycles        cycle      128,000
    Average L1 Active Cycles         cycle       431.37
    Total L1 Elapsed Cycles          cycle       90,460
    Average L2 Active Cycles         cycle       263.42
    Total L2 Elapsed Cycles          cycle       71,520
    Average SM Active Cycles         cycle       431.37
    Total SM Elapsed Cycles          cycle       90,460
    Average SMSP Active Cycles       cycle       299.06
    Total SMSP Elapsed Cycles        cycle      361,840
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.648%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.44% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.636%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.00% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.648%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.44% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.747%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 65.02% above the average, while the minimum instance value is 85.95% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.30
    Elapsed Cycles                cycle       80,818
    Memory Throughput                 %        70.65
    DRAM Throughput                   %        42.66
    Duration                         us        98.88
    L1/TEX Cache Throughput           %        72.37
    L2 Cache Throughput               %        28.96
    SM Active Cycles              cycle    78,706.47
    Compute (SM) Throughput           %        80.93
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.11
    Achieved Active Warps Per SM           warp        43.25
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      231,648
    Total DRAM Elapsed Cycles        cycle    3,258,368
    Average L1 Active Cycles         cycle    78,706.47
    Total L1 Elapsed Cycles          cycle    2,418,610
    Average L2 Active Cycles         cycle    73,203.83
    Total L2 Elapsed Cycles          cycle    1,832,640
    Average SM Active Cycles         cycle    78,706.47
    Total SM Elapsed Cycles          cycle    2,418,610
    Average SMSP Active Cycles       cycle    78,295.20
    Total SMSP Elapsed Cycles        cycle    9,674,440
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.09
    Elapsed Cycles                cycle       80,773
    Memory Throughput                 %        70.69
    DRAM Throughput                   %        42.70
    Duration                         us        98.85
    L1/TEX Cache Throughput           %        72.42
    L2 Cache Throughput               %        28.97
    SM Active Cycles              cycle       78,650
    Compute (SM) Throughput           %        80.92
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.12
    Achieved Active Warps Per SM           warp        43.26
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,642.67
    Total DRAM Elapsed Cycles        cycle    3,255,296
    Average L1 Active Cycles         cycle       78,650
    Total L1 Elapsed Cycles          cycle    2,417,320
    Average L2 Active Cycles         cycle    73,262.79
    Total L2 Elapsed Cycles          cycle    1,831,320
    Average SM Active Cycles         cycle       78,650
    Total SM Elapsed Cycles          cycle    2,417,320
    Average SMSP Active Cycles       cycle    78,302.81
    Total SMSP Elapsed Cycles        cycle    9,669,280
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.42
    Elapsed Cycles                cycle       80,700
    Memory Throughput                 %        70.63
    DRAM Throughput                   %        44.71
    Duration                         us        98.72
    L1/TEX Cache Throughput           %        72.58
    L2 Cache Throughput               %        28.98
    SM Active Cycles              cycle    78,480.60
    Compute (SM) Throughput           %        80.79
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.05
    Achieved Active Warps Per SM           warp        43.23
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      242,416
    Total DRAM Elapsed Cycles        cycle    3,253,248
    Average L1 Active Cycles         cycle    78,480.60
    Total L1 Elapsed Cycles          cycle    2,419,250
    Average L2 Active Cycles         cycle       73,085
    Total L2 Elapsed Cycles          cycle    1,829,952
    Average SM Active Cycles         cycle    78,480.60
    Total SM Elapsed Cycles          cycle    2,419,250
    Average SMSP Active Cycles       cycle    78,245.70
    Total SMSP Elapsed Cycles        cycle    9,677,000
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       796.35
    Elapsed Cycles                cycle        3,060
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.36
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.79
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       430.03
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.02
    Achieved Active Warps Per SM           warp         5.29
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.98%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        74.67
    Total DRAM Elapsed Cycles        cycle      123,904
    Average L1 Active Cycles         cycle       430.03
    Total L1 Elapsed Cycles          cycle       90,220
    Average L2 Active Cycles         cycle       227.42
    Total L2 Elapsed Cycles          cycle       69,408
    Average SM Active Cycles         cycle       430.03
    Total SM Elapsed Cycles          cycle       90,220
    Average SMSP Active Cycles       cycle       301.15
    Total SMSP Elapsed Cycles        cycle      360,880
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.71%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.91% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.738%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.27% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.71%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.91% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.17%                                                                                           
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 65.75% above the average, while the minimum instance value is 83.73% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.40
    Elapsed Cycles                cycle       80,880
    Memory Throughput                 %        70.67
    DRAM Throughput                   %        45.12
    Duration                         us        98.94
    L1/TEX Cache Throughput           %        72.62
    L2 Cache Throughput               %        28.88
    SM Active Cycles              cycle    78,432.17
    Compute (SM) Throughput           %        80.77
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.09
    Achieved Active Warps Per SM           warp        43.24
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,253.33
    Total DRAM Elapsed Cycles        cycle    3,261,440
    Average L1 Active Cycles         cycle    78,432.17
    Total L1 Elapsed Cycles          cycle    2,417,840
    Average L2 Active Cycles         cycle    73,123.54
    Total L2 Elapsed Cycles          cycle    1,833,912
    Average SM Active Cycles         cycle    78,432.17
    Total SM Elapsed Cycles          cycle    2,417,840
    Average SMSP Active Cycles       cycle    78,163.97
    Total SMSP Elapsed Cycles        cycle    9,671,360
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       799.28
    Elapsed Cycles                cycle        3,046
    Memory Throughput                 %         0.97
    DRAM Throughput                   %         0.38
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.81
    L2 Cache Throughput               %         0.97
    SM Active Cycles              cycle       427.47
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.01
    Achieved Active Warps Per SM           warp         5.28
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.99%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       427.47
    Total L1 Elapsed Cycles          cycle       91,240
    Average L2 Active Cycles         cycle       254.08
    Total L2 Elapsed Cycles          cycle       69,144
    Average SM Active Cycles         cycle       427.47
    Total SM Elapsed Cycles          cycle       91,240
    Average SMSP Active Cycles       cycle       303.14
    Total SMSP Elapsed Cycles        cycle      364,960
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.572%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 68.10% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.843%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 78.68% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.572%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 68.10% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.028%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 57.01% above the average, while the minimum instance value is 85.44% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.32
    Elapsed Cycles                cycle       80,638
    Memory Throughput                 %        70.76
    DRAM Throughput                   %        45.14
    Duration                         us        98.66
    L1/TEX Cache Throughput           %        72.58
    L2 Cache Throughput               %        29.03
    SM Active Cycles              cycle    78,473.60
    Compute (SM) Throughput           %        80.81
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.99
    Achieved Active Warps Per SM           warp        43.20
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.01%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (90.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,501.33
    Total DRAM Elapsed Cycles        cycle    3,250,176
    Average L1 Active Cycles         cycle    78,473.60
    Total L1 Elapsed Cycles          cycle    2,414,730
    Average L2 Active Cycles         cycle    73,027.58
    Total L2 Elapsed Cycles          cycle    1,828,344
    Average SM Active Cycles         cycle    78,473.60
    Total SM Elapsed Cycles          cycle    2,414,730
    Average SMSP Active Cycles       cycle    78,259.93
    Total SMSP Elapsed Cycles        cycle    9,658,920
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       803.83
    Elapsed Cycles                cycle        3,064
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.35
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.79
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       430.73
    Compute (SM) Throughput           %         0.54
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.07
    Achieved Active Warps Per SM           warp         5.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.93%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           72
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       430.73
    Total L1 Elapsed Cycles          cycle       92,940
    Average L2 Active Cycles         cycle       250.67
    Total L2 Elapsed Cycles          cycle       69,384
    Average SM Active Cycles         cycle       430.73
    Total SM Elapsed Cycles          cycle       92,940
    Average SMSP Active Cycles       cycle       301.12
    Total SMSP Elapsed Cycles        cycle      371,760
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.391%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.54% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.499%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.15% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.391%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.54% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.226%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 60.27% above the average, while the minimum instance value is 85.24% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.11
    Elapsed Cycles                cycle       80,566
    Memory Throughput                 %        70.60
    DRAM Throughput                   %        42.74
    Duration                         us        98.59
    L1/TEX Cache Throughput           %        72.61
    L2 Cache Throughput               %        29.05
    SM Active Cycles              cycle       78,446
    Compute (SM) Throughput           %        80.55
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.05
    Achieved Active Warps Per SM           warp        43.22
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      231,312
    Total DRAM Elapsed Cycles        cycle    3,247,104
    Average L1 Active Cycles         cycle       78,446
    Total L1 Elapsed Cycles          cycle    2,420,310
    Average L2 Active Cycles         cycle    73,029.17
    Total L2 Elapsed Cycles          cycle    1,826,976
    Average SM Active Cycles         cycle       78,446
    Total SM Elapsed Cycles          cycle    2,420,310
    Average SMSP Active Cycles       cycle    78,143.38
    Total SMSP Elapsed Cycles        cycle    9,681,240
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       799.05
    Elapsed Cycles                cycle        3,070
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.40
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.61
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       459.67
    Compute (SM) Throughput           %         0.54
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.60
    Achieved Active Warps Per SM           warp         5.09
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.4%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        82.67
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       459.67
    Total L1 Elapsed Cycles          cycle       92,850
    Average L2 Active Cycles         cycle       230.04
    Total L2 Elapsed Cycles          cycle       69,528
    Average SM Active Cycles         cycle       459.67
    Total SM Elapsed Cycles          cycle       92,850
    Average SMSP Active Cycles       cycle       301.52
    Total SMSP Elapsed Cycles        cycle      371,400
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.02%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.45% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.548%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.48% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.02%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.45% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.31
    Elapsed Cycles                cycle       80,478
    Memory Throughput                 %        70.85
    DRAM Throughput                   %        43.03
    Duration                         us        98.46
    L1/TEX Cache Throughput           %        72.67
    L2 Cache Throughput               %        29.09
    SM Active Cycles              cycle    78,373.63
    Compute (SM) Throughput           %        80.75
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.95
    Achieved Active Warps Per SM           warp        43.17
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.05%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,501.33
    Total DRAM Elapsed Cycles        cycle    3,241,984
    Average L1 Active Cycles         cycle    78,373.63
    Total L1 Elapsed Cycles          cycle    2,411,870
    Average L2 Active Cycles         cycle    73,124.54
    Total L2 Elapsed Cycles          cycle    1,825,008
    Average SM Active Cycles         cycle    78,373.63
    Total SM Elapsed Cycles          cycle    2,411,870
    Average SMSP Active Cycles       cycle    78,015.95
    Total SMSP Elapsed Cycles        cycle    9,647,480
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.18
    Elapsed Cycles                cycle       80,492
    Memory Throughput                 %        70.70
    DRAM Throughput                   %        45.38
    Duration                         us        98.50
    L1/TEX Cache Throughput           %        72.89
    L2 Cache Throughput               %        29.07
    SM Active Cycles              cycle    78,147.33
    Compute (SM) Throughput           %        80.51
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        90.01
    Achieved Active Warps Per SM           warp        43.20
    ------------------------------- ----------- ------------

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,349.33
    Total DRAM Elapsed Cycles        cycle    3,244,032
    Average L1 Active Cycles         cycle    78,147.33
    Total L1 Elapsed Cycles          cycle    2,416,850
    Average L2 Active Cycles         cycle    72,939.83
    Total L2 Elapsed Cycles          cycle    1,825,440
    Average SM Active Cycles         cycle    78,147.33
    Total SM Elapsed Cycles          cycle    2,416,850
    Average SMSP Active Cycles       cycle    77,906.07
    Total SMSP Elapsed Cycles        cycle    9,667,400
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       801.91
    Elapsed Cycles                cycle        3,057
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.44
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.73
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle          439
    Compute (SM) Throughput           %         0.54
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.13
    Achieved Active Warps Per SM           warp         5.34
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.87%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        90.67
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle          439
    Total L1 Elapsed Cycles          cycle       92,800
    Average L2 Active Cycles         cycle       259.88
    Total L2 Elapsed Cycles          cycle       69,288
    Average SM Active Cycles         cycle          439
    Total SM Elapsed Cycles          cycle       92,800
    Average SMSP Active Cycles       cycle       308.71
    Total SMSP Elapsed Cycles        cycle      371,200
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.614%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.74% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.684%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.00% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.614%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.74% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.306%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 58.95% above the average, while the minimum instance value is 85.76% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.10
    Elapsed Cycles                cycle       80,277
    Memory Throughput                 %        70.83
    DRAM Throughput                   %        45.49
    Duration                         us        98.24
    L1/TEX Cache Throughput           %        72.78
    L2 Cache Throughput               %        29.18
    SM Active Cycles              cycle    78,256.87
    Compute (SM) Throughput           %        80.57
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.94
    Achieved Active Warps Per SM           warp        43.17
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.06%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,434.67
    Total DRAM Elapsed Cycles        cycle    3,236,864
    Average L1 Active Cycles         cycle    78,256.87
    Total L1 Elapsed Cycles          cycle    2,412,530
    Average L2 Active Cycles         cycle    72,891.62
    Total L2 Elapsed Cycles          cycle    1,820,400
    Average SM Active Cycles         cycle    78,256.87
    Total SM Elapsed Cycles          cycle    2,412,530
    Average SMSP Active Cycles       cycle    77,904.75
    Total SMSP Elapsed Cycles        cycle    9,650,120
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.29
    Elapsed Cycles                cycle       80,426
    Memory Throughput                 %        71.08
    DRAM Throughput                   %        43.00
    Duration                         us        98.40
    L1/TEX Cache Throughput           %        72.88
    L2 Cache Throughput               %        29.09
    SM Active Cycles              cycle    78,157.70
    Compute (SM) Throughput           %        80.78
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.93
    Achieved Active Warps Per SM           warp        43.17
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.07%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,258.67
    Total DRAM Elapsed Cycles        cycle    3,240,960
    Average L1 Active Cycles         cycle    78,157.70
    Total L1 Elapsed Cycles          cycle    2,403,960
    Average L2 Active Cycles         cycle    72,805.79
    Total L2 Elapsed Cycles          cycle    1,823,808
    Average SM Active Cycles         cycle    78,157.70
    Total SM Elapsed Cycles          cycle    2,403,960
    Average SMSP Active Cycles       cycle    77,887.97
    Total SMSP Elapsed Cycles        cycle    9,615,840
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.12
    Elapsed Cycles                cycle       80,277
    Memory Throughput                 %        70.90
    DRAM Throughput                   %        45.57
    Duration                         us        98.24
    L1/TEX Cache Throughput           %        72.88
    L2 Cache Throughput               %        29.06
    SM Active Cycles              cycle    78,156.53
    Compute (SM) Throughput           %        80.50
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.88
    Achieved Active Warps Per SM           warp        43.14
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.12%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,770.67
    Total DRAM Elapsed Cycles        cycle    3,235,840
    Average L1 Active Cycles         cycle    78,156.53
    Total L1 Elapsed Cycles          cycle    2,410,070
    Average L2 Active Cycles         cycle    72,771.92
    Total L2 Elapsed Cycles          cycle    1,820,472
    Average SM Active Cycles         cycle    78,156.53
    Total SM Elapsed Cycles          cycle    2,410,070
    Average SMSP Active Cycles       cycle    77,754.17
    Total SMSP Elapsed Cycles        cycle    9,640,280
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.53
    Elapsed Cycles                cycle       80,265
    Memory Throughput                 %        70.78
    DRAM Throughput                   %        42.92
    Duration                         us        98.18
    L1/TEX Cache Throughput           %        72.91
    L2 Cache Throughput               %        29.16
    SM Active Cycles              cycle    78,119.70
    Compute (SM) Throughput           %        80.28
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.92
    Achieved Active Warps Per SM           warp        43.16
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.08%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      231,376
    Total DRAM Elapsed Cycles        cycle    3,234,816
    Average L1 Active Cycles         cycle    78,119.70
    Total L1 Elapsed Cycles          cycle    2,414,090
    Average L2 Active Cycles         cycle    72,666.21
    Total L2 Elapsed Cycles          cycle    1,820,088
    Average SM Active Cycles         cycle    78,119.70
    Total SM Elapsed Cycles          cycle    2,414,090
    Average SMSP Active Cycles       cycle    77,885.10
    Total SMSP Elapsed Cycles        cycle    9,656,360
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.36
    Elapsed Cycles                cycle       80,405
    Memory Throughput                 %        71.15
    DRAM Throughput                   %        45.28
    Duration                         us        98.37
    L1/TEX Cache Throughput           %        72.95
    L2 Cache Throughput               %        29.08
    SM Active Cycles              cycle    78,077.47
    Compute (SM) Throughput           %        80.62
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.83
    Achieved Active Warps Per SM           warp        43.12
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.17%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,576
    Total DRAM Elapsed Cycles        cycle    3,240,960
    Average L1 Active Cycles         cycle    78,077.47
    Total L1 Elapsed Cycles          cycle    2,401,670
    Average L2 Active Cycles         cycle    72,706.67
    Total L2 Elapsed Cycles          cycle    1,823,352
    Average SM Active Cycles         cycle    78,077.47
    Total SM Elapsed Cycles          cycle    2,401,670
    Average SMSP Active Cycles       cycle    77,749.78
    Total SMSP Elapsed Cycles        cycle    9,606,680
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.42
    SM Frequency                    Mhz       804.64
    Elapsed Cycles                cycle        3,040
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.36
    Duration                         us         3.78
    L1/TEX Cache Throughput           %         2.72
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       440.50
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.19
    Achieved Active Warps Per SM           warp         5.37
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.81%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        74.67
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       440.50
    Total L1 Elapsed Cycles          cycle       90,260
    Average L2 Active Cycles         cycle       259.62
    Total L2 Elapsed Cycles          cycle       68,976
    Average SM Active Cycles         cycle       440.50
    Total SM Elapsed Cycles          cycle       90,260
    Average SMSP Active Cycles       cycle       310.81
    Total SMSP Elapsed Cycles        cycle      361,040
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.85%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.27% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.949%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.94% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.85%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.27% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.201%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 57.58% above the average, while the minimum instance value is 85.75% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.23
    Elapsed Cycles                cycle       80,260
    Memory Throughput                 %        70.89
    DRAM Throughput                   %        45.45
    Duration                         us        98.21
    L1/TEX Cache Throughput           %        72.96
    L2 Cache Throughput               %        29.14
    SM Active Cycles              cycle    78,072.53
    Compute (SM) Throughput           %        80.25
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.81
    Achieved Active Warps Per SM           warp        43.11
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.19%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,016
    Total DRAM Elapsed Cycles        cycle    3,234,816
    Average L1 Active Cycles         cycle    78,072.53
    Total L1 Elapsed Cycles          cycle    2,410,270
    Average L2 Active Cycles         cycle    72,653.83
    Total L2 Elapsed Cycles          cycle    1,819,944
    Average SM Active Cycles         cycle    78,072.53
    Total SM Elapsed Cycles          cycle    2,410,270
    Average SMSP Active Cycles       cycle    77,599.06
    Total SMSP Elapsed Cycles        cycle    9,641,080
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       798.41
    Elapsed Cycles                cycle        3,118
    Memory Throughput                 %         0.85
    DRAM Throughput                   %         0.42
    Duration                         us         3.90
    L1/TEX Cache Throughput           %         2.72
    L2 Cache Throughput               %         0.85
    SM Active Cycles              cycle       441.83
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.14
    Achieved Active Warps Per SM           warp         5.35
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.86%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           88
    Total DRAM Elapsed Cycles        cycle      125,952
    Average L1 Active Cycles         cycle       441.83
    Total L1 Elapsed Cycles          cycle       90,980
    Average L2 Active Cycles         cycle       256.92
    Total L2 Elapsed Cycles          cycle       70,776
    Average SM Active Cycles         cycle       441.83
    Total SM Elapsed Cycles          cycle       90,980
    Average SMSP Active Cycles       cycle       308.31
    Total SMSP Elapsed Cycles        cycle      363,920
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.853%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.63% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.829%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.01% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.853%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.63% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.049%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 57.95% above the average, while the minimum instance value is 85.60% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.18
    Elapsed Cycles                cycle       80,204
    Memory Throughput                 %        71.08
    DRAM Throughput                   %        45.58
    Duration                         us        98.14
    L1/TEX Cache Throughput           %        73.10
    L2 Cache Throughput               %        29.15
    SM Active Cycles              cycle    77,919.63
    Compute (SM) Throughput           %        80.39
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.76
    Achieved Active Warps Per SM           warp        43.08
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.24%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,568
    Total DRAM Elapsed Cycles        cycle    3,232,768
    Average L1 Active Cycles         cycle    77,919.63
    Total L1 Elapsed Cycles          cycle    2,404,010
    Average L2 Active Cycles         cycle    72,727.83
    Total L2 Elapsed Cycles          cycle    1,818,816
    Average SM Active Cycles         cycle    77,919.63
    Total SM Elapsed Cycles          cycle    2,404,010
    Average SMSP Active Cycles       cycle    77,635.65
    Total SMSP Elapsed Cycles        cycle    9,616,040
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.46
    Elapsed Cycles                cycle       80,288
    Memory Throughput                 %        71.05
    DRAM Throughput                   %        42.96
    Duration                         us        98.21
    L1/TEX Cache Throughput           %        73.09
    L2 Cache Throughput               %        29.14
    SM Active Cycles              cycle    77,925.97
    Compute (SM) Throughput           %        80.27
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.82
    Achieved Active Warps Per SM           warp        43.11
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.18%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,741.33
    Total DRAM Elapsed Cycles        cycle    3,236,864
    Average L1 Active Cycles         cycle    77,925.97
    Total L1 Elapsed Cycles          cycle    2,405,020
    Average L2 Active Cycles         cycle    72,581.21
    Total L2 Elapsed Cycles          cycle    1,820,520
    Average SM Active Cycles         cycle    77,925.97
    Total SM Elapsed Cycles          cycle    2,405,020
    Average SMSP Active Cycles       cycle    77,671.85
    Total SMSP Elapsed Cycles        cycle    9,620,080
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.31
    Elapsed Cycles                cycle       80,166
    Memory Throughput                 %        71.35
    DRAM Throughput                   %        45.55
    Duration                         us        98.08
    L1/TEX Cache Throughput           %        73.17
    L2 Cache Throughput               %        29.11
    SM Active Cycles              cycle    77,848.13
    Compute (SM) Throughput           %        80.53
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.71
    Achieved Active Warps Per SM           warp        43.06
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.29%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,264
    Total DRAM Elapsed Cycles        cycle    3,230,720
    Average L1 Active Cycles         cycle    77,848.13
    Total L1 Elapsed Cycles          cycle    2,394,970
    Average L2 Active Cycles         cycle    72,525.04
    Total L2 Elapsed Cycles          cycle    1,817,928
    Average SM Active Cycles         cycle    77,848.13
    Total SM Elapsed Cycles          cycle    2,394,970
    Average SMSP Active Cycles       cycle    77,551.12
    Total SMSP Elapsed Cycles        cycle    9,579,880
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.31
    Elapsed Cycles                cycle       80,296
    Memory Throughput                 %        71.38
    DRAM Throughput                   %        45.46
    Duration                         us        98.24
    L1/TEX Cache Throughput           %        73.12
    L2 Cache Throughput               %        29.14
    SM Active Cycles              cycle    77,901.57
    Compute (SM) Throughput           %        80.50
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.68
    Achieved Active Warps Per SM           warp        43.05
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.32%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,192
    Total DRAM Elapsed Cycles        cycle    3,235,840
    Average L1 Active Cycles         cycle    77,901.57
    Total L1 Elapsed Cycles          cycle    2,393,940
    Average L2 Active Cycles         cycle    72,549.46
    Total L2 Elapsed Cycles          cycle    1,820,832
    Average SM Active Cycles         cycle    77,901.57
    Total SM Elapsed Cycles          cycle    2,393,940
    Average SMSP Active Cycles       cycle    77,532.90
    Total SMSP Elapsed Cycles        cycle    9,575,760
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       796.88
    Elapsed Cycles                cycle        3,061
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.38
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.78
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       430.97
    Compute (SM) Throughput           %         0.49
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.85
    Achieved Active Warps Per SM           warp         5.21
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.15%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       430.97
    Total L1 Elapsed Cycles          cycle       92,690
    Average L2 Active Cycles         cycle       255.08
    Total L2 Elapsed Cycles          cycle       69,480
    Average SM Active Cycles         cycle       430.97
    Total SM Elapsed Cycles          cycle       92,690
    Average SMSP Active Cycles       cycle       299.92
    Total SMSP Elapsed Cycles        cycle      370,760
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.446%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.72% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.485%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.11% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.446%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.72% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.385%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 61.12% above the average, while the minimum instance value is 85.49% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.34
    Elapsed Cycles                cycle       79,776
    Memory Throughput                 %        71.42
    DRAM Throughput                   %        43.43
    Duration                         us        97.60
    L1/TEX Cache Throughput           %        73.21
    L2 Cache Throughput               %        29.29
    SM Active Cycles              cycle    77,796.10
    Compute (SM) Throughput           %        80.45
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.64
    Achieved Active Warps Per SM           warp        43.03
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.36%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,834.67
    Total DRAM Elapsed Cycles        cycle    3,216,384
    Average L1 Active Cycles         cycle    77,796.10
    Total L1 Elapsed Cycles          cycle    2,392,680
    Average L2 Active Cycles         cycle    72,583.33
    Total L2 Elapsed Cycles          cycle    1,809,072
    Average SM Active Cycles         cycle    77,796.10
    Total SM Elapsed Cycles          cycle    2,392,680
    Average SMSP Active Cycles       cycle    77,425.63
    Total SMSP Elapsed Cycles        cycle    9,570,720
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.32
    Elapsed Cycles                cycle       80,086
    Memory Throughput                 %        71.36
    DRAM Throughput                   %        45.48
    Duration                         us        97.98
    L1/TEX Cache Throughput           %        73.28
    L2 Cache Throughput               %        29.18
    SM Active Cycles              cycle    77,723.27
    Compute (SM) Throughput           %        80.31
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.60
    Achieved Active Warps Per SM           warp        43.01
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.4%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   244,749.33
    Total DRAM Elapsed Cycles        cycle    3,228,672
    Average L1 Active Cycles         cycle    77,723.27
    Total L1 Elapsed Cycles          cycle    2,394,450
    Average L2 Active Cycles         cycle    72,458.67
    Total L2 Elapsed Cycles          cycle    1,816,056
    Average SM Active Cycles         cycle    77,723.27
    Total SM Elapsed Cycles          cycle    2,394,450
    Average SMSP Active Cycles       cycle    77,527.58
    Total SMSP Elapsed Cycles        cycle    9,577,800
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.40
    Elapsed Cycles                cycle       80,044
    Memory Throughput                 %        71.37
    DRAM Throughput                   %        45.65
    Duration                         us        97.92
    L1/TEX Cache Throughput           %        73.42
    L2 Cache Throughput               %        29.23
    SM Active Cycles              cycle    77,578.90
    Compute (SM) Throughput           %        80.22
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.56
    Achieved Active Warps Per SM           warp        42.99
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.44%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,490.67
    Total DRAM Elapsed Cycles        cycle    3,226,624
    Average L1 Active Cycles         cycle    77,578.90
    Total L1 Elapsed Cycles          cycle    2,394,120
    Average L2 Active Cycles         cycle    72,410.83
    Total L2 Elapsed Cycles          cycle    1,814,832
    Average SM Active Cycles         cycle    77,578.90
    Total SM Elapsed Cycles          cycle    2,394,120
    Average SMSP Active Cycles       cycle    77,443.68
    Total SMSP Elapsed Cycles        cycle    9,576,480
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.22
    Elapsed Cycles                cycle       79,895
    Memory Throughput                 %        71.37
    DRAM Throughput                   %        43.30
    Duration                         us        97.76
    L1/TEX Cache Throughput           %        73.28
    L2 Cache Throughput               %        29.26
    SM Active Cycles              cycle    77,722.13
    Compute (SM) Throughput           %        80.14
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.52
    Achieved Active Warps Per SM           warp        42.97
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.48%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,330.67
    Total DRAM Elapsed Cycles        cycle    3,219,456
    Average L1 Active Cycles         cycle    77,722.13
    Total L1 Elapsed Cycles          cycle    2,394,110
    Average L2 Active Cycles         cycle    72,313.46
    Total L2 Elapsed Cycles          cycle    1,811,784
    Average SM Active Cycles         cycle    77,722.13
    Total SM Elapsed Cycles          cycle    2,394,110
    Average SMSP Active Cycles       cycle    77,370.15
    Total SMSP Elapsed Cycles        cycle    9,576,440
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.31
    Elapsed Cycles                cycle       79,801
    Memory Throughput                 %        71.54
    DRAM Throughput                   %        45.73
    Duration                         us        97.63
    L1/TEX Cache Throughput           %        73.48
    L2 Cache Throughput               %        29.29
    SM Active Cycles              cycle    77,514.37
    Compute (SM) Throughput           %        80.25
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.42
    Achieved Active Warps Per SM           warp        42.92
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.58%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,141.33
    Total DRAM Elapsed Cycles        cycle    3,216,384
    Average L1 Active Cycles         cycle    77,514.37
    Total L1 Elapsed Cycles          cycle    2,388,430
    Average L2 Active Cycles         cycle    72,240.08
    Total L2 Elapsed Cycles          cycle    1,809,552
    Average SM Active Cycles         cycle    77,514.37
    Total SM Elapsed Cycles          cycle    2,388,430
    Average SMSP Active Cycles       cycle    77,391.40
    Total SMSP Elapsed Cycles        cycle    9,553,720
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.34
    Elapsed Cycles                cycle       79,934
    Memory Throughput                 %        71.41
    DRAM Throughput                   %        45.69
    Duration                         us        97.79
    L1/TEX Cache Throughput           %        73.43
    L2 Cache Throughput               %        29.25
    SM Active Cycles              cycle    77,572.53
    Compute (SM) Throughput           %        80.02
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.39
    Achieved Active Warps Per SM           warp        42.91
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.61%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.4%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,328
    Total DRAM Elapsed Cycles        cycle    3,221,504
    Average L1 Active Cycles         cycle    77,572.53
    Total L1 Elapsed Cycles          cycle    2,392,850
    Average L2 Active Cycles         cycle    72,279.92
    Total L2 Elapsed Cycles          cycle    1,812,312
    Average SM Active Cycles         cycle    77,572.53
    Total SM Elapsed Cycles          cycle    2,392,850
    Average SMSP Active Cycles       cycle    77,403.15
    Total SMSP Elapsed Cycles        cycle    9,571,400
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       799.52
    Elapsed Cycles                cycle        3,123
    Memory Throughput                 %         0.85
    DRAM Throughput                   %         0.41
    Duration                         us         3.90
    L1/TEX Cache Throughput           %         2.73
    L2 Cache Throughput               %         0.85
    SM Active Cycles              cycle       439.67
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.12
    Achieved Active Warps Per SM           warp         5.34
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.88%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        85.33
    Total DRAM Elapsed Cycles        cycle      125,952
    Average L1 Active Cycles         cycle       439.67
    Total L1 Elapsed Cycles          cycle       90,200
    Average L2 Active Cycles         cycle       222.79
    Total L2 Elapsed Cycles          cycle       70,800
    Average SM Active Cycles         cycle       439.67
    Total SM Elapsed Cycles          cycle       90,200
    Average SMSP Active Cycles       cycle       312.41
    Total SMSP Elapsed Cycles        cycle      360,800
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.85%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.36% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.966%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.67% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.85%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.36% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.32
    Elapsed Cycles                cycle       79,593
    Memory Throughput                 %        71.59
    DRAM Throughput                   %        43.42
    Duration                         us        97.38
    L1/TEX Cache Throughput           %        73.33
    L2 Cache Throughput               %        29.37
    SM Active Cycles              cycle    77,677.53
    Compute (SM) Throughput           %        80.14
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.30
    Achieved Active Warps Per SM           warp        42.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.7%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,157.33
    Total DRAM Elapsed Cycles        cycle    3,208,192
    Average L1 Active Cycles         cycle    77,677.53
    Total L1 Elapsed Cycles          cycle    2,386,750
    Average L2 Active Cycles         cycle    72,307.96
    Total L2 Elapsed Cycles          cycle    1,804,920
    Average SM Active Cycles         cycle    77,677.53
    Total SM Elapsed Cycles          cycle    2,386,750
    Average SMSP Active Cycles       cycle    77,243.39
    Total SMSP Elapsed Cycles        cycle    9,547,000
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       799.01
    Elapsed Cycles                cycle        3,122
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.41
    Duration                         us         3.90
    L1/TEX Cache Throughput           %         2.68
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       448.43
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.02
    Achieved Active Warps Per SM           warp         5.29
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.98%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        85.33
    Total DRAM Elapsed Cycles        cycle      125,952
    Average L1 Active Cycles         cycle       448.43
    Total L1 Elapsed Cycles          cycle       92,240
    Average L2 Active Cycles         cycle       249.33
    Total L2 Elapsed Cycles          cycle       70,800
    Average SM Active Cycles         cycle       448.43
    Total SM Elapsed Cycles          cycle       92,240
    Average SMSP Active Cycles       cycle       341.13
    Total SMSP Elapsed Cycles        cycle      368,960
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.832%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.41% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 8.467%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.31% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.832%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.41% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.30
    Elapsed Cycles                cycle       79,880
    Memory Throughput                 %        71.20
    DRAM Throughput                   %        45.66
    Duration                         us        97.73
    L1/TEX Cache Throughput           %        73.44
    L2 Cache Throughput               %        29.27
    SM Active Cycles              cycle    77,552.83
    Compute (SM) Throughput           %        79.60
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.28
    Achieved Active Warps Per SM           warp        42.86
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.72%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,000
    Total DRAM Elapsed Cycles        cycle    3,219,456
    Average L1 Active Cycles         cycle    77,552.83
    Total L1 Elapsed Cycles          cycle    2,400,000
    Average L2 Active Cycles         cycle    72,327.17
    Total L2 Elapsed Cycles          cycle    1,811,376
    Average SM Active Cycles         cycle    77,552.83
    Total SM Elapsed Cycles          cycle    2,400,000
    Average SMSP Active Cycles       cycle    77,122.65
    Total SMSP Elapsed Cycles        cycle    9,600,000
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       799.54
    Elapsed Cycles                cycle        3,048
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.38
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.64
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       454.43
    Compute (SM) Throughput           %         0.54
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.87
    Achieved Active Warps Per SM           warp         5.22
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.13%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       454.43
    Total L1 Elapsed Cycles          cycle       89,860
    Average L2 Active Cycles         cycle       257.04
    Total L2 Elapsed Cycles          cycle       69,072
    Average SM Active Cycles         cycle       454.43
    Total SM Elapsed Cycles          cycle       89,860
    Average SMSP Active Cycles       cycle       312.38
    Total SMSP Elapsed Cycles        cycle      359,440
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.27%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.72% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.994%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.65% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.27%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.72% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.327%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 59.65% above the average, while the minimum instance value is 85.61% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.45
    Elapsed Cycles                cycle       79,604
    Memory Throughput                 %        71.65
    DRAM Throughput                   %        45.81
    Duration                         us        97.38
    L1/TEX Cache Throughput           %        73.57
    L2 Cache Throughput               %        29.39
    SM Active Cycles              cycle    77,416.43
    Compute (SM) Throughput           %        80.02
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.22
    Achieved Active Warps Per SM           warp        42.83
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.78%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,002.67
    Total DRAM Elapsed Cycles        cycle    3,209,216
    Average L1 Active Cycles         cycle    77,416.43
    Total L1 Elapsed Cycles          cycle    2,384,860
    Average L2 Active Cycles         cycle    72,120.33
    Total L2 Elapsed Cycles          cycle    1,805,256
    Average SM Active Cycles         cycle    77,416.43
    Total SM Elapsed Cycles          cycle    2,384,860
    Average SMSP Active Cycles       cycle    77,121.04
    Total SMSP Elapsed Cycles        cycle    9,539,440
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       796.75
    Elapsed Cycles                cycle        3,086
    Memory Throughput                 %         0.86
    DRAM Throughput                   %         0.40
    Duration                         us         3.87
    L1/TEX Cache Throughput           %         2.71
    L2 Cache Throughput               %         0.86
    SM Active Cycles              cycle       442.67
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.15
    Achieved Active Warps Per SM           warp         5.35
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.85%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        82.67
    Total DRAM Elapsed Cycles        cycle      124,928
    Average L1 Active Cycles         cycle       442.67
    Total L1 Elapsed Cycles          cycle       90,530
    Average L2 Active Cycles         cycle       248.33
    Total L2 Elapsed Cycles          cycle       69,984
    Average SM Active Cycles         cycle       442.67
    Total SM Elapsed Cycles          cycle       90,530
    Average SMSP Active Cycles       cycle       313.27
    Total SMSP Elapsed Cycles        cycle      362,120
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.933%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.71% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.974%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.81% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.933%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.71% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.40
    Elapsed Cycles                cycle       79,730
    Memory Throughput                 %        71.74
    DRAM Throughput                   %        45.70
    Duration                         us        97.54
    L1/TEX Cache Throughput           %        73.60
    L2 Cache Throughput               %        29.32
    SM Active Cycles              cycle    77,386.30
    Compute (SM) Throughput           %        80.03
    ----------------------- ----------- ------------

    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.20
    Achieved Active Warps Per SM           warp        42.81
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.8%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,816
    Total DRAM Elapsed Cycles        cycle    3,214,336
    Average L1 Active Cycles         cycle    77,386.30
    Total L1 Elapsed Cycles          cycle    2,381,880
    Average L2 Active Cycles         cycle    72,135.46
    Total L2 Elapsed Cycles          cycle    1,808,040
    Average SM Active Cycles         cycle    77,386.30
    Total SM Elapsed Cycles          cycle    2,381,880
    Average SMSP Active Cycles       cycle    77,156.84
    Total SMSP Elapsed Cycles        cycle    9,527,520
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       798.70
    Elapsed Cycles                cycle        3,144
    Memory Throughput                 %         0.84
    DRAM Throughput                   %         0.37
    Duration                         us         3.94
    L1/TEX Cache Throughput           %         2.67
    L2 Cache Throughput               %         0.84
    SM Active Cycles              cycle       450.17
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.06
    Achieved Active Warps Per SM           warp         5.31
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.94%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      125,952
    Average L1 Active Cycles         cycle       450.17
    Total L1 Elapsed Cycles          cycle       89,170
    Average L2 Active Cycles         cycle       301.12
    Total L2 Elapsed Cycles          cycle       71,256
    Average SM Active Cycles         cycle       450.17
    Total SM Elapsed Cycles          cycle       89,170
    Average SMSP Active Cycles       cycle       309.77
    Total SMSP Elapsed Cycles        cycle      356,680
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.2%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.33% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.967%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.44% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.2%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.33% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 6.869%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.73% above the average, while the minimum instance value is 87.71% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.34
    Elapsed Cycles                cycle       79,567
    Memory Throughput                 %        71.70
    DRAM Throughput                   %        43.33
    Duration                         us        97.34
    L1/TEX Cache Throughput           %        73.62
    L2 Cache Throughput               %        29.32
    SM Active Cycles              cycle    77,371.70
    Compute (SM) Throughput           %        79.88
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.13
    Achieved Active Warps Per SM           warp        42.78
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.87%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,634.67
    Total DRAM Elapsed Cycles        cycle    3,207,168
    Average L1 Active Cycles         cycle    77,371.70
    Total L1 Elapsed Cycles          cycle    2,383,230
    Average L2 Active Cycles         cycle    72,083.50
    Total L2 Elapsed Cycles          cycle    1,804,368
    Average SM Active Cycles         cycle    77,371.70
    Total SM Elapsed Cycles          cycle    2,383,230
    Average SMSP Active Cycles       cycle    77,074.87
    Total SMSP Elapsed Cycles        cycle    9,532,920
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.37
    Elapsed Cycles                cycle       79,569
    Memory Throughput                 %        71.69
    DRAM Throughput                   %        45.96
    Duration                         us        97.34
    L1/TEX Cache Throughput           %        73.59
    L2 Cache Throughput               %        29.32
    SM Active Cycles              cycle    77,403.80
    Compute (SM) Throughput           %        79.79
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.14
    Achieved Active Warps Per SM           warp        42.79
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.86%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,645.33
    Total DRAM Elapsed Cycles        cycle    3,207,168
    Average L1 Active Cycles         cycle    77,403.80
    Total L1 Elapsed Cycles          cycle    2,383,380
    Average L2 Active Cycles         cycle    71,977.38
    Total L2 Elapsed Cycles          cycle    1,804,392
    Average SM Active Cycles         cycle    77,403.80
    Total SM Elapsed Cycles          cycle    2,383,380
    Average SMSP Active Cycles       cycle    77,027.79
    Total SMSP Elapsed Cycles        cycle    9,533,520
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.13
    Elapsed Cycles                cycle       79,572
    Memory Throughput                 %        71.80
    DRAM Throughput                   %        45.85
    Duration                         us        97.38
    L1/TEX Cache Throughput           %        73.77
    L2 Cache Throughput               %        29.41
    SM Active Cycles              cycle    77,207.80
    Compute (SM) Throughput           %        79.81
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.26
    Achieved Active Warps Per SM           warp        42.84
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.74%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.3%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,104
    Total DRAM Elapsed Cycles        cycle    3,207,168
    Average L1 Active Cycles         cycle    77,207.80
    Total L1 Elapsed Cycles          cycle    2,379,740
    Average L2 Active Cycles         cycle    72,076.88
    Total L2 Elapsed Cycles          cycle    1,804,368
    Average SM Active Cycles         cycle    77,207.80
    Total SM Elapsed Cycles          cycle    2,379,740
    Average SMSP Active Cycles       cycle    76,894.88
    Total SMSP Elapsed Cycles        cycle    9,518,960
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       798.58
    Elapsed Cycles                cycle        3,041
    Memory Throughput                 %         0.89
    DRAM Throughput                   %         0.37
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.73
    L2 Cache Throughput               %         0.89
    SM Active Cycles              cycle       440.20
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.15
    Achieved Active Warps Per SM           warp         5.35
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.85%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        74.67
    Total DRAM Elapsed Cycles        cycle      121,856
    Average L1 Active Cycles         cycle       440.20
    Total L1 Elapsed Cycles          cycle       92,520
    Average L2 Active Cycles         cycle       267.79
    Total L2 Elapsed Cycles          cycle       69,048
    Average SM Active Cycles         cycle       440.20
    Total SM Elapsed Cycles          cycle       92,520
    Average SMSP Active Cycles       cycle       316.22
    Total SMSP Elapsed Cycles        cycle      370,080
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.64%                                                                                           
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.54% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.986%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.89% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.64%                                                                                           
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.54% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.565%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 59.79% above the average, while the minimum instance value is 86.18% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.44
    Elapsed Cycles                cycle       79,500
    Memory Throughput                 %        71.83
    DRAM Throughput                   %        45.85
    Duration                         us        97.25
    L1/TEX Cache Throughput           %        73.70
    L2 Cache Throughput               %        29.41
    SM Active Cycles              cycle    77,283.10
    Compute (SM) Throughput           %        79.74
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        89.10
    Achieved Active Warps Per SM           warp        42.77
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 10.9%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,840
    Total DRAM Elapsed Cycles        cycle    3,204,096
    Average L1 Active Cycles         cycle    77,283.10
    Total L1 Elapsed Cycles          cycle    2,378,760
    Average L2 Active Cycles         cycle    71,909.67
    Total L2 Elapsed Cycles          cycle    1,802,856
    Average SM Active Cycles         cycle    77,283.10
    Total SM Elapsed Cycles          cycle    2,378,760
    Average SMSP Active Cycles       cycle    76,982.85
    Total SMSP Elapsed Cycles        cycle    9,515,040
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.23
    Elapsed Cycles                cycle       79,322
    Memory Throughput                 %        71.93
    DRAM Throughput                   %        43.67
    Duration                         us        97.06
    L1/TEX Cache Throughput           %        73.89
    L2 Cache Throughput               %        29.46
    SM Active Cycles              cycle    77,089.07
    Compute (SM) Throughput           %        79.74
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.96
    Achieved Active Warps Per SM           warp        42.70
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.04%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   232,682.67
    Total DRAM Elapsed Cycles        cycle    3,196,928
    Average L1 Active Cycles         cycle    77,089.07
    Total L1 Elapsed Cycles          cycle    2,375,700
    Average L2 Active Cycles         cycle    71,890.42
    Total L2 Elapsed Cycles          cycle    1,798,752
    Average SM Active Cycles         cycle    77,089.07
    Total SM Elapsed Cycles          cycle    2,375,700
    Average SMSP Active Cycles       cycle    76,838.63
    Total SMSP Elapsed Cycles        cycle    9,502,800
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.40
    Elapsed Cycles                cycle       79,391
    Memory Throughput                 %        71.99
    DRAM Throughput                   %        45.93
    Duration                         us        97.12
    L1/TEX Cache Throughput           %        73.89
    L2 Cache Throughput               %        29.45
    SM Active Cycles              cycle    77,083.63
    Compute (SM) Throughput           %        79.72
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.99
    Achieved Active Warps Per SM           warp        42.71
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.01%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (89.0%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,034.67
    Total DRAM Elapsed Cycles        cycle    3,201,024
    Average L1 Active Cycles         cycle    77,083.63
    Total L1 Elapsed Cycles          cycle    2,373,650
    Average L2 Active Cycles         cycle    71,849.50
    Total L2 Elapsed Cycles          cycle    1,800,240
    Average SM Active Cycles         cycle    77,083.63
    Total SM Elapsed Cycles          cycle    2,373,650
    Average SMSP Active Cycles       cycle    76,764.57
    Total SMSP Elapsed Cycles        cycle    9,494,600
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.42
    SM Frequency                    Mhz       799.71
    Elapsed Cycles                cycle        3,151
    Memory Throughput                 %         1.01
    DRAM Throughput                   %         0.35
    Duration                         us         3.94
    L1/TEX Cache Throughput           %         2.69
    L2 Cache Throughput               %         1.01
    SM Active Cycles              cycle       445.67
    Compute (SM) Throughput           %         0.56
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.11
    Achieved Active Warps Per SM           warp         5.33
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.89%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        74.67
    Total DRAM Elapsed Cycles        cycle      128,000
    Average L1 Active Cycles         cycle       445.67
    Total L1 Elapsed Cycles          cycle       90,450
    Average L2 Active Cycles         cycle       247.50
    Total L2 Elapsed Cycles          cycle       71,400
    Average SM Active Cycles         cycle       445.67
    Total SM Elapsed Cycles          cycle       90,450
    Average SMSP Active Cycles       cycle       314.12
    Total SMSP Elapsed Cycles        cycle      361,800
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.966%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.42% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.998%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.77% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.966%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.42% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.42
    Elapsed Cycles                cycle       79,287
    Memory Throughput                 %        71.99
    DRAM Throughput                   %        46.08
    Duration                         us        96.99
    L1/TEX Cache Throughput           %        73.96
    L2 Cache Throughput               %        29.46
    SM Active Cycles              cycle    77,012.80
    Compute (SM) Throughput           %        79.64
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.91
    Achieved Active Warps Per SM           warp        42.68
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.09%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,442.67
    Total DRAM Elapsed Cycles        cycle    3,195,904
    Average L1 Active Cycles         cycle    77,012.80
    Total L1 Elapsed Cycles          cycle    2,373,450
    Average L2 Active Cycles         cycle    71,810.54
    Total L2 Elapsed Cycles          cycle    1,798,032
    Average SM Active Cycles         cycle    77,012.80
    Total SM Elapsed Cycles          cycle    2,373,450
    Average SMSP Active Cycles       cycle    76,753.74
    Total SMSP Elapsed Cycles        cycle    9,493,800
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.34
    Elapsed Cycles                cycle       79,359
    Memory Throughput                 %        71.73
    DRAM Throughput                   %        43.62
    Duration                         us        97.09
    L1/TEX Cache Throughput           %        73.89
    L2 Cache Throughput               %        29.44
    SM Active Cycles              cycle    77,087.17
    Compute (SM) Throughput           %        79.27
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.93
    Achieved Active Warps Per SM           warp        42.69
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.07%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      232,560
    Total DRAM Elapsed Cycles        cycle    3,198,976
    Average L1 Active Cycles         cycle    77,087.17
    Total L1 Elapsed Cycles          cycle    2,382,330
    Average L2 Active Cycles         cycle    71,717.62
    Total L2 Elapsed Cycles          cycle    1,799,568
    Average SM Active Cycles         cycle    77,087.17
    Total SM Elapsed Cycles          cycle    2,382,330
    Average SMSP Active Cycles       cycle    76,628.25
    Total SMSP Elapsed Cycles        cycle    9,529,320
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.56
    Elapsed Cycles                cycle       79,328
    Memory Throughput                 %        72.10
    DRAM Throughput                   %        46.08
    Duration                         us        97.02
    L1/TEX Cache Throughput           %        73.82
    L2 Cache Throughput               %        29.45
    SM Active Cycles              cycle    77,161.77
    Compute (SM) Throughput           %        79.61
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.91
    Achieved Active Warps Per SM           warp        42.68
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.09%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.9%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,437.33
    Total DRAM Elapsed Cycles        cycle    3,195,904
    Average L1 Active Cycles         cycle    77,161.77
    Total L1 Elapsed Cycles          cycle    2,369,910
    Average L2 Active Cycles         cycle    71,761.08
    Total L2 Elapsed Cycles          cycle    1,798,944
    Average SM Active Cycles         cycle    77,161.77
    Total SM Elapsed Cycles          cycle    2,369,910
    Average SMSP Active Cycles       cycle    76,725.77
    Total SMSP Elapsed Cycles        cycle    9,479,640
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       794.97
    Elapsed Cycles                cycle        3,131
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.38
    Duration                         us         3.94
    L1/TEX Cache Throughput           %         2.70
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       443.90
    Compute (SM) Throughput           %         0.54
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.13
    Achieved Active Warps Per SM           warp         5.34
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.87%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      125,952
    Average L1 Active Cycles         cycle       443.90
    Total L1 Elapsed Cycles          cycle       90,310
    Average L2 Active Cycles         cycle       258.92
    Total L2 Elapsed Cycles          cycle       70,968
    Average SM Active Cycles         cycle       443.90
    Total SM Elapsed Cycles          cycle       90,310
    Average SMSP Active Cycles       cycle       312.37
    Total SMSP Elapsed Cycles        cycle      361,240
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.961%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.55% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.961%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.72% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.961%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.55% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.01
    Elapsed Cycles                cycle       79,042
    Memory Throughput                 %        71.84
    DRAM Throughput                   %        43.81
    Duration                         us        96.74
    L1/TEX Cache Throughput           %        73.91
    L2 Cache Throughput               %        29.55
    SM Active Cycles              cycle    77,060.60
    Compute (SM) Throughput           %        79.27
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.84
    Achieved Active Warps Per SM           warp        42.64
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.16%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.8%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      232,632
    Total DRAM Elapsed Cycles        cycle    3,185,664
    Average L1 Active Cycles         cycle    77,060.60
    Total L1 Elapsed Cycles          cycle    2,378,590
    Average L2 Active Cycles         cycle       71,763
    Total L2 Elapsed Cycles          cycle    1,792,344
    Average SM Active Cycles         cycle    77,060.60
    Total SM Elapsed Cycles          cycle    2,378,590
    Average SMSP Active Cycles       cycle    76,688.98
    Total SMSP Elapsed Cycles        cycle    9,514,360
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.38
    Elapsed Cycles                cycle       79,413
    Memory Throughput                 %        71.82
    DRAM Throughput                   %        46.06
    Duration                         us        97.15
    L1/TEX Cache Throughput           %        73.91
    L2 Cache Throughput               %        29.45
    SM Active Cycles              cycle    77,059.33
    Compute (SM) Throughput           %        79.21
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.70
    Achieved Active Warps Per SM           warp        42.57
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.3%                                                                                     
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      245,680
    Total DRAM Elapsed Cycles        cycle    3,200,000
    Average L1 Active Cycles         cycle    77,059.33
    Total L1 Elapsed Cycles          cycle    2,379,340
    Average L2 Active Cycles         cycle    71,795.08
    Total L2 Elapsed Cycles          cycle    1,800,888
    Average SM Active Cycles         cycle    77,059.33
    Total SM Elapsed Cycles          cycle    2,379,340
    Average SMSP Active Cycles       cycle    76,616.33
    Total SMSP Elapsed Cycles        cycle    9,517,360
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       795.66
    Elapsed Cycles                cycle        3,057
    Memory Throughput                 %         0.87
    DRAM Throughput                   %         0.42
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.80
    L2 Cache Throughput               %         0.87
    SM Active Cycles              cycle       428.70
    Compute (SM) Throughput           %         0.55
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.09
    Achieved Active Warps Per SM           warp         5.32
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.91%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.1%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        85.33
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       428.70
    Total L1 Elapsed Cycles          cycle       91,980
    Average L2 Active Cycles         cycle       277.12
    Total L2 Elapsed Cycles          cycle       69,312
    Average SM Active Cycles         cycle       428.70
    Total SM Elapsed Cycles          cycle       91,980
    Average SMSP Active Cycles       cycle       304.13
    Total SMSP Elapsed Cycles        cycle      367,920
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.482%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.82% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.737%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.99% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.482%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.82% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.32%                                                                                           
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 55.45% above the average, while the minimum instance value is 86.65% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.31
    Elapsed Cycles                cycle       79,068
    Memory Throughput                 %        71.94
    DRAM Throughput                   %        46.31
    Duration                         us        96.74
    L1/TEX Cache Throughput           %        73.93
    L2 Cache Throughput               %        29.56
    SM Active Cycles              cycle    77,038.67
    Compute (SM) Throughput           %        79.30
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.64
    Achieved Active Warps Per SM           warp        42.55
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.36%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,938.67
    Total DRAM Elapsed Cycles        cycle    3,186,688
    Average L1 Active Cycles         cycle    77,038.67
    Total L1 Elapsed Cycles          cycle    2,375,390
    Average L2 Active Cycles         cycle    71,777.38
    Total L2 Elapsed Cycles          cycle    1,793,088
    Average SM Active Cycles         cycle    77,038.67
    Total SM Elapsed Cycles          cycle    2,375,390
    Average SMSP Active Cycles       cycle    76,765.41
    Total SMSP Elapsed Cycles        cycle    9,501,560
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       802.00
    Elapsed Cycles                cycle        3,056
    Memory Throughput                 %         0.95
    DRAM Throughput                   %         0.39
    Duration                         us         3.81
    L1/TEX Cache Throughput           %         2.70
    L2 Cache Throughput               %         0.95
    SM Active Cycles              cycle       444.93
    Compute (SM) Throughput           %         0.50
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        10.57
    Achieved Active Warps Per SM           warp         5.07
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 89.43%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (10.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      122,880
    Average L1 Active Cycles         cycle       444.93
    Total L1 Elapsed Cycles          cycle       90,730
    Average L2 Active Cycles         cycle       279.79
    Total L2 Elapsed Cycles          cycle       69,240
    Average SM Active Cycles         cycle       444.93
    Total SM Elapsed Cycles          cycle       90,730
    Average SMSP Active Cycles       cycle       301.43
    Total SMSP Elapsed Cycles        cycle      362,920
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 9.927%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.48% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.711%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 77.37% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 9.927%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.48% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 5.678%                                                                                          
          One or more L2 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 58.55% above the average, while the minimum instance value is 86.78% below the      
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.11
    Elapsed Cycles                cycle       79,021
    Memory Throughput                 %        72.00
    DRAM Throughput                   %        43.55
    Duration                         us        96.70
    L1/TEX Cache Throughput           %        73.86
    L2 Cache Throughput               %        29.55
    SM Active Cycles              cycle    77,119.87
    Compute (SM) Throughput           %        79.33
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.72
    Achieved Active Warps Per SM           warp        42.58
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.28%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,229.33
    Total DRAM Elapsed Cycles        cycle    3,185,664
    Average L1 Active Cycles         cycle    77,119.87
    Total L1 Elapsed Cycles          cycle    2,373,180
    Average L2 Active Cycles         cycle    71,839.38
    Total L2 Elapsed Cycles          cycle    1,791,984
    Average SM Active Cycles         cycle    77,119.87
    Total SM Elapsed Cycles          cycle    2,373,180
    Average SMSP Active Cycles       cycle    76,798.03
    Total SMSP Elapsed Cycles        cycle    9,492,720
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.49
    Elapsed Cycles                cycle       79,320
    Memory Throughput                 %        71.99
    DRAM Throughput                   %        45.95
    Duration                         us        97.02
    L1/TEX Cache Throughput           %        73.93
    L2 Cache Throughput               %        29.43
    SM Active Cycles              cycle    77,041.97
    Compute (SM) Throughput           %        79.24
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.55
    Achieved Active Warps Per SM           warp        42.51
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.45%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle      244,816
    Total DRAM Elapsed Cycles        cycle    3,196,928
    Average L1 Active Cycles         cycle    77,041.97
    Total L1 Elapsed Cycles          cycle    2,373,610
    Average L2 Active Cycles         cycle    71,810.92
    Total L2 Elapsed Cycles          cycle    1,798,848
    Average SM Active Cycles         cycle    77,041.97
    Total SM Elapsed Cycles          cycle    2,373,610
    Average SMSP Active Cycles       cycle    76,780.43
    Total SMSP Elapsed Cycles        cycle    9,494,440
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.27
    Elapsed Cycles                cycle       79,062
    Memory Throughput                 %        72.00
    DRAM Throughput                   %        43.53
    Duration                         us        96.74
    L1/TEX Cache Throughput           %        74.05
    L2 Cache Throughput               %        29.51
    SM Active Cycles              cycle    76,917.13
    Compute (SM) Throughput           %        79.16
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.59
    Achieved Active Warps Per SM           warp        42.52
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.41%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   231,186.67
    Total DRAM Elapsed Cycles        cycle    3,186,688
    Average L1 Active Cycles         cycle    76,917.13
    Total L1 Elapsed Cycles          cycle    2,373,390
    Average L2 Active Cycles         cycle    71,760.58
    Total L2 Elapsed Cycles          cycle    1,792,968
    Average SM Active Cycles         cycle    76,917.13
    Total SM Elapsed Cycles          cycle    2,373,390
    Average SMSP Active Cycles       cycle    76,669.32
    Total SMSP Elapsed Cycles        cycle    9,493,560
    -------------------------- ----------- ------------

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.27
    Elapsed Cycles                cycle       79,141
    Memory Throughput                 %        72.09
    DRAM Throughput                   %        43.44
    Duration                         us        96.83
    L1/TEX Cache Throughput           %        74.06
    L2 Cache Throughput               %        29.57
    SM Active Cycles              cycle    76,911.13
    Compute (SM) Throughput           %        79.18
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.66
    Achieved Active Warps Per SM           warp        42.56
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.34%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.7%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   230,954.67
    Total DRAM Elapsed Cycles        cycle    3,189,760
    Average L1 Active Cycles         cycle    76,911.13
    Total L1 Elapsed Cycles          cycle    2,370,240
    Average L2 Active Cycles         cycle    71,782.58
    Total L2 Elapsed Cycles          cycle    1,794,600
    Average SM Active Cycles         cycle    76,911.13
    Total SM Elapsed Cycles          cycle    2,370,240
    Average SMSP Active Cycles       cycle    76,621.43
    Total SMSP Elapsed Cycles        cycle    9,480,960
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.38
    SM Frequency                    Mhz       802.60
    Elapsed Cycles                cycle        3,083
    Memory Throughput                 %         0.88
    DRAM Throughput                   %         0.39
    Duration                         us         3.84
    L1/TEX Cache Throughput           %         2.54
    L2 Cache Throughput               %         0.88
    SM Active Cycles              cycle       472.87
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.54
    Achieved Active Warps Per SM           warp         5.54
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.46%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.5%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle           80
    Total DRAM Elapsed Cycles        cycle      123,904
    Average L1 Active Cycles         cycle       472.87
    Total L1 Elapsed Cycles          cycle       89,220
    Average L2 Active Cycles         cycle       258.38
    Total L2 Elapsed Cycles          cycle       69,864
    Average SM Active Cycles         cycle       472.87
    Total SM Elapsed Cycles          cycle       89,220
    Average SMSP Active Cycles       cycle       308.86
    Total SMSP Elapsed Cycles        cycle      356,880
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.73%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 67.50% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.981%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.85% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.73%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 67.50% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

  heat_kernel_2d_fused(float *, float *, uchar4 *, int, int, float, float, float, float, BoundaryCondition) (63, 63, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.49
    SM Frequency                    Mhz       817.18
    Elapsed Cycles                cycle       79,237
    Memory Throughput                 %        72.26
    DRAM Throughput                   %        46.13
    Duration                         us        96.96
    L1/TEX Cache Throughput           %        74.10
    L2 Cache Throughput               %        29.45
    SM Active Cycles              cycle    76,862.43
    Compute (SM) Throughput           %        79.27
    ----------------------- ----------- ------------

    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  3,969
    Registers Per Thread             register/thread              23
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block       Kbyte/block            1.30
    # SMs                                         SM              30
    Threads                                   thread       1,016,064
    Uses Green Context                                             0
    Waves Per SM                                               22.05
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           13
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        88.56
    Achieved Active Warps Per SM           warp        42.51
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 11.44%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.6%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle   245,613.33
    Total DRAM Elapsed Cycles        cycle    3,194,880
    Average L1 Active Cycles         cycle    76,862.43
    Total L1 Elapsed Cycles          cycle    2,364,830
    Average L2 Active Cycles         cycle    71,565.12
    Total L2 Elapsed Cycles          cycle    1,796,952
    Average SM Active Cycles         cycle    76,862.43
    Total SM Elapsed Cycles          cycle    2,364,830
    Average SMSP Active Cycles       cycle    76,644.86
    Total SMSP Elapsed Cycles        cycle    9,459,320
    -------------------------- ----------- ------------

  add_heat_kernel_2d(float *, int, int, int, int) (1, 10, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.6
    Section: GPU Speed Of Light Throughput
    ----------------------- ----------- ------------
    Metric Name             Metric Unit Metric Value
    ----------------------- ----------- ------------
    DRAM Frequency                  Ghz         5.33
    SM Frequency                    Mhz       797.51
    Elapsed Cycles                cycle        3,140
    Memory Throughput                 %         0.85
    DRAM Throughput                   %         0.37
    Duration                         us         3.94
    L1/TEX Cache Throughput           %         2.68
    L2 Cache Throughput               %         0.85
    SM Active Cycles              cycle       447.63
    Compute (SM) Throughput           %         0.57
    ----------------------- ----------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     10
    Registers Per Thread             register/thread              16
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    # SMs                                         SM              30
    Threads                                   thread           2,560
    Uses Green Context                                             0
    Waves Per SM                                                0.06
    -------------------------------- --------------- ---------------

    OPT   Est. Speedup: 66.67%                                                                                          
          The grid for this launch is configured to execute only 10 blocks, which is less than the GPU's 30             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           16
    Block Limit Registers                 block           16
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            6
    Theoretical Active Warps per SM        warp           48
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.22
    Achieved Active Warps Per SM           warp         5.38
    ------------------------------- ----------- ------------

    OPT   Est. Local Speedup: 88.78%                                                                                    
          The difference between calculated theoretical (100.0%) and measured achieved occupancy (11.2%) can be the     
          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   
          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   
          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     
          optimizing occupancy.                                                                                         

    Section: GPU and Memory Workload Distribution
    -------------------------- ----------- ------------
    Metric Name                Metric Unit Metric Value
    -------------------------- ----------- ------------
    Average DRAM Active Cycles       cycle        77.33
    Total DRAM Elapsed Cycles        cycle      125,952
    Average L1 Active Cycles         cycle       447.63
    Total L1 Elapsed Cycles          cycle       89,210
    Average L2 Active Cycles         cycle       236.21
    Total L2 Elapsed Cycles          cycle       71,232
    Average SM Active Cycles         cycle       447.63
    Total SM Elapsed Cycles          cycle       89,210
    Average SMSP Active Cycles       cycle       308.40
    Total SMSP Elapsed Cycles        cycle      356,840
    -------------------------- ----------- ------------

    OPT   Est. Speedup: 10.49%                                                                                          
          One or more SMs have a much lower number of active cycles than the average number of active cycles. Maximum   
          instance value is 69.71% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 7.984%                                                                                          
          One or more SMSPs have a much lower number of active cycles than the average number of active cycles. Maximum 
          instance value is 76.99% above the average, while the minimum instance value is 100.00% below the average.    
    ----- --------------------------------------------------------------------------------------------------------------
    OPT   Est. Speedup: 10.49%                                                                                          
          One or more L1 Slices have a much lower number of active cycles than the average number of active cycles.     
          Maximum instance value is 69.71% above the average, while the minimum instance value is 100.00% below the     
          average.                                                                                                      

